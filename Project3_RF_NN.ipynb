{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**selecting necessary data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 30 variables\n",
    "\n",
    "topvars = pd.read_csv('top_30_vars.csv')\n",
    "topvars = list(topvars.variable.values)\n",
    "\n",
    "#all data\n",
    "data = pd.read_csv('card_transactions_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnskeep = topvars + ['Recnum','Date','Fraud']\n",
    "len(columnskeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[columnskeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cardnum_max_14</th>\n",
       "      <th>Cardnum_max_30</th>\n",
       "      <th>Cardnum_mean_30</th>\n",
       "      <th>Cardnum_total_130</th>\n",
       "      <th>Cardnum_total_30</th>\n",
       "      <th>Merchnum_mean_1</th>\n",
       "      <th>Merchnum_mean_3</th>\n",
       "      <th>Merchnum_mean_7</th>\n",
       "      <th>Merchnum_total_3</th>\n",
       "      <th>card_merchant_max_14</th>\n",
       "      <th>...</th>\n",
       "      <th>card_state_total_30</th>\n",
       "      <th>card_zip_max_14</th>\n",
       "      <th>card_zip_max_30</th>\n",
       "      <th>card_zip_max_7</th>\n",
       "      <th>card_zip_mean_1</th>\n",
       "      <th>card_zip_mean_7</th>\n",
       "      <th>card_zip_median_1</th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Date</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>...</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cardnum_max_14  Cardnum_max_30  Cardnum_mean_30  Cardnum_total_130  \\\n",
       "0            0.00            0.00             0.00                NaN   \n",
       "1            0.00            0.00             0.00                NaN   \n",
       "2            0.00            0.00             0.00                NaN   \n",
       "3            0.00            0.00             0.00                NaN   \n",
       "4            3.62            3.62             3.62               30.0   \n",
       "\n",
       "   Cardnum_total_30  Merchnum_mean_1  Merchnum_mean_3  Merchnum_mean_7  \\\n",
       "0              0.00             0.00             0.00             0.00   \n",
       "1              0.00             0.00             0.00             0.00   \n",
       "2              0.00             0.00             0.00             0.00   \n",
       "3              0.00             3.62             3.62             3.62   \n",
       "4              3.62             3.62             3.62             3.62   \n",
       "\n",
       "   Merchnum_total_3  card_merchant_max_14  ...  card_state_total_30  \\\n",
       "0              0.00                  0.00  ...                 0.00   \n",
       "1              0.00                  0.00  ...                 0.00   \n",
       "2              0.00                  0.00  ...                 0.00   \n",
       "3              3.62                  0.00  ...                 0.00   \n",
       "4              7.24                  3.62  ...                 3.62   \n",
       "\n",
       "   card_zip_max_14  card_zip_max_30  card_zip_max_7  card_zip_mean_1  \\\n",
       "0             0.00             0.00            0.00             0.00   \n",
       "1             0.00             0.00            0.00             0.00   \n",
       "2             0.00             0.00            0.00             0.00   \n",
       "3             0.00             0.00            0.00             0.00   \n",
       "4             3.62             3.62            3.62             3.62   \n",
       "\n",
       "   card_zip_mean_7  card_zip_median_1  Recnum        Date  Fraud  \n",
       "0             0.00               0.00       1  2010-01-01      0  \n",
       "1             0.00               0.00       2  2010-01-01      0  \n",
       "2             0.00               0.00       3  2010-01-01      0  \n",
       "3             0.00               0.00       4  2010-01-01      0  \n",
       "4             3.62               3.62       5  2010-01-01      0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**splitting modeling and oot data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_Xs = topvars\n",
    "\n",
    "#oot df\n",
    "df_oot = df[df.Date>='2010-11-01'].copy()\n",
    "\n",
    "#x and y oot\n",
    "y_oot = df_oot['Fraud'].copy()\n",
    "X_oot = df_oot.copy().drop(columns='Fraud')\n",
    "\n",
    "#modeling data\n",
    "df_model = df[(df.Date>'2010-01-14')&(df.Date<'2010-11-01')].copy()\n",
    "\n",
    "# #x and y train\n",
    "y = df_model['Fraud'].copy()\n",
    "X = df_model.copy().drop(columns='Fraud')\n",
    "\n",
    "# #dropping date and record\n",
    "df_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "y_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "X_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "df_model.drop(columns=['Date','Recnum'], inplace=True)\n",
    "y.drop(columns=['Date','Recnum'], inplace=True)\n",
    "X.drop(columns=['Date','Recnum'], inplace=True)\n",
    "\n",
    "X_oot = StandardScaler().fit_transform(X_oot)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caclulate fdr at 3%\n",
    "\n",
    "def calculateFDR(predict, fraudscore, y):\n",
    "    temp = pd.DataFrame({'true':y.tolist(), 'predict':predict, 'score':fraudscore})\n",
    "    temp.sort_values('score', ascending=False, inplace=True)\n",
    "    percent3 = int(len(predict)*0.03)\n",
    "    return np.sum(temp.true[0:percent3])/np.sum(temp.true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#messager for when algorithms are done\n",
    "\n",
    "from twilio.rest import Client \n",
    "\n",
    "account_sid = 'ACcaa43961ddf226f48ab29089dbaccac0' \n",
    "auth_token = '7c1378126e60e485165e515853ef09b9' \n",
    "client = Client(account_sid, auth_token) \n",
    "\n",
    "def sendSignaltoChatBot():\n",
    "    signalm = f\"Model is done running.\"\n",
    "    message = client.messages.create( \n",
    "                                  from_='whatsapp:+14155238886',  \n",
    "                                  body=signalm,      \n",
    "                                  to='whatsapp:+12094809788') \n",
    "    print(message.sid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforestFDR(X, X_oot, y, y_oot, iteration=10, n_estimators=50, max_features=10, max_depth=20):\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth)\n",
    "    \n",
    "    fdr_df=[]\n",
    "    fdr_total=[0,0,0]\n",
    "    for i in range(iteration):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y) # using default setting for test_size(0.25), random_state(None) and shuffle(True)\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        data = [[X_train, y_train], [X_test, y_test], [X_oot, y_oot]]\n",
    "        fdr_list=[]\n",
    "        for d in range(len(data)):\n",
    "            predict = rf.predict(data[d][0])\n",
    "            prob = rf.predict_proba(data[d][0])\n",
    "            fraudscore = prob.transpose()[1]\n",
    "            fdr_each = calculateFDR(predict, fraudscore, data[d][1])\n",
    "            fdr_total[d] += fdr_each\n",
    "            fdr_list.append(fdr_each)\n",
    "        \n",
    "        fdr_df.append(fdr_list)\n",
    "    \n",
    "    avg_train = fdr_total[0] / iteration\n",
    "    avg_test = fdr_total[1] / iteration\n",
    "    avg_oot = fdr_total[2] / iteration\n",
    "    result = [avg_train, avg_test, avg_oot]\n",
    "\n",
    "    return fdr_df, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 100, max_features: 10, max_depth: 50 with fdr: 0.9012589333086674 on the test data\n"
     ]
    }
   ],
   "source": [
    "# Adjusting hyperparameters\n",
    "tree = [50,100,150] # towarddatascience guide: 200~2000\n",
    "features = [5,10,15,20] # should be less than number of variables (original choice: [5,10,15,20])\n",
    "depth = [10,20,50] # towarddatascience guide: 10~110 (original choice: [10,20,50,100])\n",
    "\n",
    "maximum = 0\n",
    "params=[]\n",
    "fdr_all=[]\n",
    "fdr_mean=[]\n",
    "for i in tree:\n",
    "    for j in features:\n",
    "        for k in depth:\n",
    "            temp1, temp2 = randomforestFDR(X, X_oot, y, y_oot, iteration=10, n_estimators=i, max_features=j, max_depth=k) # optimizing on test data\n",
    "            params.append([i,j,k])\n",
    "            fdr_mean.append(temp2)\n",
    "            fdr_all.append(temp1)\n",
    "            if maximum < temp2[1]:\n",
    "                maximum=temp2[1]\n",
    "                maxfdr=temp2\n",
    "                maxparams=[i,j,k]\n",
    "                \n",
    "print(f'n_estimators: {maxparams[0]}, max_features: {maxparams[1]}, max_depth: {maxparams[2]} with fdr: {maximum} on the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMdb3fbbc371be41b1a3a7746bdc226351\n"
     ]
    }
   ],
   "source": [
    "sendSignaltoChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[50, 5, 10]</td>\n",
       "      <td>[0.89755270779842, 0.8294602338163406, 0.26312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[50, 5, 20]</td>\n",
       "      <td>[0.9946487397589123, 0.883232551761451, 0.3418...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[50, 5, 50]</td>\n",
       "      <td>[0.9957275328521241, 0.8878827318618441, 0.366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[50, 10, 10]</td>\n",
       "      <td>[0.9176289119647896, 0.8421373191220317, 0.315...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[50, 10, 20]</td>\n",
       "      <td>[0.9961559415705615, 0.873518970658402, 0.3681...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[50, 10, 50]</td>\n",
       "      <td>[0.9956938735090315, 0.878652611673742, 0.3687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[50, 15, 10]</td>\n",
       "      <td>[0.9262646394240868, 0.847223540729501, 0.3424...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[50, 15, 20]</td>\n",
       "      <td>[0.9960060189111525, 0.8866171899232793, 0.386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[50, 15, 50]</td>\n",
       "      <td>[0.9957690089108517, 0.8858754404220945, 0.377...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[50, 20, 10]</td>\n",
       "      <td>[0.9273406048935542, 0.8441608643791765, 0.337...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[50, 20, 20]</td>\n",
       "      <td>[0.9943768632662783, 0.8965817652227551, 0.378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[50, 20, 50]</td>\n",
       "      <td>[0.9953838288872936, 0.8824564623749559, 0.378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[100, 5, 10]</td>\n",
       "      <td>[0.9095321959402396, 0.8369373691247741, 0.290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[100, 5, 20]</td>\n",
       "      <td>[0.9955869788613958, 0.8829029385667058, 0.349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[100, 5, 50]</td>\n",
       "      <td>[0.9956759404301776, 0.8827702579464252, 0.346...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[100, 10, 10]</td>\n",
       "      <td>[0.9211566687787179, 0.8475384835640011, 0.251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[100, 10, 20]</td>\n",
       "      <td>[0.9950345656088224, 0.8869490152470332, 0.394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[100, 10, 50]</td>\n",
       "      <td>[0.9954170527340205, 0.9012589333086674, 0.385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[100, 15, 10]</td>\n",
       "      <td>[0.9254971433547462, 0.8530294828035283, 0.291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[100, 15, 20]</td>\n",
       "      <td>[0.9955172772469305, 0.8872619344257098, 0.389...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[100, 15, 50]</td>\n",
       "      <td>[0.9955499399643959, 0.8903762827481211, 0.381...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[100, 20, 10]</td>\n",
       "      <td>[0.9270909163898603, 0.8629764509098641, 0.325...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[100, 20, 20]</td>\n",
       "      <td>[0.99539271478092, 0.8850316045667016, 0.37877...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[100, 20, 50]</td>\n",
       "      <td>[0.9960149011556325, 0.8807985633094082, 0.360...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[150, 5, 10]</td>\n",
       "      <td>[0.9090872779113125, 0.8275186966306558, 0.274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[150, 5, 20]</td>\n",
       "      <td>[0.9950657647647867, 0.8776063574021638, 0.368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[150, 5, 50]</td>\n",
       "      <td>[0.9958887195990747, 0.8876998234970854, 0.361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[150, 10, 10]</td>\n",
       "      <td>[0.9148299856082469, 0.8383882357582386, 0.260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[150, 10, 20]</td>\n",
       "      <td>[0.9958341767766775, 0.8919536679067217, 0.388...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[150, 10, 50]</td>\n",
       "      <td>[0.9961022744336274, 0.8861675320080271, 0.394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[150, 15, 10]</td>\n",
       "      <td>[0.9267898120812612, 0.8359484899156004, 0.339...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[150, 15, 20]</td>\n",
       "      <td>[0.9949494121528979, 0.8858487208660607, 0.378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[150, 15, 50]</td>\n",
       "      <td>[0.9955323250665927, 0.8979818451601279, 0.388...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[150, 20, 10]</td>\n",
       "      <td>[0.9331035297794488, 0.8565567119509243, 0.363...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[150, 20, 20]</td>\n",
       "      <td>[0.9955608225736279, 0.8941653680931877, 0.382...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[150, 20, 50]</td>\n",
       "      <td>[0.9950624614197245, 0.8847889849783739, 0.375...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           params                                                fdr\n",
       "0     [50, 5, 10]  [0.89755270779842, 0.8294602338163406, 0.26312...\n",
       "1     [50, 5, 20]  [0.9946487397589123, 0.883232551761451, 0.3418...\n",
       "2     [50, 5, 50]  [0.9957275328521241, 0.8878827318618441, 0.366...\n",
       "3    [50, 10, 10]  [0.9176289119647896, 0.8421373191220317, 0.315...\n",
       "4    [50, 10, 20]  [0.9961559415705615, 0.873518970658402, 0.3681...\n",
       "5    [50, 10, 50]  [0.9956938735090315, 0.878652611673742, 0.3687...\n",
       "6    [50, 15, 10]  [0.9262646394240868, 0.847223540729501, 0.3424...\n",
       "7    [50, 15, 20]  [0.9960060189111525, 0.8866171899232793, 0.386...\n",
       "8    [50, 15, 50]  [0.9957690089108517, 0.8858754404220945, 0.377...\n",
       "9    [50, 20, 10]  [0.9273406048935542, 0.8441608643791765, 0.337...\n",
       "10   [50, 20, 20]  [0.9943768632662783, 0.8965817652227551, 0.378...\n",
       "11   [50, 20, 50]  [0.9953838288872936, 0.8824564623749559, 0.378...\n",
       "12   [100, 5, 10]  [0.9095321959402396, 0.8369373691247741, 0.290...\n",
       "13   [100, 5, 20]  [0.9955869788613958, 0.8829029385667058, 0.349...\n",
       "14   [100, 5, 50]  [0.9956759404301776, 0.8827702579464252, 0.346...\n",
       "15  [100, 10, 10]  [0.9211566687787179, 0.8475384835640011, 0.251...\n",
       "16  [100, 10, 20]  [0.9950345656088224, 0.8869490152470332, 0.394...\n",
       "17  [100, 10, 50]  [0.9954170527340205, 0.9012589333086674, 0.385...\n",
       "18  [100, 15, 10]  [0.9254971433547462, 0.8530294828035283, 0.291...\n",
       "19  [100, 15, 20]  [0.9955172772469305, 0.8872619344257098, 0.389...\n",
       "20  [100, 15, 50]  [0.9955499399643959, 0.8903762827481211, 0.381...\n",
       "21  [100, 20, 10]  [0.9270909163898603, 0.8629764509098641, 0.325...\n",
       "22  [100, 20, 20]  [0.99539271478092, 0.8850316045667016, 0.37877...\n",
       "23  [100, 20, 50]  [0.9960149011556325, 0.8807985633094082, 0.360...\n",
       "24   [150, 5, 10]  [0.9090872779113125, 0.8275186966306558, 0.274...\n",
       "25   [150, 5, 20]  [0.9950657647647867, 0.8776063574021638, 0.368...\n",
       "26   [150, 5, 50]  [0.9958887195990747, 0.8876998234970854, 0.361...\n",
       "27  [150, 10, 10]  [0.9148299856082469, 0.8383882357582386, 0.260...\n",
       "28  [150, 10, 20]  [0.9958341767766775, 0.8919536679067217, 0.388...\n",
       "29  [150, 10, 50]  [0.9961022744336274, 0.8861675320080271, 0.394...\n",
       "30  [150, 15, 10]  [0.9267898120812612, 0.8359484899156004, 0.339...\n",
       "31  [150, 15, 20]  [0.9949494121528979, 0.8858487208660607, 0.378...\n",
       "32  [150, 15, 50]  [0.9955323250665927, 0.8979818451601279, 0.388...\n",
       "33  [150, 20, 10]  [0.9331035297794488, 0.8565567119509243, 0.363...\n",
       "34  [150, 20, 20]  [0.9955608225736279, 0.8941653680931877, 0.382...\n",
       "35  [150, 20, 50]  [0.9950624614197245, 0.8847889849783739, 0.375..."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output30 = pd.DataFrame({'params':params, 'fdr':fdr_mean})\n",
    "output30_alliter = pd.DataFrame(fdr_all[0],columns=[str(params[0])+': train', 'test', 'oot'])\n",
    "for i in range(1,len(fdr_all)):\n",
    "    output30_alliter = pd.concat([output30_alliter, pd.DataFrame(fdr_all[i],columns=[str(params[i])+': train', 'test', 'oot'])], axis=1)\n",
    "output30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[50, 5, 10]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[50, 5, 20]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[50, 5, 50]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[50, 10, 10]: train</th>\n",
       "      <th>...</th>\n",
       "      <th>oot</th>\n",
       "      <th>[150, 20, 10]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[150, 20, 20]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[150, 20, 50]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892188</td>\n",
       "      <td>0.837719</td>\n",
       "      <td>0.256983</td>\n",
       "      <td>0.993701</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.866337</td>\n",
       "      <td>0.324022</td>\n",
       "      <td>0.911315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379888</td>\n",
       "      <td>0.943307</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.374302</td>\n",
       "      <td>0.996918</td>\n",
       "      <td>0.881279</td>\n",
       "      <td>0.430168</td>\n",
       "      <td>0.993808</td>\n",
       "      <td>0.887387</td>\n",
       "      <td>0.402235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.906203</td>\n",
       "      <td>0.830918</td>\n",
       "      <td>0.268156</td>\n",
       "      <td>0.993985</td>\n",
       "      <td>0.886700</td>\n",
       "      <td>0.418994</td>\n",
       "      <td>0.995434</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>0.911677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340782</td>\n",
       "      <td>0.928013</td>\n",
       "      <td>0.868996</td>\n",
       "      <td>0.312849</td>\n",
       "      <td>0.993921</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.368715</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.899123</td>\n",
       "      <td>0.407821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.862928</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.256983</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.899160</td>\n",
       "      <td>0.262570</td>\n",
       "      <td>0.919818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.995468</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.357542</td>\n",
       "      <td>0.993856</td>\n",
       "      <td>0.861751</td>\n",
       "      <td>0.379888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.910494</td>\n",
       "      <td>0.859091</td>\n",
       "      <td>0.245810</td>\n",
       "      <td>0.995327</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>0.379888</td>\n",
       "      <td>0.995413</td>\n",
       "      <td>0.920561</td>\n",
       "      <td>0.374302</td>\n",
       "      <td>0.906805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351955</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>0.853774</td>\n",
       "      <td>0.296089</td>\n",
       "      <td>0.993994</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.413408</td>\n",
       "      <td>0.993874</td>\n",
       "      <td>0.920930</td>\n",
       "      <td>0.368715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.889058</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.223464</td>\n",
       "      <td>0.993837</td>\n",
       "      <td>0.908676</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.996979</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.312849</td>\n",
       "      <td>0.915280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.933744</td>\n",
       "      <td>0.885845</td>\n",
       "      <td>0.324022</td>\n",
       "      <td>0.998442</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.418994</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>0.884793</td>\n",
       "      <td>0.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.914504</td>\n",
       "      <td>0.826291</td>\n",
       "      <td>0.251397</td>\n",
       "      <td>0.993912</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.995461</td>\n",
       "      <td>0.874396</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.933227</td>\n",
       "      <td>0.857741</td>\n",
       "      <td>0.357542</td>\n",
       "      <td>0.995482</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.368715</td>\n",
       "      <td>0.996937</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.357542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.890555</td>\n",
       "      <td>0.815920</td>\n",
       "      <td>0.290503</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.879808</td>\n",
       "      <td>0.251397</td>\n",
       "      <td>0.993912</td>\n",
       "      <td>0.914692</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.930663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379888</td>\n",
       "      <td>0.940909</td>\n",
       "      <td>0.822115</td>\n",
       "      <td>0.402235</td>\n",
       "      <td>0.995399</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.363128</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>0.351955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.897991</td>\n",
       "      <td>0.855204</td>\n",
       "      <td>0.262570</td>\n",
       "      <td>0.995509</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.268156</td>\n",
       "      <td>0.995468</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.418994</td>\n",
       "      <td>0.920188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418994</td>\n",
       "      <td>0.925984</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.993837</td>\n",
       "      <td>0.926941</td>\n",
       "      <td>0.351955</td>\n",
       "      <td>0.995406</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.357542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.915902</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.268156</td>\n",
       "      <td>0.996965</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.262570</td>\n",
       "      <td>0.995413</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.413408</td>\n",
       "      <td>0.902669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413408</td>\n",
       "      <td>0.925581</td>\n",
       "      <td>0.874439</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>0.891403</td>\n",
       "      <td>0.363128</td>\n",
       "      <td>0.993808</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.357542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.895706</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.307263</td>\n",
       "      <td>0.995448</td>\n",
       "      <td>0.875598</td>\n",
       "      <td>0.312849</td>\n",
       "      <td>0.996960</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363128</td>\n",
       "      <td>0.926718</td>\n",
       "      <td>0.882629</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.894958</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>0.995349</td>\n",
       "      <td>0.892377</td>\n",
       "      <td>0.346369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   [50, 5, 10]: train      test       oot  [50, 5, 20]: train      test  \\\n",
       "0            0.892188  0.837719  0.256983            0.993701  0.866953   \n",
       "1            0.906203  0.830918  0.268156            0.993985  0.886700   \n",
       "2            0.862928  0.831858  0.256983            0.993865  0.893519   \n",
       "3            0.910494  0.859091  0.245810            0.995327  0.884956   \n",
       "4            0.889058  0.819048  0.223464            0.993837  0.908676   \n",
       "5            0.914504  0.826291  0.251397            0.993912  0.895735   \n",
       "6            0.890555  0.815920  0.290503            0.993939  0.879808   \n",
       "7            0.897991  0.855204  0.262570            0.995509  0.860000   \n",
       "8            0.915902  0.803738  0.268156            0.996965  0.880383   \n",
       "9            0.895706  0.814815  0.307263            0.995448  0.875598   \n",
       "\n",
       "        oot  [50, 5, 50]: train      test       oot  [50, 10, 10]: train  ...  \\\n",
       "0  0.346369            0.996997  0.866337  0.324022             0.911315  ...   \n",
       "1  0.418994            0.995434  0.895735  0.346369             0.911677  ...   \n",
       "2  0.391061            0.995238  0.899160  0.262570             0.919818  ...   \n",
       "3  0.379888            0.995413  0.920561  0.374302             0.906805  ...   \n",
       "4  0.396648            0.996979  0.883495  0.312849             0.915280  ...   \n",
       "5  0.391061            0.995461  0.874396  0.391061             0.933962  ...   \n",
       "6  0.251397            0.993912  0.914692  0.424581             0.930663  ...   \n",
       "7  0.268156            0.995468  0.902913  0.418994             0.920188  ...   \n",
       "8  0.262570            0.995413  0.869159  0.413408             0.902669  ...   \n",
       "9  0.312849            0.996960  0.852381  0.396648             0.923913  ...   \n",
       "\n",
       "        oot  [150, 20, 10]: train      test       oot  [150, 20, 20]: train  \\\n",
       "0  0.379888              0.943307  0.828326  0.374302              0.996918   \n",
       "1  0.340782              0.928013  0.868996  0.312849              0.993921   \n",
       "2  0.424581              0.940625  0.833333  0.391061              0.995468   \n",
       "3  0.351955              0.932927  0.853774  0.296089              0.993994   \n",
       "4  0.391061              0.933744  0.885845  0.324022              0.998442   \n",
       "5  0.424581              0.933227  0.857741  0.357542              0.995482   \n",
       "6  0.379888              0.940909  0.822115  0.402235              0.995399   \n",
       "7  0.418994              0.925984  0.858369  0.396648              0.993837   \n",
       "8  0.413408              0.925581  0.874439  0.391061              0.996909   \n",
       "9  0.363128              0.926718  0.882629  0.391061              0.995238   \n",
       "\n",
       "       test       oot  [150, 20, 50]: train      test       oot  \n",
       "0  0.881279  0.430168              0.993808  0.887387  0.402235  \n",
       "1  0.895238  0.368715              0.993750  0.899123  0.407821  \n",
       "2  0.902913  0.357542              0.993856  0.861751  0.379888  \n",
       "3  0.891089  0.413408              0.993874  0.920930  0.368715  \n",
       "4  0.867257  0.418994              0.996928  0.884793  0.430168  \n",
       "5  0.897059  0.368715              0.996937  0.906977  0.357542  \n",
       "6  0.893519  0.363128              0.996909  0.837104  0.351955  \n",
       "7  0.926941  0.351955              0.995406  0.879070  0.357542  \n",
       "8  0.891403  0.363128              0.993808  0.878378  0.357542  \n",
       "9  0.894958  0.385475              0.995349  0.892377  0.346369  \n",
       "\n",
       "[10 rows x 108 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output30_alliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "output30.to_csv('rf_30vars_mean.csv')\n",
    "output30_alliter.to_csv('rf_30vars_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to change nodes\n",
    "\n",
    "nn_df = pd.DataFrame(columns=['TRAIN', 'TEST', 'OOT'])\n",
    "\n",
    "def neuralnet(X, X_oot, y, y_oot, epoch, hidden_layer_sizes, iterations=10):\n",
    "    kf = KFold(n_splits=4, shuffle=True)\n",
    "    nn = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes, max_iter = epoch)\n",
    "    \n",
    "    nnfdr_df = []\n",
    "    nnfdr_total=[0,0,0] # train, test, oot    \n",
    "    for i in range(iterations):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y) # using default setting for test_size(0.25), random_state(None) and shuffle(True)\n",
    "        nn.fit(X_train, y_train)\n",
    "        \n",
    "        data = [[X_train, y_train], [X_test, y_test], [X_oot, y_oot]]\n",
    "        nnfdr_list=[]\n",
    "        for d in range(len(data)):\n",
    "            predict = nn.predict(data[d][0])\n",
    "            prob = nn.predict_proba(data[d][0])\n",
    "            fraudscore = prob.transpose()[1]\n",
    "            nnfdr_each = calculateFDR(predict, fraudscore, data[d][1])\n",
    "            nnfdr_total[d] += nnfdr_each\n",
    "            nnfdr_list.append(nnfdr_each)\n",
    "        nnfdr_df.append(nnfdr_list)\n",
    "        \n",
    "    avg_train = nnfdr_total[0] / iterations\n",
    "    avg_test = nnfdr_total[1] / iterations\n",
    "    avg_oot = nnfdr_total[2] / iterations\n",
    "    result = [avg_train, avg_test, avg_oot]\n",
    "    \n",
    "    return nnfdr_df, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 40 nodes: done\n",
      "epochs: 50, nodes: 40 with fdr 0.7528645140462369 on the test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#trying to change nodes\n",
    "\n",
    "# Adjusting epochs\n",
    "epoch = [i for i in range(0,51,10) if i!=0]\n",
    "nodes = [10,20,30,40]\n",
    "\n",
    "maximum = 0\n",
    "params = []\n",
    "nnfdr_all = []\n",
    "nnfdr_mean = []\n",
    "\n",
    "for i in epoch:\n",
    "    for j in nodes:\n",
    "            temp1, temp2 = neuralnet(X, X_oot, y, y_oot, epoch=i, hidden_layer_sizes=(j,), iterations=10) # optimizing on test data\n",
    "            params.append([i,j])\n",
    "            nnfdr_mean.append(temp2)\n",
    "            nnfdr_all.append(temp1)\n",
    "            if maximum < temp2[1]:\n",
    "                maximum = temp2[1]\n",
    "                maxfdr=temp2\n",
    "                maxparams = [i,j]\n",
    "            print(f'model {i} epochs, {j} nodes: done')\n",
    "                  \n",
    "print(f'epochs: {maxparams[0]}, nodes: {maxparams[1]} with fdr {maximum} on the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM244ff2c1e6c54dca99b903dd316ed75e\n"
     ]
    }
   ],
   "source": [
    "sendSignaltoChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoutput30 = pd.DataFrame({'params':params, 'fdr':nnfdr_mean})\n",
    "nnoutput30_alliter = pd.DataFrame(nnfdr_all[0],columns=[str(params[0])+': train', 'test', 'oot'])\n",
    "for i in range(1,len(nnfdr_all)):\n",
    "    nnoutput30_alliter = pd.concat([nnoutput30_alliter, pd.DataFrame(nnfdr_all[i],columns=[str(params[i])+': train', 'test', 'oot'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[0.6427102426825326, 0.6307380113655847, 0.341...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10, 20]</td>\n",
       "      <td>[0.6655166386720852, 0.6325638569185096, 0.379...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10, 30]</td>\n",
       "      <td>[0.6793399434936884, 0.6592867378820783, 0.387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[10, 40]</td>\n",
       "      <td>[0.6896676263819879, 0.6528271881307847, 0.423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20, 10]</td>\n",
       "      <td>[0.6807637501678493, 0.6462140061114022, 0.373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[0.7002534137882411, 0.6851038265026592, 0.405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[20, 30]</td>\n",
       "      <td>[0.7249488993729234, 0.687030879386914, 0.4720...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[20, 40]</td>\n",
       "      <td>[0.7229779249152876, 0.6995465514036934, 0.475...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[30, 10]</td>\n",
       "      <td>[0.6854432151365185, 0.6751609652485083, 0.384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[30, 20]</td>\n",
       "      <td>[0.725672857721982, 0.6963657862246343, 0.4268...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[30, 30]</td>\n",
       "      <td>[0.7464935237908243, 0.7169218708584403, 0.469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[30, 40]</td>\n",
       "      <td>[0.7633755545418694, 0.7235544372775501, 0.488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[40, 10]</td>\n",
       "      <td>[0.7070874814108616, 0.6795038914919557, 0.406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[40, 20]</td>\n",
       "      <td>[0.7414556891952025, 0.7201305408924086, 0.474...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[40, 30]</td>\n",
       "      <td>[0.7633591163227677, 0.7279964362279834, 0.507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>[0.7911368001876656, 0.7335716178374103, 0.505...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[50, 10]</td>\n",
       "      <td>[0.729260431064724, 0.6777323371571201, 0.4675...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[50, 20]</td>\n",
       "      <td>[0.7637180563252507, 0.7178389974623328, 0.473...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[50, 30]</td>\n",
       "      <td>[0.7834239260741481, 0.7473036862564291, 0.484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[50, 40]</td>\n",
       "      <td>[0.7864425247015231, 0.7528645140462369, 0.509...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      params                                                fdr\n",
       "0   [10, 10]  [0.6427102426825326, 0.6307380113655847, 0.341...\n",
       "1   [10, 20]  [0.6655166386720852, 0.6325638569185096, 0.379...\n",
       "2   [10, 30]  [0.6793399434936884, 0.6592867378820783, 0.387...\n",
       "3   [10, 40]  [0.6896676263819879, 0.6528271881307847, 0.423...\n",
       "4   [20, 10]  [0.6807637501678493, 0.6462140061114022, 0.373...\n",
       "5   [20, 20]  [0.7002534137882411, 0.6851038265026592, 0.405...\n",
       "6   [20, 30]  [0.7249488993729234, 0.687030879386914, 0.4720...\n",
       "7   [20, 40]  [0.7229779249152876, 0.6995465514036934, 0.475...\n",
       "8   [30, 10]  [0.6854432151365185, 0.6751609652485083, 0.384...\n",
       "9   [30, 20]  [0.725672857721982, 0.6963657862246343, 0.4268...\n",
       "10  [30, 30]  [0.7464935237908243, 0.7169218708584403, 0.469...\n",
       "11  [30, 40]  [0.7633755545418694, 0.7235544372775501, 0.488...\n",
       "12  [40, 10]  [0.7070874814108616, 0.6795038914919557, 0.406...\n",
       "13  [40, 20]  [0.7414556891952025, 0.7201305408924086, 0.474...\n",
       "14  [40, 30]  [0.7633591163227677, 0.7279964362279834, 0.507...\n",
       "15  [40, 40]  [0.7911368001876656, 0.7335716178374103, 0.505...\n",
       "16  [50, 10]  [0.729260431064724, 0.6777323371571201, 0.4675...\n",
       "17  [50, 20]  [0.7637180563252507, 0.7178389974623328, 0.473...\n",
       "18  [50, 30]  [0.7834239260741481, 0.7473036862564291, 0.484...\n",
       "19  [50, 40]  [0.7864425247015231, 0.7528645140462369, 0.509..."
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnoutput30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[10, 10]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[10, 20]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[10, 30]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[10, 40]: train</th>\n",
       "      <th>...</th>\n",
       "      <th>oot</th>\n",
       "      <th>[50, 20]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[50, 30]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "      <th>[50, 40]: train</th>\n",
       "      <th>test</th>\n",
       "      <th>oot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.658055</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.318436</td>\n",
       "      <td>0.667180</td>\n",
       "      <td>0.639269</td>\n",
       "      <td>0.312849</td>\n",
       "      <td>0.684129</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.318436</td>\n",
       "      <td>0.714919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525140</td>\n",
       "      <td>0.747734</td>\n",
       "      <td>0.703883</td>\n",
       "      <td>0.530726</td>\n",
       "      <td>0.790447</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>0.792647</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.486034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673375</td>\n",
       "      <td>0.639640</td>\n",
       "      <td>0.374302</td>\n",
       "      <td>0.691729</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.284916</td>\n",
       "      <td>0.685670</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.374302</td>\n",
       "      <td>0.694228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374302</td>\n",
       "      <td>0.772939</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.508380</td>\n",
       "      <td>0.787136</td>\n",
       "      <td>0.716279</td>\n",
       "      <td>0.513966</td>\n",
       "      <td>0.785824</td>\n",
       "      <td>0.762557</td>\n",
       "      <td>0.480447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.290503</td>\n",
       "      <td>0.641593</td>\n",
       "      <td>0.678947</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.663093</td>\n",
       "      <td>0.646512</td>\n",
       "      <td>0.435754</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.725225</td>\n",
       "      <td>0.508380</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.530726</td>\n",
       "      <td>0.799378</td>\n",
       "      <td>0.768889</td>\n",
       "      <td>0.491620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.590090</td>\n",
       "      <td>0.368715</td>\n",
       "      <td>0.679878</td>\n",
       "      <td>0.636792</td>\n",
       "      <td>0.374302</td>\n",
       "      <td>0.695719</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.357542</td>\n",
       "      <td>0.679811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.519553</td>\n",
       "      <td>0.754224</td>\n",
       "      <td>0.751152</td>\n",
       "      <td>0.446927</td>\n",
       "      <td>0.770468</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.513966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.640909</td>\n",
       "      <td>0.340782</td>\n",
       "      <td>0.682515</td>\n",
       "      <td>0.634259</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.685325</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.452514</td>\n",
       "      <td>0.694864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.777434</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.775542</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.799373</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.480447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.674961</td>\n",
       "      <td>0.635556</td>\n",
       "      <td>0.335196</td>\n",
       "      <td>0.654709</td>\n",
       "      <td>0.643216</td>\n",
       "      <td>0.357542</td>\n",
       "      <td>0.671340</td>\n",
       "      <td>0.676991</td>\n",
       "      <td>0.351955</td>\n",
       "      <td>0.704160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>0.787970</td>\n",
       "      <td>0.699507</td>\n",
       "      <td>0.480447</td>\n",
       "      <td>0.772586</td>\n",
       "      <td>0.716814</td>\n",
       "      <td>0.497207</td>\n",
       "      <td>0.762791</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.519553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.588872</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.318436</td>\n",
       "      <td>0.644377</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.474860</td>\n",
       "      <td>0.672840</td>\n",
       "      <td>0.668182</td>\n",
       "      <td>0.385475</td>\n",
       "      <td>0.667660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458101</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.668182</td>\n",
       "      <td>0.290503</td>\n",
       "      <td>0.820433</td>\n",
       "      <td>0.725225</td>\n",
       "      <td>0.502793</td>\n",
       "      <td>0.786708</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.569832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.608828</td>\n",
       "      <td>0.620853</td>\n",
       "      <td>0.290503</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.587719</td>\n",
       "      <td>0.312849</td>\n",
       "      <td>0.658879</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.763720</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.407821</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>0.722488</td>\n",
       "      <td>0.458101</td>\n",
       "      <td>0.778287</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.513966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.662058</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.279330</td>\n",
       "      <td>0.665644</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.689382</td>\n",
       "      <td>0.611814</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.687011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435754</td>\n",
       "      <td>0.770865</td>\n",
       "      <td>0.746411</td>\n",
       "      <td>0.497207</td>\n",
       "      <td>0.775449</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.536313</td>\n",
       "      <td>0.781931</td>\n",
       "      <td>0.743363</td>\n",
       "      <td>0.491620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.616418</td>\n",
       "      <td>0.646465</td>\n",
       "      <td>0.502793</td>\n",
       "      <td>0.686916</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.402235</td>\n",
       "      <td>0.687023</td>\n",
       "      <td>0.671362</td>\n",
       "      <td>0.402235</td>\n",
       "      <td>0.673567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469274</td>\n",
       "      <td>0.760060</td>\n",
       "      <td>0.736041</td>\n",
       "      <td>0.452514</td>\n",
       "      <td>0.784522</td>\n",
       "      <td>0.765550</td>\n",
       "      <td>0.324022</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.717842</td>\n",
       "      <td>0.547486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   [10, 10]: train      test       oot  [10, 20]: train      test       oot  \\\n",
       "0         0.658055  0.604762  0.318436         0.667180  0.639269  0.312849   \n",
       "1         0.673375  0.639640  0.374302         0.691729  0.620690  0.284916   \n",
       "2         0.653963  0.669811  0.290503         0.641593  0.678947  0.441341   \n",
       "3         0.645511  0.590090  0.368715         0.679878  0.636792  0.374302   \n",
       "4         0.645062  0.640909  0.340782         0.682515  0.634259  0.391061   \n",
       "5         0.674961  0.635556  0.335196         0.654709  0.643216  0.357542   \n",
       "6         0.588872  0.683258  0.318436         0.644377  0.642857  0.474860   \n",
       "7         0.608828  0.620853  0.290503         0.640625  0.587719  0.312849   \n",
       "8         0.662058  0.576037  0.279330         0.665644  0.666667  0.441341   \n",
       "9         0.616418  0.646465  0.502793         0.686916  0.575221  0.402235   \n",
       "\n",
       "   [10, 30]: train      test       oot  [10, 40]: train  ...       oot  \\\n",
       "0         0.684129  0.671233  0.318436         0.714919  ...  0.525140   \n",
       "1         0.685670  0.657534  0.374302         0.694228  ...  0.374302   \n",
       "2         0.663093  0.646512  0.435754         0.689548  ...  0.441341   \n",
       "3         0.695719  0.635514  0.357542         0.679811  ...  0.396648   \n",
       "4         0.685325  0.681159  0.452514         0.694864  ...  0.541899   \n",
       "5         0.671340  0.676991  0.351955         0.704160  ...  0.491620   \n",
       "6         0.672840  0.668182  0.385475         0.667660  ...  0.458101   \n",
       "7         0.658879  0.672566  0.396648         0.690909  ...  0.541899   \n",
       "8         0.689382  0.611814  0.396648         0.687011  ...  0.435754   \n",
       "9         0.687023  0.671362  0.402235         0.673567  ...  0.469274   \n",
       "\n",
       "   [50, 20]: train      test       oot  [50, 30]: train      test       oot  \\\n",
       "0         0.747734  0.703883  0.530726         0.790447  0.776256  0.491620   \n",
       "1         0.772939  0.688889  0.508380         0.787136  0.716279  0.513966   \n",
       "2         0.760062  0.725225  0.508380         0.800000  0.788462  0.530726   \n",
       "3         0.755656  0.756098  0.519553         0.754224  0.751152  0.446927   \n",
       "4         0.777434  0.746606  0.541899         0.775542  0.810811  0.541899   \n",
       "5         0.787970  0.699507  0.480447         0.772586  0.716814  0.497207   \n",
       "6         0.740741  0.668182  0.290503         0.820433  0.725225  0.502793   \n",
       "7         0.763720  0.707547  0.407821         0.773900  0.722488  0.458101   \n",
       "8         0.770865  0.746411  0.497207         0.775449  0.700000  0.536313   \n",
       "9         0.760060  0.736041  0.452514         0.784522  0.765550  0.324022   \n",
       "\n",
       "   [50, 40]: train      test       oot  \n",
       "0         0.792647  0.755319  0.486034  \n",
       "1         0.785824  0.762557  0.480447  \n",
       "2         0.799378  0.768889  0.491620  \n",
       "3         0.770468  0.717391  0.513966  \n",
       "4         0.799373  0.760870  0.480447  \n",
       "5         0.762791  0.798206  0.519553  \n",
       "6         0.786708  0.728507  0.569832  \n",
       "7         0.778287  0.775701  0.513966  \n",
       "8         0.781931  0.743363  0.491620  \n",
       "9         0.807018  0.717842  0.547486  \n",
       "\n",
       "[10 rows x 60 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnoutput30_alliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoutput30.to_csv('nn_30vars_mean.csv')\n",
    "nnoutput30_alliter.to_csv('nn_30vars_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing test size to .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforestFDR2(X, X_oot, y, y_oot, iteration=10, n_estimators=50, max_features=10, max_depth=20):\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth)\n",
    "    \n",
    "    fdr_df=[]\n",
    "    fdr_total=[0,0,0]\n",
    "    for i in range(iteration):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.3) # using default setting for random_state(None) and shuffle(True)\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        data = [[X_train, y_train], [X_test, y_test], [X_oot, y_oot]]\n",
    "        fdr_list=[]\n",
    "        for d in range(len(data)):\n",
    "            predict = rf.predict(data[d][0])\n",
    "            prob = rf.predict_proba(data[d][0])\n",
    "            fraudscore = prob.transpose()[1]\n",
    "            fdr_each = calculateFDR(predict, fraudscore, data[d][1])\n",
    "            fdr_total[d] += fdr_each\n",
    "            fdr_list.append(fdr_each)\n",
    "        \n",
    "        fdr_df.append(fdr_list)\n",
    "    \n",
    "    avg_train = fdr_total[0] / iteration\n",
    "    avg_test = fdr_total[1] / iteration\n",
    "    avg_oot = fdr_total[2] / iteration\n",
    "    result = [avg_train, avg_test, avg_oot]\n",
    "\n",
    "    return fdr_df, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 100, max_features: 20, max_depth: 20 with fdr: 0.896702318976527 on the test data\n"
     ]
    }
   ],
   "source": [
    "# Adjusting hyperparameters\n",
    "tree = [50,100,150] # towarddatascience guide: 200~2000\n",
    "features = [5,10,15,20] # should be less than number of variables (original choice: [5,10,15,20])\n",
    "depth = [10,20,50] # towarddatascience guide: 10~110 (original choice: [10,20,50,100])\n",
    "\n",
    "maximum = 0\n",
    "params=[]\n",
    "fdr_all=[]\n",
    "fdr_mean=[]\n",
    "for i in tree:\n",
    "    for j in features:\n",
    "        for k in depth:\n",
    "            temp1, temp2 = randomforestFDR2(X, X_oot, y, y_oot, iteration=10, n_estimators=i, max_features=j, max_depth=k) # optimizing on test data\n",
    "            params.append([i,j,k])\n",
    "            fdr_mean.append(temp2)\n",
    "            fdr_all.append(temp1)\n",
    "            if maximum < temp2[1]:\n",
    "                maximum=temp2[1]\n",
    "                maxfdr=temp2\n",
    "                maxparams=[i,j,k]\n",
    "                \n",
    "print(f'n_estimators: {maxparams[0]}, max_features: {maxparams[1]}, max_depth: {maxparams[2]} with fdr: {maximum} on the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM3e3451ad1def440185ad1e86a0052c62\n"
     ]
    }
   ],
   "source": [
    "sendSignaltoChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "output30 = pd.DataFrame({'params':params, 'fdr':fdr_mean})\n",
    "output30_alliter = pd.DataFrame(fdr_all[0],columns=[str(params[0])+': train', 'test', 'oot'])\n",
    "for i in range(1,len(fdr_all)):\n",
    "    output30_alliter = pd.concat([output30_alliter, pd.DataFrame(fdr_all[i],columns=[str(params[i])+': train', 'test', 'oot'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "output30.to_csv('rf_30vars_mean2.csv')\n",
    "output30_alliter.to_csv('rf_30vars_all2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to change nodes\n",
    "\n",
    "nn_df = pd.DataFrame(columns=['TRAIN', 'TEST', 'OOT'])\n",
    "\n",
    "def neuralnet2(X, X_oot, y, y_oot, epoch, hidden_layer_sizes, iterations=10):\n",
    "    kf = KFold(n_splits=4, shuffle=True)\n",
    "    nn = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes, max_iter = epoch)\n",
    "    \n",
    "    nnfdr_df = []\n",
    "    nnfdr_total=[0,0,0] # train, test, oot    \n",
    "    for i in range(iterations):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3) # using default setting for random_state(None) and shuffle(True)\n",
    "        nn.fit(X_train, y_train)\n",
    "        \n",
    "        data = [[X_train, y_train], [X_test, y_test], [X_oot, y_oot]]\n",
    "        nnfdr_list=[]\n",
    "        for d in range(len(data)):\n",
    "            predict = nn.predict(data[d][0])\n",
    "            prob = nn.predict_proba(data[d][0])\n",
    "            fraudscore = prob.transpose()[1]\n",
    "            nnfdr_each = calculateFDR(predict, fraudscore, data[d][1])\n",
    "            nnfdr_total[d] += nnfdr_each\n",
    "            nnfdr_list.append(nnfdr_each)\n",
    "        nnfdr_df.append(nnfdr_list)\n",
    "        \n",
    "    avg_train = nnfdr_total[0] / iterations\n",
    "    avg_test = nnfdr_total[1] / iterations\n",
    "    avg_oot = nnfdr_total[2] / iterations\n",
    "    result = [avg_train, avg_test, avg_oot]\n",
    "    \n",
    "    return nnfdr_df, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 40 nodes: done\n",
      "epochs: 50, nodes: 40 with fdr 0.7520209286125155 on the test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#trying to change nodes\n",
    "\n",
    "# Adjusting epochs\n",
    "epoch = [i for i in range(0,51,10) if i!=0]\n",
    "nodes = [10,20,30,40]\n",
    "\n",
    "maximum = 0\n",
    "params = []\n",
    "nnfdr_all = []\n",
    "nnfdr_mean = []\n",
    "\n",
    "for i in epoch:\n",
    "    for j in nodes:\n",
    "            temp1, temp2 = neuralnet2(X, X_oot, y, y_oot, epoch=i, hidden_layer_sizes=(j,), iterations=10) # optimizing on test data\n",
    "            params.append([i,j])\n",
    "            nnfdr_mean.append(temp2)\n",
    "            nnfdr_all.append(temp1)\n",
    "            if maximum < temp2[1]:\n",
    "                maximum = temp2[1]\n",
    "                maxfdr=temp2\n",
    "                maxparams = [i,j]\n",
    "            print(f'model {i} epochs, {j} nodes: done')\n",
    "                  \n",
    "print(f'epochs: {maxparams[0]}, nodes: {maxparams[1]} with fdr {maximum} on the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMc2f2ac635f134a4fbcb0f128b4622730\n"
     ]
    }
   ],
   "source": [
    "sendSignaltoChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoutput30 = pd.DataFrame({'params':params, 'fdr':nnfdr_mean})\n",
    "nnoutput30_alliter = pd.DataFrame(nnfdr_all[0],columns=[str(params[0])+': train', 'test', 'oot'])\n",
    "for i in range(1,len(nnfdr_all)):\n",
    "    nnoutput30_alliter = pd.concat([nnoutput30_alliter, pd.DataFrame(nnfdr_all[i],columns=[str(params[i])+': train', 'test', 'oot'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoutput30.to_csv('nn_30vars_mean2.csv')\n",
    "nnoutput30_alliter.to_csv('nn_30vars_all2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 vars, test size = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10vars = [\n",
    "'Cardnum_max_30',\n",
    "'card_merchant_max_30',\n",
    "'Merchnum_total_3',\n",
    "'Cardnum_total_130',\n",
    "'Merchnum_mean_7',\n",
    "'card_merchant_median_1',\n",
    "'Merchnum_mean_3',\n",
    "'Cardnum_mean_30',\n",
    "'card_merchant_mean_1',\n",
    "'card_state_mean_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_Xs = top10vars\n",
    "\n",
    "#oot df\n",
    "df_oot = df[df.Date>='2010-11-01'].copy()\n",
    "\n",
    "#x and y oot\n",
    "y_oot = df_oot['Fraud'].copy()\n",
    "X_oot = df_oot.copy().drop(columns='Fraud')\n",
    "\n",
    "#modeling data\n",
    "df_model = df[(df.Date>'2010-01-14')&(df.Date<'2010-11-01')].copy()\n",
    "\n",
    "# #x and y train\n",
    "y = df_model['Fraud'].copy()\n",
    "X = df_model.copy().drop(columns='Fraud')\n",
    "\n",
    "# #dropping date and record\n",
    "df_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "y_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "X_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "\n",
    "df_model.drop(columns=['Date','Recnum'], inplace=True)\n",
    "y.drop(columns=['Date','Recnum'], inplace=True)\n",
    "X.drop(columns=['Date','Recnum'], inplace=True)\n",
    "\n",
    "X_oot2 = X_oot[top10vars]\n",
    "X2 = X[top10vars]\n",
    "\n",
    "X_oot2 = StandardScaler().fit_transform(X_oot2)\n",
    "X2 = StandardScaler().fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 100, max_features: 5, max_depth: 50 with fdr: 0.8935677382272041 on the test data\n"
     ]
    }
   ],
   "source": [
    "# Adjusting hyperparameters\n",
    "tree = [50,100,150] # towarddatascience guide: 200~2000\n",
    "features = [5,10] # should be less than number of variables (original choice: [5,10,15,20])\n",
    "depth = [10,20,50] # towarddatascience guide: 10~110 (original choice: [10,20,50,100])\n",
    "\n",
    "maximum = 0\n",
    "params=[]\n",
    "fdr_all=[]\n",
    "fdr_mean=[]\n",
    "for i in tree:\n",
    "    for j in features:\n",
    "        for k in depth:\n",
    "            temp1, temp2 = randomforestFDR2(X2, X_oot2, y, y_oot, iteration=10, n_estimators=i, max_features=j, max_depth=k) # optimizing on test data\n",
    "            params.append([i,j,k])\n",
    "            fdr_mean.append(temp2)\n",
    "            fdr_all.append(temp1)\n",
    "            if maximum < temp2[1]:\n",
    "                maximum=temp2[1]\n",
    "                maxfdr=temp2\n",
    "                maxparams=[i,j,k]\n",
    "                \n",
    "print(f'n_estimators: {maxparams[0]}, max_features: {maxparams[1]}, max_depth: {maxparams[2]} with fdr: {maximum} on the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM1367575ccd5b48599194177bc8444c46\n"
     ]
    }
   ],
   "source": [
    "sendSignaltoChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "output10 = pd.DataFrame({'params':params, 'fdr':fdr_mean})\n",
    "output10_alliter = pd.DataFrame(fdr_all[0],columns=[str(params[0])+': train', 'test', 'oot'])\n",
    "for i in range(1,len(fdr_all)):\n",
    "    output10_alliter = pd.concat([output10_alliter, pd.DataFrame(fdr_all[i],columns=[str(params[i])+': train', 'test', 'oot'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "output10.to_csv('rf_10vars_mean2.csv')\n",
    "output10_alliter.to_csv('rf_10vars_all2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 40 nodes: done\n",
      "epochs: 50, nodes: 30 with fdr 0.6732726274820802 on the test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#trying to change nodes\n",
    "\n",
    "# Adjusting epochs\n",
    "epoch = [i for i in range(0,51,10) if i!=0]\n",
    "nodes = [10,20,30,40]\n",
    "\n",
    "maximum = 0\n",
    "params = []\n",
    "nnfdr_all = []\n",
    "nnfdr_mean = []\n",
    "\n",
    "for i in epoch:\n",
    "    for j in nodes:\n",
    "            temp1, temp2 = neuralnet2(X2, X_oot2, y, y_oot, epoch=i, hidden_layer_sizes=(j,), iterations=10) # optimizing on test data\n",
    "            params.append([i,j])\n",
    "            nnfdr_mean.append(temp2)\n",
    "            nnfdr_all.append(temp1)\n",
    "            if maximum < temp2[1]:\n",
    "                maximum = temp2[1]\n",
    "                maxfdr=temp2\n",
    "                maxparams = [i,j]\n",
    "            print(f'model {i} epochs, {j} nodes: done')\n",
    "                  \n",
    "print(f'epochs: {maxparams[0]}, nodes: {maxparams[1]} with fdr {maximum} on the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM598fd3ddf1c14fe6afb3f7e9c3f4d6dc\n"
     ]
    }
   ],
   "source": [
    "sendSignaltoChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoutput10 = pd.DataFrame({'params':params, 'fdr':nnfdr_mean})\n",
    "nnoutput10_alliter = pd.DataFrame(nnfdr_all[0],columns=[str(params[0])+': train', 'test', 'oot'])\n",
    "for i in range(1,len(nnfdr_all)):\n",
    "    nnoutput10_alliter = pd.concat([nnoutput10_alliter, pd.DataFrame(nnfdr_all[i],columns=[str(params[i])+': train', 'test', 'oot'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoutput10.to_csv('nn_10vars_mean2.csv')\n",
    "nnoutput10_alliter.to_csv('nn_10vars_all2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Vars, test size .3 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20vars = [\n",
    "    'Cardnum_max_30',\n",
    "'card_merchant_max_30',\n",
    "'Merchnum_total_3',\n",
    "'Cardnum_total_130',\n",
    "'Merchnum_mean_7',\n",
    "'card_merchant_median_1',\n",
    "'Merchnum_mean_3',\n",
    "'Cardnum_mean_30',\n",
    "'card_merchant_mean_1',\n",
    "'card_state_mean_30',\n",
    "'card_state_median_30',\n",
    "'card_zip_median_1',\n",
    "'card_state_mean_14',\n",
    "'Cardnum_max_14',\n",
    "'card_state_max_0',\n",
    "'Cardnum_total_30',\n",
    "'card_zip_mean_1',\n",
    "'card_state_median_14',\n",
    "'card_zip_max_14',\n",
    "'card_state_total_30'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_Xs = top10vars\n",
    "\n",
    "#oot df\n",
    "df_oot = df[df.Date>='2010-11-01'].copy()\n",
    "\n",
    "#x and y oot\n",
    "y_oot = df_oot['Fraud'].copy()\n",
    "X_oot = df_oot.copy().drop(columns='Fraud')\n",
    "\n",
    "#modeling data\n",
    "df_model = df[(df.Date>'2010-01-14')&(df.Date<'2010-11-01')].copy()\n",
    "\n",
    "# #x and y train\n",
    "y = df_model['Fraud'].copy()\n",
    "X = df_model.copy().drop(columns='Fraud')\n",
    "\n",
    "# #dropping date and record\n",
    "df_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "y_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "X_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "\n",
    "df_model.drop(columns=['Date','Recnum'], inplace=True)\n",
    "y.drop(columns=['Date','Recnum'], inplace=True)\n",
    "X.drop(columns=['Date','Recnum'], inplace=True)\n",
    "\n",
    "X_oot3 = X_oot[top20vars]\n",
    "X3 = X[top20vars]\n",
    "\n",
    "X_oot3 = StandardScaler().fit_transform(X_oot3)\n",
    "X3 = StandardScaler().fit_transform(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 150, max_features: 5, max_depth: 20 with fdr: 0.8919531789304077 on the test data\n"
     ]
    }
   ],
   "source": [
    "# Adjusting hyperparameters\n",
    "tree = [50,100,150] # towarddatascience guide: 200~2000\n",
    "features = [5,10] # should be less than number of variables (original choice: [5,10,15,20])\n",
    "depth = [10,20,50] # towarddatascience guide: 10~110 (original choice: [10,20,50,100])\n",
    "\n",
    "maximum = 0\n",
    "params=[]\n",
    "fdr_all=[]\n",
    "fdr_mean=[]\n",
    "for i in tree:\n",
    "    for j in features:\n",
    "        for k in depth:\n",
    "            temp1, temp2 = randomforestFDR2(X3, X_oot3, y, y_oot, iteration=10, n_estimators=i, max_features=j, max_depth=k) # optimizing on test data\n",
    "            params.append([i,j,k])\n",
    "            fdr_mean.append(temp2)\n",
    "            fdr_all.append(temp1)\n",
    "            if maximum < temp2[1]:\n",
    "                maximum=temp2[1]\n",
    "                maxfdr=temp2\n",
    "                maxparams=[i,j,k]\n",
    "                \n",
    "print(f'n_estimators: {maxparams[0]}, max_features: {maxparams[1]}, max_depth: {maxparams[2]} with fdr: {maximum} on the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM5b5645c47ee1476eb4f6ef35a29a3a08\n"
     ]
    }
   ],
   "source": [
    "sendSignaltoChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "output20 = pd.DataFrame({'params':params, 'fdr':fdr_mean})\n",
    "output20_alliter = pd.DataFrame(fdr_all[0],columns=[str(params[0])+': train', 'test', 'oot'])\n",
    "for i in range(1,len(fdr_all)):\n",
    "    output20_alliter = pd.concat([output20_alliter, pd.DataFrame(fdr_all[i],columns=[str(params[i])+': train', 'test', 'oot'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "output20.to_csv('rf_20vars_mean.csv')\n",
    "output20_alliter.to_csv('rf_20vars_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 10 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 20 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 30 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 40 epochs, 40 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 10 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 20 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 30 nodes: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 40 nodes: done\n",
      "epochs: 40, nodes: 40 with fdr 0.7400835810350529 on the test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#trying to change nodes\n",
    "\n",
    "# Adjusting epochs\n",
    "epoch = [i for i in range(0,51,10) if i!=0]\n",
    "nodes = [10,20,30,40]\n",
    "\n",
    "maximum = 0\n",
    "params = []\n",
    "nnfdr_all = []\n",
    "nnfdr_mean = []\n",
    "\n",
    "for i in epoch:\n",
    "    for j in nodes:\n",
    "            temp1, temp2 = neuralnet2(X3, X_oot3, y, y_oot, epoch=i, hidden_layer_sizes=(j,), iterations=10) # optimizing on test data\n",
    "            params.append([i,j])\n",
    "            nnfdr_mean.append(temp2)\n",
    "            nnfdr_all.append(temp1)\n",
    "            if maximum < temp2[1]:\n",
    "                maximum = temp2[1]\n",
    "                maxfdr=temp2\n",
    "                maxparams = [i,j]\n",
    "            print(f'model {i} epochs, {j} nodes: done')\n",
    "                  \n",
    "print(f'epochs: {maxparams[0]}, nodes: {maxparams[1]} with fdr {maximum} on the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM7d3a53f6c6f442bcba88a1895eab0e6a\n"
     ]
    }
   ],
   "source": [
    "sendSignaltoChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoutput20 = pd.DataFrame({'params':params, 'fdr':nnfdr_mean})\n",
    "nnoutput20_alliter = pd.DataFrame(nnfdr_all[0],columns=[str(params[0])+': train', 'test', 'oot'])\n",
    "for i in range(1,len(nnfdr_all)):\n",
    "    nnoutput20_alliter = pd.concat([nnoutput20_alliter, pd.DataFrame(nnfdr_all[i],columns=[str(params[i])+': train', 'test', 'oot'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoutput20.to_csv('nn_20vars_mean.csv')\n",
    "nnoutput20_alliter.to_csv('nn_20vars_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MLPClassifier in module sklearn.neural_network._multilayer_perceptron:\n",
      "\n",
      "class MLPClassifier(sklearn.base.ClassifierMixin, BaseMultilayerPerceptron)\n",
      " |  MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |  \n",
      " |  Multi-layer Perceptron classifier.\n",
      " |  \n",
      " |  This model optimizes the log-loss function using LBFGS or stochastic\n",
      " |  gradient descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : tuple, length = n_layers - 2, default=(100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      " |        by Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, default=0.0001\n",
      " |      L2 penalty (regularization term) parameter.\n",
      " |  \n",
      " |  batch_size : int, default='auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate at each\n",
      " |        time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when ``solver='sgd'``.\n",
      " |  \n",
      " |  learning_rate_init : double, default=0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : double, default=0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, default=200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, default=True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Determines random number generation for weights and bias\n",
      " |      initialization, train-test split if early stopping is used, and batch\n",
      " |      sampling when solver='sgd' or 'adam'.\n",
      " |      Pass an int for reproducible results across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
      " |      unless ``learning_rate`` is set to 'adaptive', convergence is\n",
      " |      considered to be reached and training stops.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  momentum : float, default=0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : bool, default=True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default=False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for\n",
      " |      ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
      " |      except in a multilabel setting.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True\n",
      " |  \n",
      " |  beta_1 : float, default=0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  beta_2 : float, default=0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  epsilon : float, default=1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'\n",
      " |  \n",
      " |  n_iter_no_change : int, default=10\n",
      " |      Maximum number of epochs to not meet ``tol`` improvement.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  max_fun : int, default=15000\n",
      " |      Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
      " |      The solver iterates until convergence (determined by 'tol'), number\n",
      " |      of iterations reaches max_iter, or this number of loss function calls.\n",
      " |      Note that number of loss function calls will be greater than or equal\n",
      " |      to the number of iterations for the `MLPClassifier`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
      " |      Class labels for each output.\n",
      " |  \n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  best_loss_ : float\n",
      " |      The minimum loss reached by the solver throughout fitting.\n",
      " |  \n",
      " |  loss_curve_ : list of shape (`n_iter_`,)\n",
      " |      The ith element in the list represents the loss at the ith iteration.\n",
      " |  \n",
      " |  t_ : int\n",
      " |      The number of training samples seen by the solver during fitting.\n",
      " |  \n",
      " |  coefs_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      The number of iterations the solver has ran.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : str\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.neural_network import MLPClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_classification(n_samples=100, random_state=1)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
      " |  ...                                                     random_state=1)\n",
      " |  >>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
      " |  >>> clf.predict_proba(X_test[:1])\n",
      " |  array([[0.038..., 0.961...]])\n",
      " |  >>> clf.predict(X_test[:5, :])\n",
      " |  array([1, 0, 1, 0, 1])\n",
      " |  >>> clf.score(X_test, y_test)\n",
      " |  0.8...\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPClassifier trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense numpy arrays or\n",
      " |  sparse scipy arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E.\n",
      " |      \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
      " |      (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
      " |      training deep feedforward neural networks.\" International Conference\n",
      " |      on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
      " |      performance on imagenet classification.\" arXiv preprint\n",
      " |      arXiv:1502.01852 (2015).\n",
      " |  \n",
      " |  Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
      " |      optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseMultilayerPerceptron\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_classes)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return the log of probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted log-probability of the sample for each class\n",
      " |          in the model, where classes are ordered as they are in\n",
      " |          `self.classes_`. Equivalent to log(predict_proba(X))\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in `self.classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  partial_fit\n",
      " |      Update the model with a single iteration over the given data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      classes : array of shape (n_classes,), default=None\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or sparse matrix of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 10 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 10 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 10 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 10 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 20 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 20 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 20 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 20 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 30 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 30 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 30 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 30 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 40 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 40 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 40 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 50 epochs, 40 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 10 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 10 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 10 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 10 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 20 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 20 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 20 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 20 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 30 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 30 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 30 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 30 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 40 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 40 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 40 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 60 epochs, 40 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 10 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 10 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 10 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 10 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 20 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 20 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 20 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 20 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 30 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 30 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 30 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 30 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 40 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 40 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 40 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (70) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 70 epochs, 40 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 10 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 10 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 10 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 10 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 20 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 20 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 20 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 20 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 30 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 30 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 30 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 30 nodes layer 1: done, 40 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 40 nodes layer 1: done, 10 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 40 nodes layer 1: done, 20 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 40 nodes layer 1: done, 30 nodes layer 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 80 epochs, 40 nodes layer 1: done, 40 nodes layer 2: done\n",
      "epochs: 60, nodes: 40 with fdr 0.8083836123986405 on the test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (80) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#trying to change nodes\n",
    "\n",
    "# Adjusting epochs\n",
    "epoch = [i for i in range(50,81,10) if i!=0]\n",
    "nodes = [10,20,30,40]\n",
    "\n",
    "maximum = 0\n",
    "params = []\n",
    "nnfdr_all = []\n",
    "nnfdr_mean = []\n",
    "\n",
    "for i in epoch:\n",
    "    for j in nodes:\n",
    "        for k in nodes:\n",
    "            temp1, temp2 = neuralnet2(X3, X_oot3, y, y_oot, epoch=i, hidden_layer_sizes=(j,k), iterations=10) # optimizing on test data\n",
    "            params.append([i,j,k])\n",
    "            nnfdr_mean.append(temp2)\n",
    "            nnfdr_all.append(temp1)\n",
    "            if maximum < temp2[1]:\n",
    "                maximum = temp2[1]\n",
    "                maxfdr=temp2\n",
    "                maxparams = [i,j]\n",
    "            print(f'model {i} epochs, {j} nodes layer 1: done, {k} nodes layer 2: done')\n",
    "                  \n",
    "print(f'epochs: {maxparams[0]}, nodes: {maxparams[1]} with fdr {maximum} on the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM301baa1801d040dd9a16dee995b7fff5\n"
     ]
    }
   ],
   "source": [
    "sendSignaltoChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[50, 10, 10]</td>\n",
       "      <td>[0.7529443632549934, 0.7273672305630278, 0.432...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[50, 10, 20]</td>\n",
       "      <td>[0.7721176301257977, 0.7200114224041692, 0.450...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[50, 10, 30]</td>\n",
       "      <td>[0.7674356856115441, 0.7348092183452464, 0.429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[50, 10, 40]</td>\n",
       "      <td>[0.7761651681898559, 0.720909447420843, 0.3966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[50, 20, 10]</td>\n",
       "      <td>[0.8020618405894556, 0.7504918291183136, 0.501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[50, 20, 20]</td>\n",
       "      <td>[0.8214685771315657, 0.7755914783323884, 0.510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[50, 20, 30]</td>\n",
       "      <td>[0.8294009322771864, 0.7736671765579604, 0.443...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[50, 20, 40]</td>\n",
       "      <td>[0.833057091861033, 0.7739286115095652, 0.4871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[50, 30, 10]</td>\n",
       "      <td>[0.8278809843566076, 0.7653133183131555, 0.509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[50, 30, 20]</td>\n",
       "      <td>[0.8416094700919172, 0.7824696833016842, 0.477...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[50, 30, 30]</td>\n",
       "      <td>[0.8515327282478967, 0.7909660021823365, 0.513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[50, 30, 40]</td>\n",
       "      <td>[0.8485913369823225, 0.7867768569554248, 0.450...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[50, 40, 10]</td>\n",
       "      <td>[0.8312496181153479, 0.786314094659908, 0.5189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[50, 40, 20]</td>\n",
       "      <td>[0.861179845814652, 0.7876054936448855, 0.4899...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[50, 40, 30]</td>\n",
       "      <td>[0.8599795732029282, 0.7989017778608017, 0.526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[50, 40, 40]</td>\n",
       "      <td>[0.8706422401437989, 0.7910920842508944, 0.469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[60, 10, 10]</td>\n",
       "      <td>[0.760877590011533, 0.7345007618684471, 0.4620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[60, 10, 20]</td>\n",
       "      <td>[0.7740074211153696, 0.7324496614723721, 0.437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[60, 10, 30]</td>\n",
       "      <td>[0.7911902432378767, 0.7404038314110827, 0.449...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[60, 10, 40]</td>\n",
       "      <td>[0.7902676400469633, 0.7516722159725702, 0.442...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[60, 20, 10]</td>\n",
       "      <td>[0.8108064011484709, 0.7693034167369309, 0.493...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[60, 20, 20]</td>\n",
       "      <td>[0.8221139504078628, 0.7739109883110928, 0.506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[60, 20, 30]</td>\n",
       "      <td>[0.8411769354693035, 0.7761334866931425, 0.461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[60, 20, 40]</td>\n",
       "      <td>[0.8502212519024172, 0.7643918508648191, 0.474...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[60, 30, 10]</td>\n",
       "      <td>[0.8370919213217658, 0.7889429315080168, 0.524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[60, 30, 20]</td>\n",
       "      <td>[0.8553968309004519, 0.7852505849027961, 0.512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[60, 30, 30]</td>\n",
       "      <td>[0.8627783273604459, 0.7712304532417524, 0.498...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[60, 30, 40]</td>\n",
       "      <td>[0.870321445327227, 0.7997964035409185, 0.4497...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[60, 40, 10]</td>\n",
       "      <td>[0.8518133588302181, 0.7947082396073145, 0.498...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[60, 40, 20]</td>\n",
       "      <td>[0.8589663672976882, 0.7963393876744644, 0.492...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[60, 40, 30]</td>\n",
       "      <td>[0.8753301491321173, 0.7770921798143682, 0.507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[60, 40, 40]</td>\n",
       "      <td>[0.8852458313863811, 0.8083836123986405, 0.474...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[70, 10, 10]</td>\n",
       "      <td>[0.7752325255774359, 0.7239991269419246, 0.472...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[70, 10, 20]</td>\n",
       "      <td>[0.7981774967455811, 0.7399601224818289, 0.440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[70, 10, 30]</td>\n",
       "      <td>[0.8098729107834888, 0.7484089090871697, 0.456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[70, 10, 40]</td>\n",
       "      <td>[0.8009991466558816, 0.7598021847617116, 0.428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[70, 20, 10]</td>\n",
       "      <td>[0.8251671765454687, 0.7682446512764856, 0.450...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[70, 20, 20]</td>\n",
       "      <td>[0.8399543199722862, 0.7845192859853803, 0.519...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[70, 20, 30]</td>\n",
       "      <td>[0.849048163669927, 0.7784870592490356, 0.5078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[70, 20, 40]</td>\n",
       "      <td>[0.8527267243244496, 0.7857914552189972, 0.458...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[70, 30, 10]</td>\n",
       "      <td>[0.8459519796480193, 0.7728798853981862, 0.517...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[70, 30, 20]</td>\n",
       "      <td>[0.8528537964975736, 0.7894780440773831, 0.496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[70, 30, 30]</td>\n",
       "      <td>[0.8744645387307732, 0.7945048761762807, 0.498...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[70, 30, 40]</td>\n",
       "      <td>[0.874021540082842, 0.7998048862556527, 0.4698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[70, 40, 10]</td>\n",
       "      <td>[0.861887191869633, 0.7759848600735249, 0.4905...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[70, 40, 20]</td>\n",
       "      <td>[0.8806226095740766, 0.7787828204447258, 0.460...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[70, 40, 30]</td>\n",
       "      <td>[0.8803270301456958, 0.7923592618464349, 0.469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[70, 40, 40]</td>\n",
       "      <td>[0.8898698244942207, 0.7940217352835388, 0.465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[80, 10, 10]</td>\n",
       "      <td>[0.7673702877084986, 0.722723618168968, 0.4748...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[80, 10, 20]</td>\n",
       "      <td>[0.7884352382233941, 0.7400849879523124, 0.457...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[80, 10, 30]</td>\n",
       "      <td>[0.7986955956299188, 0.7390497026078411, 0.455...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[80, 10, 40]</td>\n",
       "      <td>[0.8135407271717054, 0.7611331867173011, 0.497...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[80, 20, 10]</td>\n",
       "      <td>[0.8329936564194634, 0.7666839714040595, 0.500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[80, 20, 20]</td>\n",
       "      <td>[0.8456221868746482, 0.765769219669729, 0.4553...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[80, 20, 30]</td>\n",
       "      <td>[0.8490961078519808, 0.7746932748644335, 0.489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[80, 20, 40]</td>\n",
       "      <td>[0.8664958463133011, 0.7798284620742517, 0.480...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[80, 30, 10]</td>\n",
       "      <td>[0.8557278119065043, 0.7856506071493738, 0.469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[80, 30, 20]</td>\n",
       "      <td>[0.8669856493563557, 0.7975554920505943, 0.495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[80, 30, 30]</td>\n",
       "      <td>[0.8747998467039151, 0.7921422412052062, 0.467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[80, 30, 40]</td>\n",
       "      <td>[0.8857977377072104, 0.7916675444981929, 0.448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[80, 40, 10]</td>\n",
       "      <td>[0.8733407127836003, 0.7963145926565992, 0.489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[80, 40, 20]</td>\n",
       "      <td>[0.8820470198868134, 0.8078571905719016, 0.474...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[80, 40, 30]</td>\n",
       "      <td>[0.8906446444998712, 0.7818175460739346, 0.463...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[80, 40, 40]</td>\n",
       "      <td>[0.9032836100591736, 0.8039496999185353, 0.448...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          params                                                fdr\n",
       "0   [50, 10, 10]  [0.7529443632549934, 0.7273672305630278, 0.432...\n",
       "1   [50, 10, 20]  [0.7721176301257977, 0.7200114224041692, 0.450...\n",
       "2   [50, 10, 30]  [0.7674356856115441, 0.7348092183452464, 0.429...\n",
       "3   [50, 10, 40]  [0.7761651681898559, 0.720909447420843, 0.3966...\n",
       "4   [50, 20, 10]  [0.8020618405894556, 0.7504918291183136, 0.501...\n",
       "5   [50, 20, 20]  [0.8214685771315657, 0.7755914783323884, 0.510...\n",
       "6   [50, 20, 30]  [0.8294009322771864, 0.7736671765579604, 0.443...\n",
       "7   [50, 20, 40]  [0.833057091861033, 0.7739286115095652, 0.4871...\n",
       "8   [50, 30, 10]  [0.8278809843566076, 0.7653133183131555, 0.509...\n",
       "9   [50, 30, 20]  [0.8416094700919172, 0.7824696833016842, 0.477...\n",
       "10  [50, 30, 30]  [0.8515327282478967, 0.7909660021823365, 0.513...\n",
       "11  [50, 30, 40]  [0.8485913369823225, 0.7867768569554248, 0.450...\n",
       "12  [50, 40, 10]  [0.8312496181153479, 0.786314094659908, 0.5189...\n",
       "13  [50, 40, 20]  [0.861179845814652, 0.7876054936448855, 0.4899...\n",
       "14  [50, 40, 30]  [0.8599795732029282, 0.7989017778608017, 0.526...\n",
       "15  [50, 40, 40]  [0.8706422401437989, 0.7910920842508944, 0.469...\n",
       "16  [60, 10, 10]  [0.760877590011533, 0.7345007618684471, 0.4620...\n",
       "17  [60, 10, 20]  [0.7740074211153696, 0.7324496614723721, 0.437...\n",
       "18  [60, 10, 30]  [0.7911902432378767, 0.7404038314110827, 0.449...\n",
       "19  [60, 10, 40]  [0.7902676400469633, 0.7516722159725702, 0.442...\n",
       "20  [60, 20, 10]  [0.8108064011484709, 0.7693034167369309, 0.493...\n",
       "21  [60, 20, 20]  [0.8221139504078628, 0.7739109883110928, 0.506...\n",
       "22  [60, 20, 30]  [0.8411769354693035, 0.7761334866931425, 0.461...\n",
       "23  [60, 20, 40]  [0.8502212519024172, 0.7643918508648191, 0.474...\n",
       "24  [60, 30, 10]  [0.8370919213217658, 0.7889429315080168, 0.524...\n",
       "25  [60, 30, 20]  [0.8553968309004519, 0.7852505849027961, 0.512...\n",
       "26  [60, 30, 30]  [0.8627783273604459, 0.7712304532417524, 0.498...\n",
       "27  [60, 30, 40]  [0.870321445327227, 0.7997964035409185, 0.4497...\n",
       "28  [60, 40, 10]  [0.8518133588302181, 0.7947082396073145, 0.498...\n",
       "29  [60, 40, 20]  [0.8589663672976882, 0.7963393876744644, 0.492...\n",
       "30  [60, 40, 30]  [0.8753301491321173, 0.7770921798143682, 0.507...\n",
       "31  [60, 40, 40]  [0.8852458313863811, 0.8083836123986405, 0.474...\n",
       "32  [70, 10, 10]  [0.7752325255774359, 0.7239991269419246, 0.472...\n",
       "33  [70, 10, 20]  [0.7981774967455811, 0.7399601224818289, 0.440...\n",
       "34  [70, 10, 30]  [0.8098729107834888, 0.7484089090871697, 0.456...\n",
       "35  [70, 10, 40]  [0.8009991466558816, 0.7598021847617116, 0.428...\n",
       "36  [70, 20, 10]  [0.8251671765454687, 0.7682446512764856, 0.450...\n",
       "37  [70, 20, 20]  [0.8399543199722862, 0.7845192859853803, 0.519...\n",
       "38  [70, 20, 30]  [0.849048163669927, 0.7784870592490356, 0.5078...\n",
       "39  [70, 20, 40]  [0.8527267243244496, 0.7857914552189972, 0.458...\n",
       "40  [70, 30, 10]  [0.8459519796480193, 0.7728798853981862, 0.517...\n",
       "41  [70, 30, 20]  [0.8528537964975736, 0.7894780440773831, 0.496...\n",
       "42  [70, 30, 30]  [0.8744645387307732, 0.7945048761762807, 0.498...\n",
       "43  [70, 30, 40]  [0.874021540082842, 0.7998048862556527, 0.4698...\n",
       "44  [70, 40, 10]  [0.861887191869633, 0.7759848600735249, 0.4905...\n",
       "45  [70, 40, 20]  [0.8806226095740766, 0.7787828204447258, 0.460...\n",
       "46  [70, 40, 30]  [0.8803270301456958, 0.7923592618464349, 0.469...\n",
       "47  [70, 40, 40]  [0.8898698244942207, 0.7940217352835388, 0.465...\n",
       "48  [80, 10, 10]  [0.7673702877084986, 0.722723618168968, 0.4748...\n",
       "49  [80, 10, 20]  [0.7884352382233941, 0.7400849879523124, 0.457...\n",
       "50  [80, 10, 30]  [0.7986955956299188, 0.7390497026078411, 0.455...\n",
       "51  [80, 10, 40]  [0.8135407271717054, 0.7611331867173011, 0.497...\n",
       "52  [80, 20, 10]  [0.8329936564194634, 0.7666839714040595, 0.500...\n",
       "53  [80, 20, 20]  [0.8456221868746482, 0.765769219669729, 0.4553...\n",
       "54  [80, 20, 30]  [0.8490961078519808, 0.7746932748644335, 0.489...\n",
       "55  [80, 20, 40]  [0.8664958463133011, 0.7798284620742517, 0.480...\n",
       "56  [80, 30, 10]  [0.8557278119065043, 0.7856506071493738, 0.469...\n",
       "57  [80, 30, 20]  [0.8669856493563557, 0.7975554920505943, 0.495...\n",
       "58  [80, 30, 30]  [0.8747998467039151, 0.7921422412052062, 0.467...\n",
       "59  [80, 30, 40]  [0.8857977377072104, 0.7916675444981929, 0.448...\n",
       "60  [80, 40, 10]  [0.8733407127836003, 0.7963145926565992, 0.489...\n",
       "61  [80, 40, 20]  [0.8820470198868134, 0.8078571905719016, 0.474...\n",
       "62  [80, 40, 30]  [0.8906446444998712, 0.7818175460739346, 0.463...\n",
       "63  [80, 40, 40]  [0.9032836100591736, 0.8039496999185353, 0.448..."
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnoutput20 = pd.DataFrame({'params':params, 'fdr':nnfdr_mean})\n",
    "nnoutput20_alliter = pd.DataFrame(nnfdr_all[0],columns=[str(params[0])+': train', 'test', 'oot'])\n",
    "for i in range(1,len(nnfdr_all)):\n",
    "    nnoutput20_alliter = pd.concat([nnoutput20_alliter, pd.DataFrame(nnfdr_all[i],columns=[str(params[i])+': train', 'test', 'oot'])], axis=1)\n",
    "nnoutput20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [nnoutput20.iloc[i,0][1:] for i in nnoutput20.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf = pd.DataFrame(index = nnoutput20.index, columns = ['Layers','Epochs','Nodes','TRAIN','TEST','OOT'])\n",
    "resultsdf['Layers'] = 2\n",
    "resultsdf['Nodes'] = nodes\n",
    "\n",
    "for i in nnoutput20.index:\n",
    "    resultsdf.loc[i,'Epochs'] = nnoutput20.iloc[i,0][0]\n",
    "    resultsdf.loc[i,'TRAIN'] = nnoutput20.iloc[i,1][0]\n",
    "    resultsdf.loc[i,'TEST'] = nnoutput20.iloc[i,1][1]\n",
    "    resultsdf.loc[i,'OOT'] = nnoutput20.iloc[i,1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layers</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Nodes</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>TEST</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>0.752944</td>\n",
       "      <td>0.727367</td>\n",
       "      <td>0.432961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[10, 20]</td>\n",
       "      <td>0.772118</td>\n",
       "      <td>0.720011</td>\n",
       "      <td>0.450838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[10, 30]</td>\n",
       "      <td>0.767436</td>\n",
       "      <td>0.734809</td>\n",
       "      <td>0.429609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[10, 40]</td>\n",
       "      <td>0.776165</td>\n",
       "      <td>0.720909</td>\n",
       "      <td>0.396648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[20, 10]</td>\n",
       "      <td>0.802062</td>\n",
       "      <td>0.750492</td>\n",
       "      <td>0.501676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>0.821469</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.510056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[20, 30]</td>\n",
       "      <td>0.829401</td>\n",
       "      <td>0.773667</td>\n",
       "      <td>0.443017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[20, 40]</td>\n",
       "      <td>0.833057</td>\n",
       "      <td>0.773929</td>\n",
       "      <td>0.487151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[30, 10]</td>\n",
       "      <td>0.827881</td>\n",
       "      <td>0.765313</td>\n",
       "      <td>0.509497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[30, 20]</td>\n",
       "      <td>0.841609</td>\n",
       "      <td>0.78247</td>\n",
       "      <td>0.477095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[30, 30]</td>\n",
       "      <td>0.851533</td>\n",
       "      <td>0.790966</td>\n",
       "      <td>0.513408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[30, 40]</td>\n",
       "      <td>0.848591</td>\n",
       "      <td>0.786777</td>\n",
       "      <td>0.450838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[40, 10]</td>\n",
       "      <td>0.83125</td>\n",
       "      <td>0.786314</td>\n",
       "      <td>0.518994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[40, 20]</td>\n",
       "      <td>0.86118</td>\n",
       "      <td>0.787605</td>\n",
       "      <td>0.489944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[40, 30]</td>\n",
       "      <td>0.85998</td>\n",
       "      <td>0.798902</td>\n",
       "      <td>0.526816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>0.870642</td>\n",
       "      <td>0.791092</td>\n",
       "      <td>0.469832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>0.760878</td>\n",
       "      <td>0.734501</td>\n",
       "      <td>0.462011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[10, 20]</td>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.73245</td>\n",
       "      <td>0.43743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[10, 30]</td>\n",
       "      <td>0.79119</td>\n",
       "      <td>0.740404</td>\n",
       "      <td>0.449162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[10, 40]</td>\n",
       "      <td>0.790268</td>\n",
       "      <td>0.751672</td>\n",
       "      <td>0.442458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[20, 10]</td>\n",
       "      <td>0.810806</td>\n",
       "      <td>0.769303</td>\n",
       "      <td>0.493855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>0.822114</td>\n",
       "      <td>0.773911</td>\n",
       "      <td>0.506145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[20, 30]</td>\n",
       "      <td>0.841177</td>\n",
       "      <td>0.776133</td>\n",
       "      <td>0.461453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[20, 40]</td>\n",
       "      <td>0.850221</td>\n",
       "      <td>0.764392</td>\n",
       "      <td>0.47486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[30, 10]</td>\n",
       "      <td>0.837092</td>\n",
       "      <td>0.788943</td>\n",
       "      <td>0.524581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[30, 20]</td>\n",
       "      <td>0.855397</td>\n",
       "      <td>0.785251</td>\n",
       "      <td>0.512849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[30, 30]</td>\n",
       "      <td>0.862778</td>\n",
       "      <td>0.77123</td>\n",
       "      <td>0.498324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[30, 40]</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>0.799796</td>\n",
       "      <td>0.449721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[40, 10]</td>\n",
       "      <td>0.851813</td>\n",
       "      <td>0.794708</td>\n",
       "      <td>0.498883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[40, 20]</td>\n",
       "      <td>0.858966</td>\n",
       "      <td>0.796339</td>\n",
       "      <td>0.492737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[40, 30]</td>\n",
       "      <td>0.87533</td>\n",
       "      <td>0.777092</td>\n",
       "      <td>0.507821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.808384</td>\n",
       "      <td>0.47486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>0.775233</td>\n",
       "      <td>0.723999</td>\n",
       "      <td>0.472626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[10, 20]</td>\n",
       "      <td>0.798177</td>\n",
       "      <td>0.73996</td>\n",
       "      <td>0.440782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[10, 30]</td>\n",
       "      <td>0.809873</td>\n",
       "      <td>0.748409</td>\n",
       "      <td>0.456425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[10, 40]</td>\n",
       "      <td>0.800999</td>\n",
       "      <td>0.759802</td>\n",
       "      <td>0.428492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[20, 10]</td>\n",
       "      <td>0.825167</td>\n",
       "      <td>0.768245</td>\n",
       "      <td>0.450838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>0.839954</td>\n",
       "      <td>0.784519</td>\n",
       "      <td>0.519553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[20, 30]</td>\n",
       "      <td>0.849048</td>\n",
       "      <td>0.778487</td>\n",
       "      <td>0.507821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[20, 40]</td>\n",
       "      <td>0.852727</td>\n",
       "      <td>0.785791</td>\n",
       "      <td>0.458659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[30, 10]</td>\n",
       "      <td>0.845952</td>\n",
       "      <td>0.77288</td>\n",
       "      <td>0.517877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[30, 20]</td>\n",
       "      <td>0.852854</td>\n",
       "      <td>0.789478</td>\n",
       "      <td>0.496089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[30, 30]</td>\n",
       "      <td>0.874465</td>\n",
       "      <td>0.794505</td>\n",
       "      <td>0.498324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[30, 40]</td>\n",
       "      <td>0.874022</td>\n",
       "      <td>0.799805</td>\n",
       "      <td>0.469832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[40, 10]</td>\n",
       "      <td>0.861887</td>\n",
       "      <td>0.775985</td>\n",
       "      <td>0.490503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[40, 20]</td>\n",
       "      <td>0.880623</td>\n",
       "      <td>0.778783</td>\n",
       "      <td>0.460335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[40, 30]</td>\n",
       "      <td>0.880327</td>\n",
       "      <td>0.792359</td>\n",
       "      <td>0.469832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>0.88987</td>\n",
       "      <td>0.794022</td>\n",
       "      <td>0.465922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>0.76737</td>\n",
       "      <td>0.722724</td>\n",
       "      <td>0.47486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[10, 20]</td>\n",
       "      <td>0.788435</td>\n",
       "      <td>0.740085</td>\n",
       "      <td>0.457542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[10, 30]</td>\n",
       "      <td>0.798696</td>\n",
       "      <td>0.73905</td>\n",
       "      <td>0.455866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[10, 40]</td>\n",
       "      <td>0.813541</td>\n",
       "      <td>0.761133</td>\n",
       "      <td>0.497207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[20, 10]</td>\n",
       "      <td>0.832994</td>\n",
       "      <td>0.766684</td>\n",
       "      <td>0.500559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>0.845622</td>\n",
       "      <td>0.765769</td>\n",
       "      <td>0.455307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[20, 30]</td>\n",
       "      <td>0.849096</td>\n",
       "      <td>0.774693</td>\n",
       "      <td>0.489944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[20, 40]</td>\n",
       "      <td>0.866496</td>\n",
       "      <td>0.779828</td>\n",
       "      <td>0.480447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[30, 10]</td>\n",
       "      <td>0.855728</td>\n",
       "      <td>0.785651</td>\n",
       "      <td>0.469832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[30, 20]</td>\n",
       "      <td>0.866986</td>\n",
       "      <td>0.797555</td>\n",
       "      <td>0.495531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[30, 30]</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.792142</td>\n",
       "      <td>0.467598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[30, 40]</td>\n",
       "      <td>0.885798</td>\n",
       "      <td>0.791668</td>\n",
       "      <td>0.448045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[40, 10]</td>\n",
       "      <td>0.873341</td>\n",
       "      <td>0.796315</td>\n",
       "      <td>0.489385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[40, 20]</td>\n",
       "      <td>0.882047</td>\n",
       "      <td>0.807857</td>\n",
       "      <td>0.474302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[40, 30]</td>\n",
       "      <td>0.890645</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.463687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>[40, 40]</td>\n",
       "      <td>0.903284</td>\n",
       "      <td>0.80395</td>\n",
       "      <td>0.448603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layers Epochs     Nodes     TRAIN      TEST       OOT\n",
       "0        2     50  [10, 10]  0.752944  0.727367  0.432961\n",
       "1        2     50  [10, 20]  0.772118  0.720011  0.450838\n",
       "2        2     50  [10, 30]  0.767436  0.734809  0.429609\n",
       "3        2     50  [10, 40]  0.776165  0.720909  0.396648\n",
       "4        2     50  [20, 10]  0.802062  0.750492  0.501676\n",
       "5        2     50  [20, 20]  0.821469  0.775591  0.510056\n",
       "6        2     50  [20, 30]  0.829401  0.773667  0.443017\n",
       "7        2     50  [20, 40]  0.833057  0.773929  0.487151\n",
       "8        2     50  [30, 10]  0.827881  0.765313  0.509497\n",
       "9        2     50  [30, 20]  0.841609   0.78247  0.477095\n",
       "10       2     50  [30, 30]  0.851533  0.790966  0.513408\n",
       "11       2     50  [30, 40]  0.848591  0.786777  0.450838\n",
       "12       2     50  [40, 10]   0.83125  0.786314  0.518994\n",
       "13       2     50  [40, 20]   0.86118  0.787605  0.489944\n",
       "14       2     50  [40, 30]   0.85998  0.798902  0.526816\n",
       "15       2     50  [40, 40]  0.870642  0.791092  0.469832\n",
       "16       2     60  [10, 10]  0.760878  0.734501  0.462011\n",
       "17       2     60  [10, 20]  0.774007   0.73245   0.43743\n",
       "18       2     60  [10, 30]   0.79119  0.740404  0.449162\n",
       "19       2     60  [10, 40]  0.790268  0.751672  0.442458\n",
       "20       2     60  [20, 10]  0.810806  0.769303  0.493855\n",
       "21       2     60  [20, 20]  0.822114  0.773911  0.506145\n",
       "22       2     60  [20, 30]  0.841177  0.776133  0.461453\n",
       "23       2     60  [20, 40]  0.850221  0.764392   0.47486\n",
       "24       2     60  [30, 10]  0.837092  0.788943  0.524581\n",
       "25       2     60  [30, 20]  0.855397  0.785251  0.512849\n",
       "26       2     60  [30, 30]  0.862778   0.77123  0.498324\n",
       "27       2     60  [30, 40]  0.870321  0.799796  0.449721\n",
       "28       2     60  [40, 10]  0.851813  0.794708  0.498883\n",
       "29       2     60  [40, 20]  0.858966  0.796339  0.492737\n",
       "30       2     60  [40, 30]   0.87533  0.777092  0.507821\n",
       "31       2     60  [40, 40]  0.885246  0.808384   0.47486\n",
       "32       2     70  [10, 10]  0.775233  0.723999  0.472626\n",
       "33       2     70  [10, 20]  0.798177   0.73996  0.440782\n",
       "34       2     70  [10, 30]  0.809873  0.748409  0.456425\n",
       "35       2     70  [10, 40]  0.800999  0.759802  0.428492\n",
       "36       2     70  [20, 10]  0.825167  0.768245  0.450838\n",
       "37       2     70  [20, 20]  0.839954  0.784519  0.519553\n",
       "38       2     70  [20, 30]  0.849048  0.778487  0.507821\n",
       "39       2     70  [20, 40]  0.852727  0.785791  0.458659\n",
       "40       2     70  [30, 10]  0.845952   0.77288  0.517877\n",
       "41       2     70  [30, 20]  0.852854  0.789478  0.496089\n",
       "42       2     70  [30, 30]  0.874465  0.794505  0.498324\n",
       "43       2     70  [30, 40]  0.874022  0.799805  0.469832\n",
       "44       2     70  [40, 10]  0.861887  0.775985  0.490503\n",
       "45       2     70  [40, 20]  0.880623  0.778783  0.460335\n",
       "46       2     70  [40, 30]  0.880327  0.792359  0.469832\n",
       "47       2     70  [40, 40]   0.88987  0.794022  0.465922\n",
       "48       2     80  [10, 10]   0.76737  0.722724   0.47486\n",
       "49       2     80  [10, 20]  0.788435  0.740085  0.457542\n",
       "50       2     80  [10, 30]  0.798696   0.73905  0.455866\n",
       "51       2     80  [10, 40]  0.813541  0.761133  0.497207\n",
       "52       2     80  [20, 10]  0.832994  0.766684  0.500559\n",
       "53       2     80  [20, 20]  0.845622  0.765769  0.455307\n",
       "54       2     80  [20, 30]  0.849096  0.774693  0.489944\n",
       "55       2     80  [20, 40]  0.866496  0.779828  0.480447\n",
       "56       2     80  [30, 10]  0.855728  0.785651  0.469832\n",
       "57       2     80  [30, 20]  0.866986  0.797555  0.495531\n",
       "58       2     80  [30, 30]    0.8748  0.792142  0.467598\n",
       "59       2     80  [30, 40]  0.885798  0.791668  0.448045\n",
       "60       2     80  [40, 10]  0.873341  0.796315  0.489385\n",
       "61       2     80  [40, 20]  0.882047  0.807857  0.474302\n",
       "62       2     80  [40, 30]  0.890645  0.781818  0.463687\n",
       "63       2     80  [40, 40]  0.903284   0.80395  0.448603"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf.to_csv('extraNN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model & Savings Calculation Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use X3 and X_oot3 to only use the top 20 variables\n",
    "\n",
    "#oot df\n",
    "df_oot = df[df.Date>='2010-11-01'].copy()\n",
    "\n",
    "#x and y oot\n",
    "y_oot = df_oot['Fraud'].copy()\n",
    "X_oot = df_oot.copy().drop(columns='Fraud')\n",
    "\n",
    "#modeling data\n",
    "df_model = df[(df.Date>'2010-01-14')&(df.Date<'2010-11-01')].copy()\n",
    "\n",
    "# #x and y train\n",
    "y = df_model['Fraud'].copy()\n",
    "X = df_model.copy().drop(columns='Fraud')\n",
    "\n",
    "# #dropping date and record\n",
    "df_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "y_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "X_oot.drop(columns=['Date','Recnum'], inplace=True)\n",
    "\n",
    "df_model.drop(columns=['Date','Recnum'], inplace=True)\n",
    "y.drop(columns=['Date','Recnum'], inplace=True)\n",
    "X.drop(columns=['Date','Recnum'], inplace=True)\n",
    "\n",
    "X_oot3 = X_oot[top20vars]\n",
    "X3 = X[top20vars]\n",
    "\n",
    "X_oot3 = StandardScaler().fit_transform(X_oot3)\n",
    "X3 = StandardScaler().fit_transform(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "final_model = MLPClassifier(hidden_layer_sizes = (40,), max_iter = 50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y, test_size = .3)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "trainpred = final_model.predict(X_train)\n",
    "trainprob = final_model.predict_proba(X_train)\n",
    "\n",
    "testpred = final_model.predict(X_test)\n",
    "testprob = final_model.predict_proba(X_test)\n",
    "\n",
    "ootpred = final_model.predict(X_oot3)\n",
    "ootprob = final_model.predict_proba(X_oot3)\n",
    "\n",
    "#y_train, y_test, y_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# final_model2 = MLPClassifier(hidden_layer_sizes = (40,), max_iter = 50)\n",
    "# final_model2.fit(X3, y)\n",
    "# predictions = final_model2.predict(X_oot3)\n",
    "# probs = final_model2.predict_proba(X_oot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782258064516129"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #final final model (trained on all modeling data, tested on oot data)\n",
    "# trnpredict = final_model2.predict(X3)\n",
    "# trnprob = final_model2.predict_proba(X3)\n",
    "# trnfrdscore = trnprob.transpose()[1]\n",
    "# trnfdr = calculateFDR(trnpredict, trnfrdscore, y)\n",
    "# trnfdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5865921787709497"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tstpredict = final_model2.predict(X_oot3)\n",
    "# tstprob = final_model2.predict_proba(X_oot3)\n",
    "# tstfrdscore = tstprob.transpose()[1]\n",
    "# tstfdr = calculateFDR(tstpredict, tstfrdscore, y_oot)\n",
    "# tstfdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12427"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_y = y_oot.copy().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12248\n",
       "1      179\n",
       "Name: Fraud, dtype: int64"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_y['Fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Predicted_Prob</th>\n",
       "      <th>Fraud_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12422</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12423</th>\n",
       "      <td>0</td>\n",
       "      <td>0.993315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12424</th>\n",
       "      <td>0</td>\n",
       "      <td>0.981731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12425</th>\n",
       "      <td>0</td>\n",
       "      <td>0.983782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12426</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  Predicted_Prob  Fraud_Label\n",
       "0               0        0.999768            0\n",
       "1               0        0.998959            0\n",
       "2               0        0.999531            0\n",
       "3               0        0.999831            0\n",
       "4               0        0.999613            0\n",
       "...           ...             ...          ...\n",
       "12422           0        0.999832            0\n",
       "12423           0        0.993315            0\n",
       "12424           0        0.981731            0\n",
       "12425           0        0.983782            0\n",
       "12426           0        0.999323            0\n",
       "\n",
       "[12427 rows x 3 columns]"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizdf = pd.DataFrame(columns = ['Prediction','Predicted_Prob','Fraud_Label'])\n",
    "vizdf['Prediction'] = predictions\n",
    "vizdf['Predicted_Prob'] = probs\n",
    "vizdf['Fraud_Label'] = viz_y.Fraud\n",
    "\n",
    "vizdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdf = vizdf.sort_values(by='Predicted_Prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Predicted_Prob</th>\n",
       "      <th>Fraud_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  Predicted_Prob  Fraud_Label\n",
       "5160            1        0.000238            1\n",
       "5159            1        0.000242            1\n",
       "5158            1        0.000248            1\n",
       "5151            1        0.000308            1\n",
       "5150            1        0.000324            1\n",
       "...           ...             ...          ...\n",
       "5428            0        1.000000            0\n",
       "5536            0        1.000000            0\n",
       "11870           0        1.000000            0\n",
       "5236            0        1.000000            1\n",
       "4269            0        1.000000            0\n",
       "\n",
       "[12427 rows x 3 columns]"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = pd.qcut(range(len(vizdf)), q=100, precision=1)\n",
    "\n",
    "# bin definition\n",
    "bins  = qc.categories\n",
    "\n",
    "# bin corresponding to each point in data\n",
    "codes = qc.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdf['Bin'] = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Predicted_Prob</th>\n",
       "      <th>Fraud_Label</th>\n",
       "      <th>Bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12427 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  Predicted_Prob  Fraud_Label  Bin\n",
       "5160            1        0.000238            1    0\n",
       "5159            1        0.000242            1    0\n",
       "5158            1        0.000248            1    0\n",
       "5151            1        0.000308            1    0\n",
       "5150            1        0.000324            1    0\n",
       "...           ...             ...          ...  ...\n",
       "5428            0        1.000000            0   99\n",
       "5536            0        1.000000            0   99\n",
       "11870           0        1.000000            0   99\n",
       "5236            0        1.000000            1   99\n",
       "4269            0        1.000000            0   99\n",
       "\n",
       "[12427 rows x 4 columns]"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdf2 = pd.DataFrame(columns = ['Bin','FraudSavings', 'LostSales', 'OverallSavings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdf2['Bin'] = list(np.unique(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in vizdf2.index:\n",
    "    vizdf2.loc[i,'FraudSavings'] = 2000 * len(vizdf[(vizdf.Bin==vizdf2.loc[i,'Bin']) & (vizdf.Fraud_Label==1)])\n",
    "    vizdf2.loc[i,'LostSales'] = 50 * len(vizdf[(vizdf.Bin==vizdf2.loc[i,'Bin']) & (vizdf.Fraud_Label==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bin</th>\n",
       "      <th>FraudSavings</th>\n",
       "      <th>LostSales</th>\n",
       "      <th>OverallSavings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>126000</td>\n",
       "      <td>3100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>66000</td>\n",
       "      <td>4550</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16000</td>\n",
       "      <td>5800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6000</td>\n",
       "      <td>6100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8000</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>8000</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>5950</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>4000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>8000</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>4000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bin FraudSavings LostSales OverallSavings\n",
       "0     0       126000      3100            NaN\n",
       "1     1        66000      4550            NaN\n",
       "2     2        16000      5800            NaN\n",
       "3     3         6000      6100            NaN\n",
       "4     4         8000      6000            NaN\n",
       "5     5         4000      6100            NaN\n",
       "6     6         8000      6000            NaN\n",
       "7     7        10000      6000            NaN\n",
       "8     8         6000      6050            NaN\n",
       "9     9         2000      6150            NaN\n",
       "10   10        10000      5950            NaN\n",
       "11   11         4000      6150            NaN\n",
       "12   12         4000      6100            NaN\n",
       "13   13         6000      6050            NaN\n",
       "14   14            0      6200            NaN\n",
       "15   15            0      6250            NaN\n",
       "16   16         2000      6150            NaN\n",
       "17   17         6000      6050            NaN\n",
       "18   18            0      6200            NaN\n",
       "19   19         2000      6200            NaN\n",
       "20   20         8000      6000            NaN\n",
       "21   21            0      6200            NaN\n",
       "22   22         2000      6150            NaN\n",
       "23   23            0      6250            NaN\n",
       "24   24         2000      6150            NaN\n",
       "25   25            0      6200            NaN\n",
       "26   26         2000      6200            NaN\n",
       "27   27            0      6200            NaN\n",
       "28   28            0      6200            NaN\n",
       "29   29            0      6200            NaN\n",
       "30   30         4000      6150            NaN\n",
       "31   31         2000      6150            NaN\n",
       "32   32         2000      6150            NaN\n",
       "33   33         2000      6150            NaN\n",
       "34   34         2000      6200            NaN\n",
       "35   35         6000      6050            NaN\n",
       "36   36            0      6200            NaN\n",
       "37   37         6000      6050            NaN\n",
       "38   38         2000      6200            NaN\n",
       "39   39            0      6200            NaN\n",
       "40   40         2000      6150            NaN\n",
       "41   41         4000      6100            NaN\n",
       "42   42         2000      6200            NaN\n",
       "43   43            0      6200            NaN\n",
       "44   44            0      6200            NaN\n",
       "45   45            0      6200            NaN\n",
       "46   46            0      6250            NaN\n",
       "47   47            0      6200            NaN\n",
       "48   48            0      6200            NaN\n",
       "49   49         2000      6200            NaN\n",
       "50   50            0      6200            NaN\n",
       "51   51            0      6200            NaN\n",
       "52   52         4000      6100            NaN\n",
       "53   53            0      6250            NaN\n",
       "54   54         2000      6150            NaN\n",
       "55   55            0      6200            NaN\n",
       "56   56         4000      6100            NaN\n",
       "57   57            0      6250            NaN\n",
       "58   58            0      6200            NaN\n",
       "59   59            0      6200            NaN\n",
       "60   60            0      6200            NaN\n",
       "61   61            0      6250            NaN\n",
       "62   62            0      6200            NaN\n",
       "63   63         2000      6150            NaN\n",
       "64   64            0      6200            NaN\n",
       "65   65            0      6250            NaN\n",
       "66   66            0      6200            NaN\n",
       "67   67            0      6200            NaN\n",
       "68   68            0      6200            NaN\n",
       "69   69            0      6250            NaN\n",
       "70   70            0      6200            NaN\n",
       "71   71            0      6200            NaN\n",
       "72   72            0      6200            NaN\n",
       "73   73            0      6250            NaN\n",
       "74   74            0      6200            NaN\n",
       "75   75            0      6200            NaN\n",
       "76   76            0      6250            NaN\n",
       "77   77            0      6200            NaN\n",
       "78   78            0      6200            NaN\n",
       "79   79            0      6200            NaN\n",
       "80   80            0      6250            NaN\n",
       "81   81            0      6200            NaN\n",
       "82   82            0      6200            NaN\n",
       "83   83            0      6200            NaN\n",
       "84   84         2000      6200            NaN\n",
       "85   85            0      6200            NaN\n",
       "86   86            0      6200            NaN\n",
       "87   87            0      6200            NaN\n",
       "88   88         2000      6200            NaN\n",
       "89   89            0      6200            NaN\n",
       "90   90            0      6200            NaN\n",
       "91   91         2000      6150            NaN\n",
       "92   92            0      6250            NaN\n",
       "93   93         2000      6150            NaN\n",
       "94   94            0      6200            NaN\n",
       "95   95            0      6200            NaN\n",
       "96   96            0      6250            NaN\n",
       "97   97            0      6200            NaN\n",
       "98   98            0      6200            NaN\n",
       "99   99         2000      6200            NaN"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdf2['OverallSavings'] = vizdf2['FraudSavings'] - vizdf2['LostSales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdf2['CumulativeSavings'] = 0\n",
    "vizdf2['CumulativeLosses'] = 0\n",
    "vizdf2['CumulativeOverall'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdf2.loc[0,'CumulativeSavings'] = 90000\n",
    "vizdf2.loc[0,'CumulativeLosses'] = 4000\n",
    "vizdf2.loc[0,'CumulativeOverall'] = 86000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(vizdf2)):\n",
    "    vizdf2.loc[i,'CumulativeSavings'] = vizdf2.loc[i-1,'CumulativeSavings'] + vizdf2.loc[i,'FraudSavings']\n",
    "    vizdf2.loc[i,'CumulativeLosses'] = vizdf2.loc[i-1,'CumulativeLosses'] + vizdf2.loc[i,'LostSales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdf2['CumulativeOverall'] = vizdf2['CumulativeSavings'] - vizdf2['CumulativeLosses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bin</th>\n",
       "      <th>FraudSavings</th>\n",
       "      <th>LostSales</th>\n",
       "      <th>OverallSavings</th>\n",
       "      <th>CumulativeSavings</th>\n",
       "      <th>CumulativeLosses</th>\n",
       "      <th>CumulativeOverall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>126000</td>\n",
       "      <td>3100</td>\n",
       "      <td>122900</td>\n",
       "      <td>90000</td>\n",
       "      <td>4000</td>\n",
       "      <td>86000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>66000</td>\n",
       "      <td>4550</td>\n",
       "      <td>61450</td>\n",
       "      <td>156000</td>\n",
       "      <td>8550</td>\n",
       "      <td>147450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16000</td>\n",
       "      <td>5800</td>\n",
       "      <td>10200</td>\n",
       "      <td>172000</td>\n",
       "      <td>14350</td>\n",
       "      <td>157650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6000</td>\n",
       "      <td>6100</td>\n",
       "      <td>-100</td>\n",
       "      <td>178000</td>\n",
       "      <td>20450</td>\n",
       "      <td>157550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8000</td>\n",
       "      <td>6000</td>\n",
       "      <td>2000</td>\n",
       "      <td>186000</td>\n",
       "      <td>26450</td>\n",
       "      <td>159550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>-2100</td>\n",
       "      <td>190000</td>\n",
       "      <td>32550</td>\n",
       "      <td>157450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>8000</td>\n",
       "      <td>6000</td>\n",
       "      <td>2000</td>\n",
       "      <td>198000</td>\n",
       "      <td>38550</td>\n",
       "      <td>159450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>208000</td>\n",
       "      <td>44550</td>\n",
       "      <td>163450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>-50</td>\n",
       "      <td>214000</td>\n",
       "      <td>50600</td>\n",
       "      <td>163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>216000</td>\n",
       "      <td>56750</td>\n",
       "      <td>159250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>5950</td>\n",
       "      <td>4050</td>\n",
       "      <td>226000</td>\n",
       "      <td>62700</td>\n",
       "      <td>163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>4000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-2150</td>\n",
       "      <td>230000</td>\n",
       "      <td>68850</td>\n",
       "      <td>161150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>-2100</td>\n",
       "      <td>234000</td>\n",
       "      <td>74950</td>\n",
       "      <td>159050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>-50</td>\n",
       "      <td>240000</td>\n",
       "      <td>81000</td>\n",
       "      <td>159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>240000</td>\n",
       "      <td>87200</td>\n",
       "      <td>152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>240000</td>\n",
       "      <td>93450</td>\n",
       "      <td>146550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>242000</td>\n",
       "      <td>99600</td>\n",
       "      <td>142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>-50</td>\n",
       "      <td>248000</td>\n",
       "      <td>105650</td>\n",
       "      <td>142350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>248000</td>\n",
       "      <td>111850</td>\n",
       "      <td>136150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>-4200</td>\n",
       "      <td>250000</td>\n",
       "      <td>118050</td>\n",
       "      <td>131950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>8000</td>\n",
       "      <td>6000</td>\n",
       "      <td>2000</td>\n",
       "      <td>258000</td>\n",
       "      <td>124050</td>\n",
       "      <td>133950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>258000</td>\n",
       "      <td>130250</td>\n",
       "      <td>127750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>260000</td>\n",
       "      <td>136400</td>\n",
       "      <td>123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>260000</td>\n",
       "      <td>142650</td>\n",
       "      <td>117350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>262000</td>\n",
       "      <td>148800</td>\n",
       "      <td>113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>262000</td>\n",
       "      <td>155000</td>\n",
       "      <td>107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>-4200</td>\n",
       "      <td>264000</td>\n",
       "      <td>161200</td>\n",
       "      <td>102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>264000</td>\n",
       "      <td>167400</td>\n",
       "      <td>96600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>264000</td>\n",
       "      <td>173600</td>\n",
       "      <td>90400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>264000</td>\n",
       "      <td>179800</td>\n",
       "      <td>84200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>4000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-2150</td>\n",
       "      <td>268000</td>\n",
       "      <td>185950</td>\n",
       "      <td>82050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>270000</td>\n",
       "      <td>192100</td>\n",
       "      <td>77900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>272000</td>\n",
       "      <td>198250</td>\n",
       "      <td>73750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>274000</td>\n",
       "      <td>204400</td>\n",
       "      <td>69600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>-4200</td>\n",
       "      <td>276000</td>\n",
       "      <td>210600</td>\n",
       "      <td>65400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>-50</td>\n",
       "      <td>282000</td>\n",
       "      <td>216650</td>\n",
       "      <td>65350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>282000</td>\n",
       "      <td>222850</td>\n",
       "      <td>59150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>6000</td>\n",
       "      <td>6050</td>\n",
       "      <td>-50</td>\n",
       "      <td>288000</td>\n",
       "      <td>228900</td>\n",
       "      <td>59100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>-4200</td>\n",
       "      <td>290000</td>\n",
       "      <td>235100</td>\n",
       "      <td>54900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>290000</td>\n",
       "      <td>241300</td>\n",
       "      <td>48700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>292000</td>\n",
       "      <td>247450</td>\n",
       "      <td>44550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>-2100</td>\n",
       "      <td>296000</td>\n",
       "      <td>253550</td>\n",
       "      <td>42450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>-4200</td>\n",
       "      <td>298000</td>\n",
       "      <td>259750</td>\n",
       "      <td>38250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>298000</td>\n",
       "      <td>265950</td>\n",
       "      <td>32050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>298000</td>\n",
       "      <td>272150</td>\n",
       "      <td>25850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>298000</td>\n",
       "      <td>278350</td>\n",
       "      <td>19650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>298000</td>\n",
       "      <td>284600</td>\n",
       "      <td>13400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>298000</td>\n",
       "      <td>290800</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>298000</td>\n",
       "      <td>297000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>-4200</td>\n",
       "      <td>300000</td>\n",
       "      <td>303200</td>\n",
       "      <td>-3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>300000</td>\n",
       "      <td>309400</td>\n",
       "      <td>-9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>300000</td>\n",
       "      <td>315600</td>\n",
       "      <td>-15600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>-2100</td>\n",
       "      <td>304000</td>\n",
       "      <td>321700</td>\n",
       "      <td>-17700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>304000</td>\n",
       "      <td>327950</td>\n",
       "      <td>-23950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>306000</td>\n",
       "      <td>334100</td>\n",
       "      <td>-28100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>306000</td>\n",
       "      <td>340300</td>\n",
       "      <td>-34300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>4000</td>\n",
       "      <td>6100</td>\n",
       "      <td>-2100</td>\n",
       "      <td>310000</td>\n",
       "      <td>346400</td>\n",
       "      <td>-36400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>310000</td>\n",
       "      <td>352650</td>\n",
       "      <td>-42650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>310000</td>\n",
       "      <td>358850</td>\n",
       "      <td>-48850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>310000</td>\n",
       "      <td>365050</td>\n",
       "      <td>-55050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>310000</td>\n",
       "      <td>371250</td>\n",
       "      <td>-61250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>310000</td>\n",
       "      <td>377500</td>\n",
       "      <td>-67500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>310000</td>\n",
       "      <td>383700</td>\n",
       "      <td>-73700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>312000</td>\n",
       "      <td>389850</td>\n",
       "      <td>-77850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>396050</td>\n",
       "      <td>-84050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>312000</td>\n",
       "      <td>402300</td>\n",
       "      <td>-90300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>408500</td>\n",
       "      <td>-96500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>414700</td>\n",
       "      <td>-102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>420900</td>\n",
       "      <td>-108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>312000</td>\n",
       "      <td>427150</td>\n",
       "      <td>-115150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>433350</td>\n",
       "      <td>-121350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>439550</td>\n",
       "      <td>-127550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>445750</td>\n",
       "      <td>-133750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>312000</td>\n",
       "      <td>452000</td>\n",
       "      <td>-140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>458200</td>\n",
       "      <td>-146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>464400</td>\n",
       "      <td>-152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>312000</td>\n",
       "      <td>470650</td>\n",
       "      <td>-158650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>476850</td>\n",
       "      <td>-164850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>483050</td>\n",
       "      <td>-171050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>489250</td>\n",
       "      <td>-177250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>312000</td>\n",
       "      <td>495500</td>\n",
       "      <td>-183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>501700</td>\n",
       "      <td>-189700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>507900</td>\n",
       "      <td>-195900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>312000</td>\n",
       "      <td>514100</td>\n",
       "      <td>-202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>-4200</td>\n",
       "      <td>314000</td>\n",
       "      <td>520300</td>\n",
       "      <td>-206300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>314000</td>\n",
       "      <td>526500</td>\n",
       "      <td>-212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>314000</td>\n",
       "      <td>532700</td>\n",
       "      <td>-218700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>314000</td>\n",
       "      <td>538900</td>\n",
       "      <td>-224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>-4200</td>\n",
       "      <td>316000</td>\n",
       "      <td>545100</td>\n",
       "      <td>-229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>316000</td>\n",
       "      <td>551300</td>\n",
       "      <td>-235300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>316000</td>\n",
       "      <td>557500</td>\n",
       "      <td>-241500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>318000</td>\n",
       "      <td>563650</td>\n",
       "      <td>-245650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>318000</td>\n",
       "      <td>569900</td>\n",
       "      <td>-251900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>2000</td>\n",
       "      <td>6150</td>\n",
       "      <td>-4150</td>\n",
       "      <td>320000</td>\n",
       "      <td>576050</td>\n",
       "      <td>-256050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>320000</td>\n",
       "      <td>582250</td>\n",
       "      <td>-262250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>320000</td>\n",
       "      <td>588450</td>\n",
       "      <td>-268450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>6250</td>\n",
       "      <td>-6250</td>\n",
       "      <td>320000</td>\n",
       "      <td>594700</td>\n",
       "      <td>-274700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>320000</td>\n",
       "      <td>600900</td>\n",
       "      <td>-280900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-6200</td>\n",
       "      <td>320000</td>\n",
       "      <td>607100</td>\n",
       "      <td>-287100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>2000</td>\n",
       "      <td>6200</td>\n",
       "      <td>-4200</td>\n",
       "      <td>322000</td>\n",
       "      <td>613300</td>\n",
       "      <td>-291300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bin FraudSavings LostSales OverallSavings  CumulativeSavings  \\\n",
       "0     0       126000      3100         122900              90000   \n",
       "1     1        66000      4550          61450             156000   \n",
       "2     2        16000      5800          10200             172000   \n",
       "3     3         6000      6100           -100             178000   \n",
       "4     4         8000      6000           2000             186000   \n",
       "5     5         4000      6100          -2100             190000   \n",
       "6     6         8000      6000           2000             198000   \n",
       "7     7        10000      6000           4000             208000   \n",
       "8     8         6000      6050            -50             214000   \n",
       "9     9         2000      6150          -4150             216000   \n",
       "10   10        10000      5950           4050             226000   \n",
       "11   11         4000      6150          -2150             230000   \n",
       "12   12         4000      6100          -2100             234000   \n",
       "13   13         6000      6050            -50             240000   \n",
       "14   14            0      6200          -6200             240000   \n",
       "15   15            0      6250          -6250             240000   \n",
       "16   16         2000      6150          -4150             242000   \n",
       "17   17         6000      6050            -50             248000   \n",
       "18   18            0      6200          -6200             248000   \n",
       "19   19         2000      6200          -4200             250000   \n",
       "20   20         8000      6000           2000             258000   \n",
       "21   21            0      6200          -6200             258000   \n",
       "22   22         2000      6150          -4150             260000   \n",
       "23   23            0      6250          -6250             260000   \n",
       "24   24         2000      6150          -4150             262000   \n",
       "25   25            0      6200          -6200             262000   \n",
       "26   26         2000      6200          -4200             264000   \n",
       "27   27            0      6200          -6200             264000   \n",
       "28   28            0      6200          -6200             264000   \n",
       "29   29            0      6200          -6200             264000   \n",
       "30   30         4000      6150          -2150             268000   \n",
       "31   31         2000      6150          -4150             270000   \n",
       "32   32         2000      6150          -4150             272000   \n",
       "33   33         2000      6150          -4150             274000   \n",
       "34   34         2000      6200          -4200             276000   \n",
       "35   35         6000      6050            -50             282000   \n",
       "36   36            0      6200          -6200             282000   \n",
       "37   37         6000      6050            -50             288000   \n",
       "38   38         2000      6200          -4200             290000   \n",
       "39   39            0      6200          -6200             290000   \n",
       "40   40         2000      6150          -4150             292000   \n",
       "41   41         4000      6100          -2100             296000   \n",
       "42   42         2000      6200          -4200             298000   \n",
       "43   43            0      6200          -6200             298000   \n",
       "44   44            0      6200          -6200             298000   \n",
       "45   45            0      6200          -6200             298000   \n",
       "46   46            0      6250          -6250             298000   \n",
       "47   47            0      6200          -6200             298000   \n",
       "48   48            0      6200          -6200             298000   \n",
       "49   49         2000      6200          -4200             300000   \n",
       "50   50            0      6200          -6200             300000   \n",
       "51   51            0      6200          -6200             300000   \n",
       "52   52         4000      6100          -2100             304000   \n",
       "53   53            0      6250          -6250             304000   \n",
       "54   54         2000      6150          -4150             306000   \n",
       "55   55            0      6200          -6200             306000   \n",
       "56   56         4000      6100          -2100             310000   \n",
       "57   57            0      6250          -6250             310000   \n",
       "58   58            0      6200          -6200             310000   \n",
       "59   59            0      6200          -6200             310000   \n",
       "60   60            0      6200          -6200             310000   \n",
       "61   61            0      6250          -6250             310000   \n",
       "62   62            0      6200          -6200             310000   \n",
       "63   63         2000      6150          -4150             312000   \n",
       "64   64            0      6200          -6200             312000   \n",
       "65   65            0      6250          -6250             312000   \n",
       "66   66            0      6200          -6200             312000   \n",
       "67   67            0      6200          -6200             312000   \n",
       "68   68            0      6200          -6200             312000   \n",
       "69   69            0      6250          -6250             312000   \n",
       "70   70            0      6200          -6200             312000   \n",
       "71   71            0      6200          -6200             312000   \n",
       "72   72            0      6200          -6200             312000   \n",
       "73   73            0      6250          -6250             312000   \n",
       "74   74            0      6200          -6200             312000   \n",
       "75   75            0      6200          -6200             312000   \n",
       "76   76            0      6250          -6250             312000   \n",
       "77   77            0      6200          -6200             312000   \n",
       "78   78            0      6200          -6200             312000   \n",
       "79   79            0      6200          -6200             312000   \n",
       "80   80            0      6250          -6250             312000   \n",
       "81   81            0      6200          -6200             312000   \n",
       "82   82            0      6200          -6200             312000   \n",
       "83   83            0      6200          -6200             312000   \n",
       "84   84         2000      6200          -4200             314000   \n",
       "85   85            0      6200          -6200             314000   \n",
       "86   86            0      6200          -6200             314000   \n",
       "87   87            0      6200          -6200             314000   \n",
       "88   88         2000      6200          -4200             316000   \n",
       "89   89            0      6200          -6200             316000   \n",
       "90   90            0      6200          -6200             316000   \n",
       "91   91         2000      6150          -4150             318000   \n",
       "92   92            0      6250          -6250             318000   \n",
       "93   93         2000      6150          -4150             320000   \n",
       "94   94            0      6200          -6200             320000   \n",
       "95   95            0      6200          -6200             320000   \n",
       "96   96            0      6250          -6250             320000   \n",
       "97   97            0      6200          -6200             320000   \n",
       "98   98            0      6200          -6200             320000   \n",
       "99   99         2000      6200          -4200             322000   \n",
       "\n",
       "    CumulativeLosses  CumulativeOverall  \n",
       "0               4000              86000  \n",
       "1               8550             147450  \n",
       "2              14350             157650  \n",
       "3              20450             157550  \n",
       "4              26450             159550  \n",
       "5              32550             157450  \n",
       "6              38550             159450  \n",
       "7              44550             163450  \n",
       "8              50600             163400  \n",
       "9              56750             159250  \n",
       "10             62700             163300  \n",
       "11             68850             161150  \n",
       "12             74950             159050  \n",
       "13             81000             159000  \n",
       "14             87200             152800  \n",
       "15             93450             146550  \n",
       "16             99600             142400  \n",
       "17            105650             142350  \n",
       "18            111850             136150  \n",
       "19            118050             131950  \n",
       "20            124050             133950  \n",
       "21            130250             127750  \n",
       "22            136400             123600  \n",
       "23            142650             117350  \n",
       "24            148800             113200  \n",
       "25            155000             107000  \n",
       "26            161200             102800  \n",
       "27            167400              96600  \n",
       "28            173600              90400  \n",
       "29            179800              84200  \n",
       "30            185950              82050  \n",
       "31            192100              77900  \n",
       "32            198250              73750  \n",
       "33            204400              69600  \n",
       "34            210600              65400  \n",
       "35            216650              65350  \n",
       "36            222850              59150  \n",
       "37            228900              59100  \n",
       "38            235100              54900  \n",
       "39            241300              48700  \n",
       "40            247450              44550  \n",
       "41            253550              42450  \n",
       "42            259750              38250  \n",
       "43            265950              32050  \n",
       "44            272150              25850  \n",
       "45            278350              19650  \n",
       "46            284600              13400  \n",
       "47            290800               7200  \n",
       "48            297000               1000  \n",
       "49            303200              -3200  \n",
       "50            309400              -9400  \n",
       "51            315600             -15600  \n",
       "52            321700             -17700  \n",
       "53            327950             -23950  \n",
       "54            334100             -28100  \n",
       "55            340300             -34300  \n",
       "56            346400             -36400  \n",
       "57            352650             -42650  \n",
       "58            358850             -48850  \n",
       "59            365050             -55050  \n",
       "60            371250             -61250  \n",
       "61            377500             -67500  \n",
       "62            383700             -73700  \n",
       "63            389850             -77850  \n",
       "64            396050             -84050  \n",
       "65            402300             -90300  \n",
       "66            408500             -96500  \n",
       "67            414700            -102700  \n",
       "68            420900            -108900  \n",
       "69            427150            -115150  \n",
       "70            433350            -121350  \n",
       "71            439550            -127550  \n",
       "72            445750            -133750  \n",
       "73            452000            -140000  \n",
       "74            458200            -146200  \n",
       "75            464400            -152400  \n",
       "76            470650            -158650  \n",
       "77            476850            -164850  \n",
       "78            483050            -171050  \n",
       "79            489250            -177250  \n",
       "80            495500            -183500  \n",
       "81            501700            -189700  \n",
       "82            507900            -195900  \n",
       "83            514100            -202100  \n",
       "84            520300            -206300  \n",
       "85            526500            -212500  \n",
       "86            532700            -218700  \n",
       "87            538900            -224900  \n",
       "88            545100            -229100  \n",
       "89            551300            -235300  \n",
       "90            557500            -241500  \n",
       "91            563650            -245650  \n",
       "92            569900            -251900  \n",
       "93            576050            -256050  \n",
       "94            582250            -262250  \n",
       "95            588450            -268450  \n",
       "96            594700            -274700  \n",
       "97            600900            -280900  \n",
       "98            607100            -287100  \n",
       "99            613300            -291300  "
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizdf3 = vizdf2[vizdf2['Bin']<=50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bin</th>\n",
       "      <th>FraudSavings</th>\n",
       "      <th>LostSales</th>\n",
       "      <th>OverallSavings</th>\n",
       "      <th>CumulativeSavings</th>\n",
       "      <th>CumulativeLosses</th>\n",
       "      <th>CumulativeOverall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>208000</td>\n",
       "      <td>44550</td>\n",
       "      <td>163450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bin FraudSavings LostSales OverallSavings  CumulativeSavings  \\\n",
       "7    7        10000      6000           4000             208000   \n",
       "\n",
       "   CumulativeLosses  CumulativeOverall  \n",
       "7             44550             163450  "
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vizdf3[vizdf3.CumulativeOverall == vizdf3.CumulativeOverall.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAGDCAYAAABJITbwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAACACklEQVR4nOzdd1zV1RvA8c9hyxRwoYjiBhcq7py4t2Zqao7K9t42tPJn2bRsWJmmmWXmwL13ZeYeiApuhoigTFHgnt8f90pkqKDAl/G8fz9ecM/9jod7Ex7OeI7SWiOEEEIIIUoGK6MDEEIIIYQQ+UeSOyGEEEKIEkSSOyGEEEKIEkSSOyGEEEKIEkSSOyGEEEKIEkSSOyGEEEKIEkSSOyFEkaSUmq2U+l8h37OdUupYYd7zbiml3lZK/ZQP19FKqVp3eO4IpdS6u41BCJE/JLkTQtySUuq0UuqKUio520dlg2OyU0p9opSKsMRzWin12d1eV2u9XWtdNx9CzBOllJdSaqZSKloplaSUOqqUekcp5VTYsdyOUqq6JRG0ud6mtZ6nte5mZFxCiH9IcieEyI2+WmvnbB9R2Z/M/ou+kIwHAoEWgAvQEdhbyDHkC6WUB7ADKAO01lq7AF2BskBNA0MTQhRTktwJIe6IpffmSaVUGBBmaftcKXVOKZWolNqjlGqX7fh/DbMqpToqpSKyPW6ilNpr6bn6FXC4xe2bA0u01lHa7LTW+sds13pNKXXCcq0jSqmBlnZ7pdRlpVSDbMeWt/RMVsghptNKqZeUUgeVUglKqV+VUg7Znn/F0tsWpZR6OPvQplKql+XeSUqpSKXUSzf5Xl4AkoCRWuvTAFrrc1rrZ7XWB2/3uubwvtyjlPrT8n2eU0qNsbRvUUo9nO24MUqp329yjd5KqX2W+51TSr2d7eltls+XLb2mrW+8llKqjVJql+U126WUapPtuS1KqUlKqT8sr806pVQ5y3MOSqmflFJxlvh3KaUq3ux7FULkTJI7IcTdGAC0BPwtj3cBAYAH8DPwW/Zk6GaUUnZAMDDXcu5vwL23OOUv4AWl1BNKqYZKKXXD8yeAdoAb8A7wk1LKS2t9FVgM3J/t2CHAVq31hZvcawjQA/AFGgFjLDH3wJyYdQFqYe49zG4m8KilJ64BsOkm1+8CLNZam27x/ebqdVVKVQNWA18A5S3n7L/FdW8mBRiFufewN/C4UmqA5bn2ls9lLb24O26IwQNYCUwDPIFPgZVKKc9shw0HxgIVADvgeuI7GvN7VtVy7mPAlTuIX4hSTZI7IURuBFt6Ui4rpYKztb+vtY7XWl8B0Fr/pLWO01pnaK0/AeyB3MxhawXYAp9prdO11gsxJzQ38z7wATAC2A1EKqVGX39Sa/2bpVfPpLX+FXPPYgvL0z8Dw7Jda7il7WamWa4VDyzHnDCBOen7QWsdorVOBd6+4bx0wF8p5aq1vqS1vtmwsScQfYv75+V1HQ5s0Fr/Ynkd47TW+2917Zvcb4vW+pDl9TsI/AJ0yOXpvYEwrfVcS7y/AEeBvtmO+UFrfdzy380C/nlN0zG/HrW01pla6z1a68S8xi9EaSfJnRAiNwZorctaPgZkaz+X/SDLEGaoZTjuMuZemHK5uH5lIFJrrbO1nbnZwZZf/F9prdti7l2aDMxSSvlZ4hillNp/PSHF3HN2PY7NgKNSqqVSqjrmxGLJLWI7n+3rVMA5W8zZv/9/vRaYex57AWeUUluVUq1vcv04wOsW98/L61oVc6/lXbG8NpuVUrFKqQTMPWi5eR/B/Lrc+N6dAapke3yz13QusBaYbxnq/lApZZv370CI0k2SOyHE3chKxizzwF7B3KPlrrUuCyQA14dMUwDHbOdWyvZ1NFDlhuFVn1wFoPUVrfVXwCXMPWXVgBnAU4CnJY7D1+PQWmdi7i263/KxQmudlJt73SAa8M72uOoNce3SWvfHPPQYbLlnTjYAA5VSOf48zsXrmt05br4I41av/41+BpYBVbXWbsA32e6nb3qWWRRQ7YY2HyDyNudh6W18R2vtD7QB+mAeHhZC5IEkd0KI/OICZACxgI1SagLgmu35/UAvpZSHUqoS8Fy253ZYzn1GKWWrlBrEP8Oo/6GUes6y+KGMUsrGMiTrAuwDnDAnILGWY8di7rnL7mdgKOZh3VsNyd7KAmCsUspPKeUIvJUtPjtlrv3mprVOBxKBm82p+xTz6zTHkpiilKqilPpUKdWI27+u2c0DuiilhlheF0+lVIDluf3AIKWUozIv+njoFt+bCxCvtU5TSrXAPNx7Xazle6lxk3NXAXWUUsMtMQzFPCdzxS3uh+X77mSZQ2mN+TVL5+avmxDiJiS5E0Lkl7XAGuA45mG4NP49VDkXOACcBtYBv15/Qmt9DRiEebFCPObEa/Et7pUKfIJ5eO8i8CRwr9b6pNb6iOW5HUAM0BD4I/vJWuudmHuyKmNegJBnWuvVmBcNbAbCMS/yALhq+fwAcFoplYh5WHPETa4Tj7mXKh3YqZRKAjZi7p0L5/ava/ZrncU8FPwi5tdxP9DY8vRU4Brm12QO5kTwZp4A3rXEMoFsvY6W+YWTgT8sw96tboghDnOP24uYh5xfAfporS/e4n7XVQIWYk7sQoGtmP+7EULkgfr3FBchhBB3wjLf7zBgr7XOMDoeIUTpJT13Qghxh5RSA5W5dp475tW7yyWxE0IYTZI7IYS4c48CFzCvUM0EHjc2HCGEkGFZIYQQQogSRXruhBBCCCFKEEnuhBBCCCFKEBujAygqypUrp6tXr250GMXC9aH8/27nKYQQQojCsGfPnota6/I5PSfJnUX16tXZvXu30WEIIYQQQtyWUuqmWzTKsKzIs127drFr1632dBdCCCGEUSS5E3kWEhJCSEiI0WEIIYQQIgeS3AkhhBBClCCS3AkhhBBClCCS3AkhhBBClCCS3AkhhBBClCBSCkXk2ZgxY4wOQQghhBA3IT13QgghhBAliCR3Is/+/PNP/vzzT6PDEEIIIUQOJLkTeXb8+HGOHz9udBhCCCGEyIEkd0IIIYQQJYgkd0IIIYQQ+cFkgpAlkJ5maBiS3AkhhBBC3K1zu2BmV/htDBycb2goUgpF5Jmtra3RIQghhBBFw+VzsOFtOLwQnCtB/6+h8f2GhiTJncizESNGGB2CEEIIYayryfDHZ/DnF+bH7V+Gts+BvbORUQGS3AkhhBBC5J7JBAd+gY3vQvJ5aDAYurwNZasaHVkWSe5Enm3duhWADh06GByJEEIIUYjO/AlrxkP0fqgSCEPnQtUWRkf1H5LciTw7deoUIMmdEEKIUuLSaVg/AY4sBdcqMGiGucfOqmiuSy2wqJRSDkqpv5VSB5RSIUqpdyztvkqpnUqpcKXUr0opO0u7veVxuOX56tmuNd7Sfkwp1T1bew9LW7hS6rVs7TneQwghhBAi19ISYf1E+LI5hK2Hjq/DU7uh0ZAim9hBwZZCuQp01lo3BgKAHkqpVsAHwFStdS3gEvCQ5fiHgEuW9qmW41BK+QPDgPpAD+BrpZS1Usoa+AroCfgD91uO5Rb3EEIIIYS4NVMm7JkNXzQ1L5pocC88vQc6vgp2jkZHd1sFNiyrtdZAsuWhreVDA52B4Zb2OcDbwHSgv+VrgIXAl0opZWmfr7W+CpxSSoUD1we4w7XWJwGUUvOB/kqp0FvcQwghhBDi5k5uhbWvQ8xhTN4tOdFlJnszfDn1RyImnZCrSwwIqIJ/ZdcCDvTmCnTOnaV3bQ9QC3Mv2wngstY6w3JIBFDF8nUV4ByA1jpDKZUAeFra/8p22eznnLuhvaXlnJvd48b4HgEeAfDx8bmzb7IUcnQs+n+1CCGEELmltebimVBY/xblIzcQZ1ORr8u8wg8nGmMKTwYOYWutsMnlUGyTqmVLbnKntc4EApRSZYElQL2CvF9eaa2/A74DCAwM1AaHU2wMGTLE6BCEEELkg4xME6fjUjgSnURodCKnL6aQaSpdvw4zUy/T8fwPDNWruYYtH2YMZbX9IGpWKsdTTVzw83LFz8sVHw9HrKyU0eHmSqGsltVaX1ZKbQZaA2WVUjaWnjVvINJyWCRQFYhQStkAbkBctvbrsp+TU3vcLe4hhBBClEoJV9IJjU7M+jh6Polj55O4mmECwNZa4ePhiK110V0okJ+sdCa9rq1hVNrPOJNEeJUBJLd9jUdr1OSVMsV7J6YCS+6UUuWBdEtiVwboinmhw2ZgMDAfGA0stZyyzPJ4h+X5TVprrZRaBvyslPoUqAzUBv4GFFBbKeWLOXkbBgy3nHOze4h8sGHDBgC6dOlicCRCCCFuRmvN3rOXWbw3gi3HYom8fCXrOQ8nO/y8XHigVbWsnqlaFZyxsykdiR3hG2DtG5BwFKrdAz3ep45XI6OjyjcF2XPnBcyxzLuzAhZorVcopY4A85VS/wP2ATMtx88E5loWTMRjTtbQWocopRYAR4AM4EnLcC9KqaeAtYA1MEtrHWK51qs3uYfIBxEREUaHIIQQ4ibOxaeyZF8ki/dGcDouFQdbKzrVrcCIVj74ebni7+VKBRd7zGsWS5nYY+akLnw9uPvC0HlQrzeUsNeiIFfLHgSa5NB+kn9Wu2ZvTwPuu8m1JgOTc2hfBazK7T2EEEKIkigxLZ1VB6NZvC+Sv0/FA9CqhgdPdKpFzwaVcHEo3sOMdy01Hra8D7tmgp0TdPsftHgEbOyNjqxAyA4VQgghRDF0LcPEH+EXWbQ3gvVHYriaYaJGeSde7l6X/gGV8XaXygZkXINd38PWKXA1CZqNhU6vg1M5oyMrUJLcCSGEEEXcxeSr2RZDmFe2hl9IJsOkcXe0ZWjzqgxq6k1jb7fSOdx6I63h+FpY9wbEhUPNztBtMlT0v/25JYAkdyLPXF2Nq90jhBDFUVp6JuEXkkm5mnHbYzUQk5jGkWyJXGzS1aznK7ra4+flSqd6FWjm4077OuVLz0KI3IgJMRchPrkFPGvD8N+gdtcSN6/uViS5E3k2aNAgo0MQQogi60JSWlZSdv3jRGze68fZWVtRq4Iz7WuXx8/LBX8vV+p5ueLhJNul5yg5FjZPhr1zwN4VenwAzR8C69I331CSOyGEEOIOZZo064+cZ+/Zy1mJ3MXka1nPV3ZzwM/LlW7+lajn5YKHY+4SMw9nO2qWdy41NefuSsZV2PkNbPsY0lOhxaPQ4RVw9DA6MsNIcifybM2aNQD06NHD4EiEEMIYWmu2HI9lyqqjHItJws7GijoVnelUt0JW3Tg/LxfK5jKZE3dAawhdBusnwKXTUKeHeRVsudpGR2Y4Se5Enp0/f97oEIQQwjCHIxN4f3Uof4THUc3TkS+HN6FH/UrYSC9b4Ynab55Xd+YPqOAPDywxL5oQgCR3QgghRK5EXr7CJ2uPsWR/JGXL2DKxrz8jWlaTxQyFKek8bJwE++eZh117fwpNR4O1pDPZyashhBBC3ELClXS+3hLOD3+cBuDR9jV5vGNN3Ir5/qPFSnoa7PgStn8KmdegzVPQ7iUoU9boyIokSe6EEEKIHFzLMPHTX2f4YlMYl6+kM7BJFV7sVpcqZcsYHVrpoTUcWQrr34LLZ6FeH+j6LnjWNDqyIk2SO5Fnnp6eRocghBB5lp5pYv6ucyzaE0GGyXTb42OTrhKTeJV7apXjtZ71aFDFrRCiFFmiD8Ca8ZZ5dfVh1DKo0cHoqIoFSe5EnvXt29foEIQQIte01qw7EsMHq49y8mIKDau4UdHF4bbnVXV3ZGjzqnSoU152fShMSTGw6V3YZ5lX12eqeV6dlbXRkRUbktwJIYQosfaevcT7q0LZdfoSNcs78f2oQIL8KkiyVhSlp8HO6bDtE8hIg9ZPQvuXZV7dHZDkTuTZ8uXLAenBE0IUXWfiUvhwzTFWHoqmnLM9kwc2YGhgVSlXUhRpDaHLYd2bcPkM1OkJ3SfLvLq7IMmdyLO4uDijQxBCiBzFp1xj2sYw5u08g42VFc8G1WZc+xo428uvuyIp+gCseR3O/A7l/aReXT6R/9qFEEIUa1prYpOusmhvJF9vCSflagZDm1fl+S51qOB6+7l1wgBJ52HTpH/m1fX+BJqOkXp1+UReRSGEEMXGtQwT4ReSOXo+0bKXaxKh0YnEpZj3c+1crwKv9axHnYouBkcqcpR+BXZ89U+9OplXVyAkuRNCCFEkxSVfzUreQqMTORKdyInYZNIzNUDWfq6d65n3c21WzZ3GVcsaG7TImdYQshjWT4SEc1KvroBJcifyrFKlSkaHIIQoQTIyTZy6mMKRbD1xodGJXEi6mnVMBRd7/Lxc6Vi3An5eLvh5uVKjnJMskCgOIvbA2vFwbidUbAgDvgbf9kZHVaJJcifyrEePHkaHIIQophJS0wnNGlI1J3PHY5K4mmEuKmxrrahZ3pl7apXDz8sVPy9X6nm5UM7Z3uDIRZ4lRMLGd+Dgr+BUAfp9AQEjpF5dIZDkTgghRL7LNGnOxKX8qycuNDqRqIS0rGM8nezw83JlVOtq5iSukiu1KjhjZyO9ccXatRT4Yxr88TloE9zzPLR7EexlHmRhkeRO5NnixYsBGDRokMGRCCGKguSrGRzNmhdnTuaOnU/iSnomANZWihrlnAis7mHpjXPB38uV8i72Uky4JDGZ4NBvsOFtSIqC+gOhyzvgXs3oyEodSe5EniUmJhodghDCAFprIi5dscyN+2dY9Wx8atYxrg42+Fd2ZWjzqvhbhlVrV3TGwVaG4kq0szthzWsQtRcqN4HBs6Baa6OjKrUkuRNCCHFTCanprDwUzfIDURyOTCDpagYASoGvpxMNq7gxJNA7a36cl5uD9MaVJpfPmnvqDi8CFy8Y8A00GgpWMrRuJEnuhBBC/Et6pomtx2JZvC+CDUcucC3TRK0KzgxoUiVrWLVuJRcc7eRXSKl1NQl+n2quWYeCDq9C22fBzsnoyASS3AkhhMA85Ho4MpFFeyNYfiCKuJRreDrZMaKVD4OaeNOgiqv0yAnzvLoDP8PGdyE5BhoOgS4Twc3b6MhENpLciTzz9pZ/xELkp0yTJuVahiH3TkhNZ8XBaBbvjSDsQjJ21lZ09a/IoKZVaF+nPLZSR05cd/p3WDMezh8E7+Yw7GfwDjQ6KpEDSe5EnnXp0sXoEIQotpLS0jl6PulfCxKyryw1SmA1d94b2JDeDb1wc7Q1NBZRxMSfhPUTIHQ5uHrDvTOhwb3miZeiSJLkTggh8iAj08SZ+FRSr94+GdNooi6n/ZPInU/kXPyVrOfdytji5+XCsBZVqVK2TEGGfVN2NlZ0qFOeap4yV0rcIC0Btn0MO78BK1vo9Ca0eQpsjflvVeSeJHcizxYsWADAkCFDDI5EiIKVcCWd0OhESw23JELPm+u3Xd9NIbeuryxtVKUsQwOryspSUbRlZsC+H2HTZEiNg4Dh0PktcPUyOjKRS5LciTxLTU29/UFCFAHpmSZOxqZwMjaZDJO+7fEZJvPx14dLIy//08vm4WSHn5cLD7SqRj0vV8qWyd3QpaeznawsFcXHic2w9nW4cAR82kCP98x160SxIj9thBAlwuXUa//ZeD4sJplrmXnrZbNSUKO8M02ruTOilQ9+Xq74e7lSQXZTECXZxTBY9yYcXwNlq8GQH8Gvn8yrK6YkuRNCFCnhF5JYdyQGffuONlKuZnDMsjgh+56l5ZzNe5aOaVsdPy8XaldwwcE2N6s+Fd7uZWQ3BVF6pMbD1g9h1wywKQNd3oaWj4Otg9GRibsgyZ0QokjQWvPz32d5d/mRXM9ps7FS1CzvTAtfj6x5bH6WPUuFELeQmQ67Z8GW980LJ5qOgk5vgHMFoyMT+UCSO5Fnvr6+RocgSpiEK+mMX3yQVYfO0652OT4a3BgPJ7vbnmdtpbC2kmEjIfIkbL15Xt3F4+DbAbq/B5UaGB2VyEeS3Ik869Chg9EhiBJk79lLPP3zPmIS03itZz0eaVcDK0nYhMh/F0Jh7RtwYiN41IT750OdHjKvrgSS5E4IYQiTSfPttpN8vO4YXm4OLHisNU193I0OS4iSJyUOtrwHu38Ae2fo/j40fxhsbt87LoqnAttXRilVVSm1WSl1RCkVopR61tL+tlIqUim13/LRK9s545VS4UqpY0qp7tnae1jawpVSr2Vr91VK7bS0/6qUsrO021seh1uer15Q32dpNG/ePObNm2d0GKIYu5CUxugf/uaDNUfpUb8SK59pJ4mdEPktPQ3++BymNTEnds0fgmf2Q+snJLEr4Qqy5y4DeFFrvVcp5QLsUUqttzw3VWv9cfaDlVL+wDCgPlAZ2KCUqmN5+iugKxAB7FJKLdNaHwE+sFxrvlLqG+AhYLrl8yWtdS2l1DDLcUML8HstVdLT040OQRRj247H8sKC/SSlZfDewIbc36KqlBgRIj9pDSGLYcPbcPks1O4O3SZB+bpGRyYKSYEld1rraCDa8nWSUioUqHKLU/oD87XWV4FTSqlwoIXluXCt9UkApdR8oL/lep2B4ZZj5gBvY07u+lu+BlgIfKmUUlrnpriCEKIgpGea+GTdcb7ZeoI6FZ35eVwr6lR0MTosIUqWc3+bF0tE7IKKDWHUUqjR0eioRCErlDl3lmHRJsBOoC3wlFJqFLAbc+/eJcyJ31/ZTovgn2Tw3A3tLQFP4LLWOiOH46tcP0drnaGUSrAcfzF/vzMhRE5Sr12vP/dPQeGj55NIvprB8JY+vNXbnzJ2UktOiHwTf8rcU3ckGJwrQf+voPH9YCX/zkqjAk/ulFLOwCLgOa11olJqOjAJ0JbPnwAPFnQcN4ntEeARAB8fHyNCEKLIupCURnzKtdsepzVEXb6StWVXaHQip+JSsooQu9jbUM/LhUFNq9CpXgU61ZU6WkLkmyuXYdtH8Pd3YGUDHV6Dts+AnZPRkQkDFWhyp5SyxZzYzdNaLwbQWsdke34GsMLyMBKomu10b0sbN2mPA8oqpWwsvXfZj79+rQillA3gZjn+X7TW3wHfAQQGBsqQbS7VqVPn9geJYuti8lU+3xDGz3+fJTMX+7Fm5+PhiJ+XC/0CKmdt2+XtXkbm1AmR3zLTzYsktrwPVy5BwAjo/Aa4VjY6MlEEFFhyp8w/zWcCoVrrT7O1e1nm4wEMBA5bvl4G/KyU+hTzgorawN+AAmorpXwxJ23DgOFaa62U2gwMBuYDo4Gl2a41GthheX6TzLfLP23atDE6BFEArlzLZObvJ/lm60mupGcyrHlV7qlVLlfnlnexp24lF1wcbAs4SiFKOa3h+FrzPrBxYeDbHrpNBq9GRkcmipCC7LlrCzwAHFJK7be0vQ7cr5QKwDwsexp4FEBrHaKUWgAcwbzS9kmtdSaAUuopYC1gDczSWodYrvcqMF8p9T9gH+ZkEsvnuZZFGfGYE0IhRA4yTZpFeyP4dN1xziem0dW/Iq/2qEetCs5GhyaEyO78YVj3BpzcAp61pAixuCklHVpmgYGBevfu3UaHUSzMnj0bgDFjxhgah7g7Wmu2Ho9lyuqjHD2fREDVsrzey48Wvh5GhyaEyC4pBjb/D/b9BA5u0HE8BD4I1tJTXpoppfZorQNzek52qBCiFAqJSuD9VUf5PfwiPh6OfDm8Cb0besncOCGKkvQrsOMr+H0qZFyFlo9Dh5ehjBT8FrcmyZ0QpUDK1QyOnk/i6PlEdpyIY+WhaNzK2DKhjz8jWvlgbyPlEoQoMrSGw4vMpU0SzkG9PtD1XfCsaXRkopiQ5E6IEkRrTeTlK/+qLxcanciZ+NR/SpM42PBI+xo80bEWbmVkWEeIIuXcLljzGkTuhkqNYMB08G1ndFSimJHkTohClpaeyZw/T7MtLJb8nPJ6NcNEWEwSiWkZWW3VPR3x83JlYBNv/Lxc8JPSJEIUTZfPmXvqDi+0FCH+2lKEuMC2gBclmCR3Is/q169vdAjFksmkWXogko/XHify8hX8vVxxss+/4VBba0Xfxub6cn5ertSr5IKTvfwTF6JIu5oMf3wGf35hftz+ZWj7HNjLanVx5+Qnv8iz5s2bGx1CsfNn+EXeWx3K4chEGlRx5aPBjWiTyxpyQogSyGSCA7/Axnch+Tw0GAxd3oayVW97qhC3I8mdyLP09HQAbG1lvtbtHDufxPurQ9lyLJYqZcvw2dAA+jWujJWVDIsKUWqd/gPWjofoA1AlEIbOhaotjI5KlCCS3Ik8mzdvHiB17m4lJjGNT9cd57c953Cyt2F8z3qMblMdB1tZlSpEqRV/CtZPgNBl4OoNg76HBvfKvDqR7yS5EyIfJaWlM2PbSWZsP0WGycTYtr481akW7k52RocmhDBKWiJs/xj+mg5WNtDpDWj9FNg5Gh2ZKKEkuRPiLmWaNH+euMjivZGsOXyeK+mZ9GnkxSvd6+HjKT+8hSi1TJmw90fY9D9IvQiNh0PQW+Ba2ejIRAknyZ0Qd+jY+SQW74sgeF8kMYlXcXWwYWDTKtzf3IeG3m5GhyeEMNLJLbD2DYg5DD6toftvUKWp0VGJUkKSOyHyIDbpKssORLF4bwQhUYnYWCk61i3PxL7edK5XQebUCVHaxZ2AdW/CsVVQ1gfumwP+/UFqS4pCJMmdyLOAgACjQyhUaemZbAiNYfHeSLYejyXTpGlYxY2Jff3p27gy5ZztjQ5RCGG0K5dg60fw93dgYw9BE6HVE2DrYHRkohSS5E7kWWlI7rTW7Dp9iSX7IlhxMJqktAwquTowrl0NBjWtQp2KLkaHKIQoCjLTYc9s2PyeOcFr+gB0ehNcKhodmSjFJLkTeZaamgqAo2PJWyxw+mIKi/dFsmRfBOfir+BoZ02PBpUY1MSb1jU9sZb6dEIIAK3h2GpzaZO4MKjeDrq/B16NjI5MCEnuRN4tWLAAKDl17hJS01lxKIrFeyPZc+YSSkHbmuV4vksdutevJFt4CSH+LXIvrHsLzvwOnrXh/vlQp4fMqxNFhvzWEqVWytUM3lp6mBUHormWaaJ2BWde61mP/gGV8XIrY3R4Qoii5vJZ83Zhh34Dx3LQ+xNoOhqsZbceUbRIcidKpUsp1xg7excHIy7zQKtq3BdYlfqVXVHyl7cQ4kZpCbD9E/jrG3PvXLsXoe1z4OBqdGRC5EiSO1HqRF2+wqhZf3M2PpVvRjajW/1KRockhCiKMtNh9yzYMsW8WKLxMOj8Jrh5Gx2ZELckyZ0oVcIvJDNq5k6S0jL48cEWtKrhaXRIQoiiRmtznbp1b0H8CfBtD10nQeUAoyMTIlckuRN5FhgYaHQId2T/ucuM/eFvrK2smP9oK+pXll0khBA3OH8Y1o6HU9ugXB0YvgBqd5PFEqJYkeRO5FmDBg2MDiHPtofF8ujcPXg62/HTQy2p5ulkdEhCiKIk+YJ5D9h9c8HBDXp+BIFjZbGEKJYkuRN5lpCQAICbW/Ho+VpxMIrnf91PzfLO/PhgCyq4SsV4IYRFxlX4azps+xgyrkDLx6DDK1DG3ejIhLhjktyJPFuyZAlQPOrczf3rDBOWHiawmjvfj26OWxn5K1wIgXleXegy87y6y2egTk/o9j8oV8voyIS4a5LciRJJa820jeFM3XCcLn4V+HJ4UxxsrY0OSwhRFETth7Wvw5k/oEJ9eCAYanYyOioh8o0kd6JESb6awbHziSzcE8Evf5/j3qbefHBvQ2ysrYwOTQhhtIRI87y6A7+Aoyf0+QyajgIr+cNPlCyS3IliSWtNxKUrhEYnEhqdZP58PpEzcalZxzzSvgav9aiHlewHK0TplpYIf3wOO740D8e2fcZciNiheMwbFiKvJLkTxcapiyn8uOM0IZHmRC4pLQMwVyio7umEv5cr9zb1xs/LFf/KrlQpK1uICVGqZWbA3tmw+X1IvQgNh0DQW1DWx+jIhChQktyJPGvdunWh3i8u+SrTNoYxb+dZrK0UDaq40T+gMn5ervh5uVK3ogtO9vKfshDCQms4vgbWT4CLx6FaW+j2G1RpanRkQhQK+Y0o8qxu3bqFcp8r1zKZ9ccppm85wZX0TO5vUZVng+pQ3sW+UO4vhCiGovaZV8Ce3g6etWHYL1C3pxQhFqWKJHcizy5evAhAuXLlCuT6mSbNor0RfLruOOcT0+jqX5FXe9SjVgXnArmfEKIEuHwONk2Cg7+aF0v0+hiajZEixKJUkuRO5NmKFSuAgqlzt/V4LO+vCuXo+SQaVy3L58MCaCn7vwohbuZqsnmxxJ/TzI/veQHueU4WS4hSTZI7USSERCUwZfVRtoddxMfDkS+HN6F3Qy+UDKUIIXJiMsHB+bDhHUg+Dw0GQ5eJslhCCCS5EwbTWvPV5nA+WX8ctzK2vNXHn5GtfLC3kbpTQoibOLMD1rwG0fuhSiAMnQtVWxgdlRBFhiR3wjAmk+bdFUeY/edp+gdU5t1+DXBzlPkxQoibuHTavAL2yFJwrQKDZph77KykSLkQ2UlyJwxxLcPEywsPsHR/FA/d48sbvfyk2LAQImdpibD9E/jra7CygY6vQ5unwc7R6MiEKJIkuRN51r59+7s6P/VaBo//tJetx2N5pUddHu9QU+bWCSH+y5QJ+34yr4JNiYXG90PQBHCtbHRkQhRpktyJPKtRo8Ydn3s59RoPzt7F/nOXmTKoIcNayORnIUQOTmyGtW/AhRCo2gqG/wpVmhkdlRDFQoFNVFBKVVVKbVZKHVFKhSilnrW0eyil1iulwiyf3S3tSik1TSkVrpQ6qJRqmu1aoy3HhymlRmdrb6aUOmQ5Z5qydP/c7B4if5w/f57z58/n/byENIZ8u4PDkYl8PaKpJHZCiP+KPQ4/D4W5A+BaMtw3Bx5cI4mdEHlQkLNQM4AXtdb+QCvgSaWUP/AasFFrXRvYaHkM0BOobfl4BJgO5kQNmAi0BFoAE7Mla9OBcdnO62Fpv9k9RD5Ys2YNa9asydM5J2KTuXf6n0RdTmP2g83p0cCrgKITQhRLqfGw6mX4uhWc+RO6vgtP/g31B8juEkLkUYENy2qto4Foy9dJSqlQoArQH+hoOWwOsAV41dL+o9ZaA38ppcoqpbwsx67XWscDKKXWAz2UUlsAV631X5b2H4EBwOpb3EMY4GDEZcb8sAsFzH+kFQ2qSHFRIYRFxjX4+zvY9qG5IHHgWOg4HpwKZgccIUqDQplzp5SqDjQBdgIVLYkfwHmgouXrKsC5bKdFWNpu1R6RQzu3uMeNcT2CuZcQHx8ZIiwIf4Rf5JEfd+PuZMfch1riW87J6JCEEEWB1hC63Fza5NIpqNUVuv0PKtQzOjIhir0CT+6UUs7AIuA5rXVi9lWRWmutlNIFef9b3UNr/R3wHUBgYGCBxlEaLdkXwasLD+FbzokfH2pBRVcHo0MSQhQFUfvMiyXO/AHl/WDkIqjVxeiohCgxCjS5U0rZYk7s5mmtF1uaY5RSXlrraMuw6wVLeyRQNdvp3pa2SP4ZYr3evsXS7p3D8be6hygEKVczmLgshIV7Imjp68F3DwRKcWIhBCRGwcZ34cAv4FgOen8KTUeDtRRuECI/Fdi/KMvK1ZlAqNb602xPLQNGA1Msn5dma39KKTUf8+KJBEtythZ4L9siim7AeK11vFIqUSnVCvNw7yjgi9vcQ+SDoKCgmz4XEpXA07/s49TFFJ4Jqs0znWthYy3V44Uo1a6lwB/T4I/PQWdC2+eg3Yvg4Gp0ZEKUSAX551Jb4AHgkFJqv6XtdcwJ1wKl1EPAGWCI5blVQC8gHEgFxgJYkrhJwC7Lce9eX1wBPAHMBspgXkix2tJ+s3uIfFC1atX/tGmt+XHHGSavCsXd0ZZ5D7ekTU2ZEC1EqWYymXvpNk2CpGioPwi6TAT36kZHJkSJpsyLU0VgYKDevXu30WEUC+fOmde3XE/yLqde4+WFB1l/JIZOdcvz8X2N8XS2NzJEIYTRTm2Hta/D+YPmGnXd3weflkZHJUSJoZTao7UOzOk5megg8mzjxo0AjBkzhl2n43n2l33EJl/lzd5+PHSPr2wlJkRpFnfCvAL26Apw9YZB30ODe8FKpmcIUVgkuRN3RAPTNobx2YbjVPVwZPHjbWnoLfXrhCi1rlyCrR+Za9ZZ20HnN6H1U2BbxujIhCh1JLkTeXY1w8SJ2GQWHD1O/4DK/G9AA1wcZDWsEKVSZjrsmglbp8CVy9D0Aej0BrhUMjoyIUotSe5ErqRey2BdSAyL9kbgfO4SVkrx0eBGDG7mLcOwQpRGWsPxNbDuTYgLB9/20P09qNTQ6MiEKPUkuRM3ZTJp/joVx+K9kaw+FE3KtUyqlC1DD7cyVHB14L7A/66aFUKUAtEHYd0bcGobeNaG+3+FOt1lD1ghighJ7sR/hF9IZvHeCIL3RRKVkIazvQ29G3kxqKk3Lap7cOGCv9EhCiGMkHQeNv0P9v0EZcpCzw8h8EGwlmkZQhQlktwJwFynbvHeSH7ccZoDEQlYKWhXuzyv9qxHN/9KlLGzzjq2UiWZSyNEqZJ+BXZ8CdunQuY1aP0ktH8Jyrjf/lwhRKGT5E6QkJrOa4sPsvrweepWdOHN3n70a1yZCjfZC/bkyZMA1KhRozDDFEIUNpMJDi+EDe9AYgTU6wNd3wXPmkZHJoS4BUnuSrk9Zy7xzC/7iElMY3zPeoxrVwMrq1vPm9m2bRsgyZ0QJdrZv8xFiCP3gFdjGPQtVL/H6KiEELkgyV0pZTJppm89wafrj1O5rAO/PdaaJj4yxCJEqXfpNKyfCEeCwcULBkyHRsOkCLEQxYgkd6XQhaQ0Xvj1AL+HX6RPIy/eG9QQV6lTJ0TplpYA2z+Bv6aDsoYOr0HbZ8DOyejIhBB5JMldKbP1eCwvLthP8tUMPri3IUMCq0qdOiFKs8wM2DsHNr8HqReh8XAIegtcKxsdmRDiDklyV0pcyzDxybpjfLvtJHUruvDLuFbUruhidFhCCCOFb4C1b0JsKFRrC90XQuUmRkclhLhLktyVAmfjUnl6/j4OnLvMiJY+vNXHHwdb69ufeBN9+vTJx+iEEIUu9ri5CHHYOnCvDkN/Mq+ElV58IUoESe5KsJSrGczYfpLvtp3E2koxfURTejb0uuvrlitXLh+iE0IUutR42DIFdn1vnkvXdRK0fBRs7I2OTAiRjyS5K4EyMk38tieCT9cfJzbpKj0bVOKN3n54uzvmy/WPHTsGQN26dfPlekKIApaZbk7otkyBq4nQbCx0eh2c5A81IUoiSe5KEK01m45eYMrqo4RdSKapT1m+GdmUZtU88vU+O3bsACS5E6LI0xqOrzUPwcaFQ41O0P09qChbCApRkklyV0Icikhg8qoj/HUyHt9yTnwzsind61eSlbBClFYxIeYixCe3gGdtGL4AaneTeXWlTHp6OhEREaSlpRkdirhDDg4OeHt7Y2ub+5JluUrulFLPaq0/v12bKHzn4lP5eN0xlu6PwsPJjnf61Wd4Sx9sraXgqBClUnIsbJ5sLm9i7wo9PoDmD4G11LIsjSIiInBxcaF69eryx34xpLUmLi6OiIgIfH19c31ebnvuRgM3JnJjcmgThSQj08RH647xw++nUQqe7FSTRzvUlGLEQpRWGVdh5zew7WO4lgLNx0HH18Axf6dliOIlLS1NErtiTCmFp6cnsbGxeTrvlsmdUup+YDjgq5Ralu0pFyA+z1GKfPPttpN8u/Ukg5pW4eXudfFyK2N0SEIII2gNocth/VvmrcNqd4du/4PydYyOTBQRktgVb3fy/t2u5+5PIBooB3ySrT0JOJjnu4l8ERqdyGcbjtO7oRef3Ne40P/hDhw4sFDvJ4S4iegDsOZ1OPM7lPeDkYuhVpDRUQnxL9bW1jRs2DDrcXBwMNWrV8/Xe1SvXp3du3f/p1TXrFmzmDp1KkopTCYTkydPpn///nm+/oQJE2jfvj1dunTJr5AL1C2TO631GeAM0LpwwhG3cy3DxAsLDuBWxo5JAxoY8heZm5tbod9TCJFN0nnYOAn2zzMPu/b+FJqOBmtZIyeKnjJlyrB///4cn9Nao7XGyir/54lHREQwefJk9u7di5ubG8nJyXke3rzu3XffzefoClauXk2l1CClVJhSKkEplaiUSlJKJRZ0cOK/pm0MIzQ6kfcHNcTDyc6QGA4fPszhw4cNubcQpVr6FfOcumlN4eCv0OYpeHqvZcGEJHaieDh9+jR169Zl1KhRNGjQgHPnzvH4448TGBhI/fr1mThxYtax1atX5+LFiwDs3r2bjh07AhAXF0e3bt2oX78+Dz/8MFrr/9znwoULuLi44OzsDICzs3PWooQZM2bQvHlzGjduzL333ktqaioJCQlUq1YNk8kEQEpKClWrViU9PZ0xY8awcOHCrJgmTpxI06ZNadiwIUePHgUgNjaWrl27ZsVUrVo1Ll68SEpKCr1796Zx48Y0aNCAX3/9tWBe2Gxy+9PgQ6Cv1jq0IIMRt7bv7CW+3hLO4GbedPWvaFgcu3fvBqBBgwaGxSBEqaI1hCyG9RMh4Zx5q7Cu74JnTaMjE8XIO8tDOBKVv/0y/pVdmdi3/i2PuXLlCgEBAQD4+voydepUwsLCmDNnDq1atQJg8uTJeHh4kJmZSVBQEAcPHqRRo0Y3veY777zDPffcw4QJE1i5ciUzZ878zzGNGzemYsWK+Pr6EhQUxKBBg+jbty8AgwYNYty4cQC8+eabzJw5k6effpqAgAC2bt1Kp06dWLFiBd27d8+xBEm5cuXYu3cvX3/9NR9//DHff/8977zzDp07d2b8+PGsWbMmK6Y1a9ZQuXJlVq5cCUBCQsJtXtW7l9t+0BhJ7Ix15VomLy44QCVXByb0lQKkQpQaEXtgVndY+CA4lIXRy2HYPEnsRLFxfVh2//79LFmyBIBq1aplJXYACxYsoGnTpjRp0oSQkBCOHDlyy2tu27aNkSNHAtC7d2/c3d3/c4y1tTVr1qxh4cKF1KlTh+eff563334bMI9AtWvXjoYNGzJv3jxCQkIAGDp0aFbP2vz58xk6dGiO9x80aBAAzZo14/Tp0wD8/vvvDBs2DIAePXpkxdSwYUPWr1/Pq6++yvbt2wtlalNue+52K6V+BYKBq9cbtdaLCyIo8V8frj3KyYspzHu4pZQ7EaI0SIiEje+Yh1+dKkC/LyBgBFhZGx2ZKKZu18NWmJycnLK+PnXqFB9//DG7du3C3d2dMWPGZBVdtrGxyRomvZNCzEopWrRoQYsWLejatStjx47l7bffZsyYMQQHB9O4cWNmz57Nli1bAOjXrx+vv/468fHx7Nmzh86dO+d4XXt7837M1tbWZGRk3DKGOnXqsHfvXlatWsWbb75JUFAQEyZMyPP3khe5Te5cgVSgW7Y2DUhyVwj+PHGRH/44zejW1Whbq2TtBZlhymBH1A52x+xGa41SCoXK+gxgpayyHttb29OpaidqlK1x1/e+knGFPyP/pIxNGfw8/XB3+O9ffkIUumsp8Mc0+ONz0Ca45wVo9wLYuxgdmRAFIjExEScnJ9zc3IiJiWH16tVZc+uqV6/Onj176NmzJ4sWLco6p3379vz888+8+eabrF69mkuXLv3nulFRUZw/f56mTZsCsH//fqpVqwZAUlISXl5epKenM2/ePKpUqQKY5+U1b96cZ599lj59+mBtnfs/ptq2bcuCBQt49dVXWbduXVZMUVFReHh4MHLkSMqWLcv3339/R69TXuQqudNajy3oQETOktLSefm3g1T3dOTVnvWMDiffHIs/xrITy1h5ciVxaXHYKBusrazRWmPCBBr09f9p8+frPtv7GY3KN2JArQH0qN4DF7vc/9LTWrP3wl6WnVjG2tNrSUlPyXrOy8kLPw8//D398fM0fy5XpmQl06IIM5ng0G+w4W1IioL6A6HLO+BezejIhChQjRs3pkmTJtSrV4+qVavStm3brOcmTpzIQw89xFtvvZWV8F1vv//++6lfvz5t2rTBx8fnP9dNT0/npZdeIioqCgcHB8qXL88333wDwKRJk2jZsiXly5enZcuWJCUlZZ03dOhQ7rvvvqzevNy6HtPcuXNp3bo1lSpVwsXFhS1btvDyyy9jZWWFra0t06dPz9sLdAdUTitM/nOQUj8A/zlQa/1gQQRlhMDAQH19oUBR8tqigyzYfY7fHmtNs2pFo9J8amoqAI6Ojnk670LqBVadXMWyk8sIuxSGjZUNHbw70LdmX9pXaY/tbbZH0loTlxbHypMrWRK2hBMJJ3CwdqBLtS4MrDWQwEqBWKmcp5GeSzrH8hPLWXZiGZHJkTjaONKtejf61OgDQGhcKEfijhAaH8rpxNNZ51UoUyEr2fPz8MPP04+KjhWlKKjIX2d3wtrxELkHKjeB7u9DNalAJe5eaGgofn5+RodRKly9ehVra2tsbGzYsWMHjz/++E1LwORVTu+jUmqP1jowp+NzOyy7ItvXDsBAIOqOIhS5tuloDPN3neOxDjWLTGIHeUvqUtNT2XRuEytOrGBH9A5M2kSjco14o+Ub9Kjeg7IOZXN9LaUU5cqUY3T90YzyH8Xhi4cJDg9m9anVrDi5girOVehfsz/9a/WnsnNlkq8ls/7MepaeWMqemD0oFC28WvBkwJME+QThaPvP99HSq2XW18nXkjkafzQr2TsSd4StEVuzeg/d7d2p51GPep718Pfwp55HPXxcfW6aWApxU5fPmlfAhiwGFy8Y8A00GgoFUPNLCFGwzp49y5AhQzCZTNjZ2TFjxgzDYslVz91/TlLKCvhda90m/0MyRlHrubuUco1un23D08mOpU+1xd4mfydRa62JTonmWPwxjl06xvFLxwm7FIa9tT31POpl9VTV9aiLk63Tv869/pfI9aXt12WYMjibeJZjl45lXXdvzF5SM1LxcvKiT40+9K3ZF1+33G9+nBtpGWlsPLuR4PBgdkbvBKBBuQaEXQojLTON6q7V6VezH31r9qWSU6U7ukdqeirHLx0nND6Uo/FHCY0LJexyGBkm80RaRxtHc8LnUY/KzpX/NW/wei/fv9pQeDl70a5KO+kFLI2uJsHvU+HPL0FZQdtnoO2zYOd0+3OFyAPpuSsZCqrn7ka1gQp3eK7IhQnLQriUco3ZY5vfNLGLuxJHSnoKVsoq5w+sshKHiKSIfyVdxy8dJ+naP3MMfFx8qONehysZV9geuZ2lJ5YC5oTEx9UHPw8/c9Ln4ceRvUdQSpFRKSPrWsfijxF+OZyrmebF1DbKhhpla9DTtye9a/SmWcVmBdaz5WDjQO8aveldozdRyVEsPbGUree20q9mP/rV6kejco3uOoFytHUkoEIAARUCstrSM9M5kXCC0LjQrKRvSfgSrmRcyfV1G5VvxCvNX6Fx+cZ3FZ8oJkyZsP9n2DQJkmOg4RDoMhHcvI2OTAhRguR2zl0S5jl3yvL5PDBea73olicWI0Wp527FwSie+nkfL3atw9NBtXM8ZuHxhUz6axImbcrTtcvYlKGOex3qutelrkdd6rjXoY57nX8NUWqtib0S+6+kJTQulKgU80h8h+gOAGz12gqYhynrePxzzbrudanhVuO2c+hKIpM2kZKekrUQBMhaEHLj4pDtEduZtm8aF69cpJdvL55v9vwd9yyKYuDUdvO8uvOHwLs59JgC3jn+0S1EvpGeu5KhQHrutNayBr+QxCVf5a3gwzT2duPxjjkXKf3h8A98uudT2lZpS2/f3pi06Z8PTJhMls/Z2is7V6aue128Xbxv24OmlKKCYwUqOFagQ9UOWe0JVxM4Gn+UzYs3o9F8HfQ1dT3qUr5MeRlatLBSVrlevTuw9kC6Ve/GzEMzmRMyh01nNzG6/mgebPDgv5JtUczFn4R1b8HRFeDqDffOhAb3gvybEUIUkFwPyyql+gHtLQ+3aK1X3Op4cWe2Ho/lUmo6s8c2wMb630mY1ppp+6bx/aHv6VG9B+/d816h9o652bvR0qsloU7mzUraebcrtHuXVE62TjzT9BkG1xnMZ3s+49uD37IkbAnPNH2GvjX7yiKN4iwtAbZ9BDu/BStb6PwmtH4KbMsYHZkQooTL1W8OpdQU4FngiOXjWaXUewUZWGkVdiEZW2uFf2XXf7WbtInJOyfz/aHvGVxnMFPaTSmVw54lVWXnynzY4UPm9pxLRaeKvPnHmwxfOZy9MXuNDk3kVWYG7JoJ05qaF0w0vA+e3gPtX5bETpRKzs7Od3X+li1b+PPPP3N8LiYmhj59+tC4cWP8/f3p1atXgcdTHOS2W6AX0FVrPUtrPQvoAfS51QlKqVlKqQtKqcPZ2t5WSkUqpfZbPnple268UipcKXVMKdU9W3sPS1u4Uuq1bO2+SqmdlvZflVJ2lnZ7y+Nwy/PVc/k9FglhMUn4lnPCNluvXbopnfHbx/PrsV95sMGDTGg1AWsDtyAaMWIEI0aMMOz+JVlAhQB+6vUT793zHrFXYhm9ZjQvbnmRyORIo0MTuXFiE3zbDla+AOXrwiNbYMDX4OpldGRCFFu3Su4mTJhA165dOXDgAEeOHGHKlCmFHF3RlJcxn7LZvs7NrrezMSeBN5qqtQ6wfKwCUEr5A8OA+pZzvlZKWSulrIGvgJ6AP3C/5ViADyzXqgVcAh6ytD8EXLK0T7UcV2yEXUimdoV/5mylZaTx/ObnWXVqFc82fZbnmz1v+Pw2W1tbbG2l17CgWCkr+tbsy4qBK3ii8RNsi9hGvyX9mLZ3GqnpqUaHJ3JyMQx+HgpzB5q3DxvyI4xZCZUDjI5MiCJp//79tGrVikaNGjFw4MCsrbqmTZuGv78/jRo1YtiwYZw+fZpvvvmGqVOnEhAQwPbt2/91nejoaLy9/1lt3qhRIwCSk5MJCgqiadOmNGzYkKVLl+YYx0cffUTz5s1p1KgREydOBCAlJYXevXvTuHFjGjRowK+//loQL0GByu2cu/eBfUqpzZhXzLYHXrvVCVrrbXnoNesPzNdaXwVOKaXCgRaW58K11icBlFLzgf5KqVCgMzDccswc4G1guuVab1vaFwJfKqWUvpOCfoUsLT2Ts/GpDGxi3uMu+VoyT296mj0xe3ir1VsMqTvE4AjNdu3aBUDz5s0NjqRkK2NThscDHmdg7YF8tvczZhyaQXB4MM82fVbm4xUVqfGw9UPYNQNsypi3C2v5GNg6GB2ZEP+1+jXzau38VKkh9Mx7b9moUaP44osv6NChAxMmTOCdd97hs88+Y8qUKZw6dQp7e3suX75M2bJleeyxx3B2duall176z3WefPJJhg4dypdffkmXLl0YO3YslStXxsHBgSVLluDq6srFixdp1aoV/fr1+1fnyLp16wgLC+Pvv/9Ga02/fv3Ytm0bsbGxVK5cmZUrVwKQkJBw56+PQXL120Fr/QvQClgMLAJaa63vNJV9Sil10DJse32n9irAuWzHRFjabtbuCVzWWmfc0P6va1meT7AcX+SFX0hGa6hdwYVLaZd4aN1D7L+wnyntphSZxA4gJCSEkJAQo8MoNSo5VWJKuyn81OsnvJy8subj7buwz+jQSq/MdPNCiS+awt/fQpOR8MxeuOc5SeyEuI2EhAQuX75Mhw7magyjR49m27ZtgLnnbcSIEfz000/Y2Ny+/6l79+6cPHmScePGcfToUZo0aUJsbCxaa15//XUaNWpEly5diIyMJCYm5l/nrlu3jnXr1tGkSROaNm3K0aNHCQsLo2HDhqxfv55XX32V7du34+aWm8HKoiUvRYzLZzunjVIKrfXiPN5vOjAJc628ScAngGH70yqlHgEeAXLcdLiwhV9IBsDDLZUxax4jMjmSzzt/Tnvv9rc5U5QGjcs3Zm6vuaw6tYqpe6YyavUoelbvyfPNnsfLWeZ0FQqtIWwdrHsTLh4H3w7Q/T2o1MDoyIS4vTvoYStsK1euZNu2bSxfvpzJkydz6NDtexo9PDwYPnw4w4cPp0+fPmzbto2kpCRiY2PZs2cPtra2VK9enbS0tH+dp7Vm/PjxPProo/+55t69e1m1ahVvvvkmQUFBTJgwId++x8KQ29Wys4BZwL1AX8vHLRdU5ERrHaO1ztRam4AZ/DP0GglUzXaot6XtZu1xQFmllM0N7f+6luV5N8vxOcXzndY6UGsdWL58+ZwOKVRhF5KwsU1h4q4niEmNYXqX6ZLYiX+xUlb0qdGH5QOW81jjx9h0bhN9g/vy5b4vZT5eQYsJgbkD4Och5p0mhv0Co5ZKYidEHrm5ueHu7p41f27u3Ll06NABk8nEuXPn6NSpEx988AEJCQkkJyfj4uJCUlJSjtfatGkTqanmn31JSUmcOHECHx8fEhISqFChAra2tmzevJkzZ87859zu3bsza9YskpPNHSuRkZFcuHCBqKgoHB0dGTlyJC+//DJ79xa/qgW57blrpbX2v/1ht6aU8tJaR1seDgSur6RdBvyslPoUqIx5e7O/Mc/vq62U8sWctA0DhmuttWX+32BgPjAaWJrtWqOBHZbnNxWH+XYAx2OSqVjpJNEpUczqPovmlWROm8iZo60jTwY8yaBag5i6d2pWfbzBdQfTv2Z/KjtXNjrEkiMpBjZPhn1zwd4VenwAgQ+CjZ3RkQlRLKSmpv5r0cMLL7zAnDlzeOyxx0hNTaVGjRr88MMPZGZmMnLkSBISEtBa88wzz1C2bFn69u3L4MGDWbp0KV988QXt2v1TY3XPnj089dRT2NjYYDKZePjhh2nevDm+vr707duXhg0bEhgYSL169f4TV7du3QgNDaV169aAuUTKTz/9RHh4OC+//DJWVlbY2toyffr0gn+R8llutx+bCXyitT6S6wsr9QvQESgHxAATLY8DMA/LngYevZ7sKaXewDxEmwE8p7VebWnvBXwGWAOztNaTLe01MCd2HsA+YKTW+qpSygGYCzQB4oFh1xdk3EpR2H6s08dbsKuwnHirbfw1/C9Dy53cyuzZswEYM2aMoXGIf+y/sJ+v9n/FzuidALT0asmAWgMI8gnCwUbmgN2R9Cvw19ew/VPISIMWj5hr1Tl6GB2ZELkm24+VDHndfiy3yV0HzD1i54GrWPaY1Vo3uuuIiwijk7u09Ez8J6yhVqN5eLpofunzi2GxiOIrKjmKpSeWsjR8KZHJkbjYutDTtycDag2gQbkGhpfRKRa0hsOLYMPbkHAO6vaGru9CuVpGRyZEnklyVzIUyN6ywEzgAeAQkLed6kWunLqYgklDouksrdw7Gx2OKKYqO1fm8caP82ijR9l9fjfB4cEsO7GMBccXUNOtJgNrD6R3jd6UK1PO6FCLpnN/w5rxELnbXOJhwNfgK/NehRDFS26Tu1it9bICjaSUOx6ThLJOIiUjgdrutY0O55auVwpv06aNwZGIm7FSVrTwakELrxaMbzmetafXEhwezMe7P+aT3Z9gb22f1YtnpaxQlv+Z/6+wUlZYKSvae7fn6SZPU8GxgsHfUQG7fM7cU3d4IThXgv5fQeP7oYhOjRBCiFvJbXK3Tyn1M7Ac87AswJ2UQhE3EX4hGZsy5ho8ddzrGBzNrR0/fhyQ5K64cLFzYXCdwQyuM5iTl0+y7sw6UtJT0Fqj0Zi0uTNeo//VlpKewsqTK1l7ei0PNniQ0fVHU8amhO2Nei0F/vgc/pgGaGj/CrR9FuxL/t6TQoiSK7fJXRnMSV23bG0ac1FjkQ/CYpLxdI8jBYp8z50ovmqUrcFjZR/L9fFPNH6CqXun8tX+r1gUtojnmz5PT9+exX/unslk7qVbPxGSoqD+IOj6DpQ1vt6lEELcrVwld1rrsTe2KaWkTkc+On4hCcdysZQpUw4PB1mNJ4qGqq5V+bTjp+w6v4uPdn3Eq9tfZd7RebzS/BUal29sdHh3JmI3rH7VPK/OKwDu+wF8WhkdlRBC5Js8bU6plPJXSk2y7P1a/Aq/FFFXMzI5E5eKySaK2mWl104UPc0rNeeX3r/wbpt3iUqOYuSqkby67VXOp5w3OrTcS4yCxY/A90GQEAEDpsO4zZLYCVHAIiIi6N+/P7Vr16ZmzZo8++yzXLt2rcDv6+xsnl5x+vRpGjT4b7Fxk8nEM888Q4MGDWjYsCHNmzfn1KlTd3SvXr16cfny5bsJN1/dNrlTSlVXSo1XSh3EXD/ucaDLzZbfirw7fTGVTFMGCZkRRX6+HYCtrS22trZGhyEKmbWVNQNrD2TlwJWMaziOjWc30mdJn6K/O8a1VNj6IXzRDEKCod2L8PQeCBgOVnn6+1YIkUdaawYNGsSAAQMICwvj+PHjJCcn88Ybb9z1tTMyMm5/0C38+uuvREVFcfDgQQ4dOsSSJUsoW7bsHV1r1apVd3xuQbjlTzal1A5gJebh23u11s2AJK316UKIrdQ4HpOElV0cGfpasZhvN2LECEaMGGF0GMIgjraOPNP0GZYNWEbnqp359uC3dP6tM2//+TYHYw9SZDaEMZng4AL4MtC8w0TtbvDULgiaIAsmhCgkmzZtwsHBgbFjzbO7rK2tmTp1KrNmzSI1NZVWrVoREhKSdXzHjh3ZvXs3KSkpPPjgg7Ro0YImTZqwdKl5E6rZs2fTr18/OnfuTFBQEMnJyQQFBdG0aVMaNmyYdVxuREdH4+XlhZXljzxvb2/c3d0BePzxxwkMDKR+/fpMnDgRgDVr1nDfffdlnb9lyxb69DHvxFq9enUuXrzI6dOn8fPzY9y4cdSvX59u3bpx5coVAHbt2kWjRo0ICAjg5ZdfzupNDAkJoUWLFgQEBNCoUSPCwsLu6LXO7nZz7mKAKkBFoDwQhnkhhchHYReSsXYwD28Vh+ROCDDX1Puww4c84P8Avx77lVWnVrEobFFWPb0+NfrgWcYzz9fNMGWQqTOxt7a/8+DO7IC1r0PUXqjcBO79HqrJ6m5Run3w9wccjT+ar9es51GPV1u8etPnQ0JCaNas2b/aXF1d8fHxITw8nKFDh7JgwQLeeecdoqOjiY6OJjAwkNdff53OnTsza9YsLl++TIsWLejSpQsAe/fu5eDBg3h4eJCRkcGSJUtwdXXl4sWLtGrVin79+uVq0deQIUO455572L59O0FBQYwcOZImTZoAMHnyZDw8PMjMzCQoKIiDBw/SpUsXHnnkEVJSUnBycuLXX39l2LBh/7luWFgYv/zyCzNmzGDIkCEsWrSIkSNHMnbsWGbMmEHr1q157bXXso7/5ptvePbZZxkxYgTXrl0jMzMzV6/9rdyy505rPQBoCOwB3lZKnQLclVIt7vrOIkv4hSTcy8ZjpayoWbam0eHc1tatW9m6davRYYgiomH5hvzvnv+x6b5NTGw9ESc7Jz7e/TFdfuvC85ufZ1vENjJMOQ+fJFxN4O/ov5l7ZC5v/v4mQ5YPoeW8lrSb347pB6ZzJeNK3oKJPwULRsMPPSDpPAz8Fh7eJImdEEXUkCFDWLhwIQALFixg8ODBAKxbt44pU6YQEBBAx44dSUtL4+zZswB07doVDw/zwkOtNa+//jqNGjWiS5cuREZGEhMTk6t7e3t7c+zYMd5//32srKwICgpi48aNWbE0bdqUJk2aEBISwpEjR7CxsaFHjx4sX76cjIwMVq5cSf/+/f9zXV9fXwICAgBo1qwZp0+f5vLlyyQlJWXtYzt8+PCs41u3bs17773HBx98wJkzZyhT5u5LTt12tazWOgH4AfhBKVUBGAJMVUr5aK2r3nUEgrCYZBw8Y6jkWu3ueisKyfUJpx06dDA4ElGUONs5Z9XTC78UTnB4MMtPLmfD2Q1UKFOBfrX6Uce9DmGXwjh26RjH4o8Rk/rPD2EPBw/qutdluN9wIpMj+Xr/1yw6vojnmj1HL99eWKlb/C2algDbPoad34CVDXR6A1o/BXaOhfCdC1E83KqHraD4+/tnJW/XJSYmcvbsWWrVqoWjoyOenp4cPHiQX3/9lW+++QYwJ22LFi2ibt26/zp3586dODk5ZT2eN28esbGx7NmzB1tbW6pXr05aWlqu47O3t6dnz5707NmTihUrEhwcTI0aNfj444/ZtWsX7u7ujBkzJuuaw4YN48svv8TDw4PAwEBcXFxyvOZ11tbWWcOyNzN8+HBatmzJypUr6dWrF99++y2dO9/dTlW5rXMHgNb6AvAl8KVSqtpd3VkAcC3DxKmLKZSvEEUd9wCjwxEiX9Ryr8VLzV/i2abPsi1iG4vDFzPr8CxM2oS1ssbXzZfASoHUda9LXfe61PGo858t0fbE7OGDvz9g/Pbx/BL6C6+0yKH8SmYG7PkBtrwPqfEQMAI6vwmuXoX43QohbiYoKIjXXnuNH3/8kVGjRpGZmcmLL77ImDFjcHQ0//E1dOhQPvzwQxISEmjUyLxlfffu3fniiy/44osvUEqxb9++rCHT7BISEqhQoQK2trZs3ryZM2fO5Dq2vXv3UqlSJSpXrozJZOLgwYM0atSIxMREnJyccHNzIyYmhtWrV9OxY0fA3Knx4IMPMmPGjByHZG+mbNmyuLi4sHPnTlq2bMn8+fOznjt58iQ1atTgmWee4ezZsxw8eLBwk7vstNa5fwXFTZ2JSyGDNJIzY6QMiihxbK1tCaoWRFC1IGJTY4lLi6OGWw3srO1ue26zis2Y32c+y08s5/O9nzNy1Uh6+vbk+abP4+XsBWEbYN0bEHsUqreD7pPBq5jW3hOihFJKsWTJEp544gkmTZqEyWSiV69evPfee1nHDB48mGeffZa33norq+2tt97iueeeo1GjRphMJnx9fVmxYsV/rj9ixAj69u1Lw4YNCQwMpF69ermO7cKFC4wbN46rV80bb7Vo0YKnnnoKBwcHmjRpQr169ahatSpt27bNOsfa2po+ffowe/Zs5syZk6fXYubMmYwbNw4rKys6dOiAm5sbYB4Cnjt3Lra2tlSqVInXX389T9fNiSoyK9sMFhgYqHfv3l3o9111KJqnFgXj5Ps10zpNo5NPp0KPIa9mz54NwJgxYwyNQ5QeqempzDw8kzkhc0CbGK1deOjUARzdfaHrJKjXG4r7rhlCFIDQ0FD8/PyMDkMAycnJWbX3pkyZQnR0NJ9//nmuzs3pfVRK7blZWTop8mSw4zFJWDtEA8Vnpayjo2NWd7oQhcHR1pGn6wxnuWtLOicm8J2Op0/Nuizp/jpX63SVxE4IUeStXLmSgIAAGjRowPbt23nzzTcL7F63HZa1LKJI0VqnKKXKAC8ALsDnWuvoAouslAi7kIybWxzWNo5Udq5sdDi5MmTIEKNDEKVJxjXYNQO2fIDXtWQ+DBzL8Ib9+ejQt0z4610+3vsZvXx7MaD2APw9/Iv/vrdCiBJp6NChDB06tFDulZs5d/OBMUAK8A7mendHgZ+Boj+GWMSFxyRj5xFDDffat14NKERpozUcWwXr3oL4E1CzM3R/Dyr4EQDMrXoPO6N3EhwezJLwJcw/Np867nUYUGsAvWv0lj2ahRCl1i2TO6XUaKAm0FGZ/xweCnwIJAPVlFKjgP1a64MFHmkJlJ5p4uTFJFw9I6jt3tPocHJtw4YNAFkFJYXId+cPmYsQn9oG5erA8N+g9r+HX62UFa0rt6Z15dYkXktkzak1BIcH8+GuD/l0z6d09O7IgFoDaFulLTZWd7x2TIhiT2stPdrF2J2sjbjdT7wtmHvsDgKemHesWA4o4EnL8wl5vqsA4ExcKhkqgWs6pVjsKXtdRESE0SGIkiox2rxV2L6foExZ6PkRBI4F61vvZexq58qQukMYUnfIf2rslStTjn41+zHKf9Qd7ZghRHHm4OBAXFwcnp6ekuAVQ1pr4uLicHBwyNN5t0zutNZnlFJfAGsBEzBOa31WKeUDxGmtz95xxILwC0lY2Vu2HZMyKKI0u5oEf0yDHV9CZjq0ehzavwyOeR9azaqx1+xZtkdsZ0n4EuaEzGHBsQU82uhRRviNwPY2yaIQJYW3tzcRERHExsYaHYq4Qw4ODnh7e+fpnNzsUDFdKTUXMGmtUy3NccD9eQ9RZBcWk4y1vewpK0qxzHTYOwe2TIGUWKg/CILeAo8ad31pWytbOvt0prNPZ04mnOST3Z/wyZ5P+O34b7wY+CKdqnaSngxR4tna2uLr62t0GKKQ5WoGv9Y6OVtih9Y6RWt9ucCiKiWOX0jG2fUCFR0r4mbvZnQ4QhQereHoSvi6Nax8ETxrw8Mb4b4f8iWxu1ENtxp8FfQV33T5BhsrG57d/Czj1o/j+KXj+X4vIYQwmizPNFBYTBI2DjHFrtfO1dUVV1dXo8MQxVXEHvihF8y3bJw97GcYuwq8c6zFma/aVmnLwn4LGd9iPKFxody3/D4m7ZhEfFp8gd9bCCEKiywhM0hGpomTFxMp4x5NHfduRoeTJ4MGDTI6BFEcXToNG96BkMXgVB56fwpNR912sUR+s7WyZbjfcHrX6M3X+7/m12O/svrUah5t/CjD6w2X+XhCiGJPeu4McjY+lQzrGExkFrueOyHyJC0R1k+AL5vD8TXQ4VV4Zh80f6jQE7vs3OzdGN9yPIv7LaZRhUZ8vPtjBi0bxG/HfyPpWpJhcQkhxN2S5M4gYReSs1bKFqcyKABr1qxhzZo1RochijpTJuz+Ab5oCn98Dg0Gw9N7oNPrYO9idHRZapStwTddvuGroK+wtbbl3R3v0nlBZ8ZvH8/O6J2YtMnoEIUQIk9kWNYg4ZbkzlrZ4OtavFYynT9/3ugQRFF3cgusfQNiDoNPaxi+AKo0NTqqW2rv3Z52Vdpx+OJhloQvYfWp1aw4uYIqzlXoX7M//Wv1LzZbBAohSjdJ7gxyPCYJJ+cL+Jb1lTk+ouSIOwHr3jRvG1bWB+6bA/79/7WzRFGmlKJh+YY0LN+QV5q/wsazG1kSvoSvD3zN9APTaeHVggG1BtDFpwsONnkrKiqEEIVFkjuDhMUko9zOU7tsK6NDEeLuXbkEWz+Cv78DGwfo8ja0fBxsi28C5GDjQO8aveldozdRyVEsPbGUpeFLGb99PO/ZvsfQekN5uOHDONk6GR2qEEL8iyR3Bsg0aU7ExWJXNr7YzbcT4l8yM2DPD7D5PXOC13QUdH4TnCsYHVm+quxcmccbP86jjR5l9/ndLDi+gO8Pfc+SsCU80/QZ+tfsj7WVtdFhCiEEIAsqDHEuPpUM62igeO5M4enpiaen7NFZ6oVtgG/awqqXoGJ9eHQb9JtW4hK77KyUFS28WvBxh4/5udfPeLt4M/HPiQxbOYxd53cZHZ4QQgDSc2eIsAvJWDmYk7vi2HPXt29fo0MQRoo9Zl4sEb7evJvEsJ+hbq9iM68uvzQs35C5Peey5vQapu6ZyoNrHyTIJ4gXm71IVdeqRocnhCjFJLkzQNiFJKzsz+Ni60JFx4pGhyNE7qTGw5b3YddMsHOGbpOhxSNgY2d0ZIZRStHTtyedqnbixyM/8v2h79kasZWRfiN5pNEjuNgVnZIvQojSQ4ZlDRAek4yD0wVqu9culhuXL1++nOXLlxsdhigsGddgx1cwLcCc2AWONRchbvNUqU7ssnOwceCRRo+wcuBK+tTow5yQOfRZ0ocFxxaQYcowOjwhRCkjyZ0Bjl1IBNvoYjkkCxAXF0dcXJzRYYiCpjUcWw1ft4K1r0OVQHj8D+j9CTjJnMuclHcsz6S2k5jfZz6+br5M+msSvRf3Zvr+6UQnRxsdnhCilJBh2UJmMmlOxJ/D1jWtWC6mEKVE9EFzvbpTW6FcXRixEGp3NTqqYsPf058fuv/ApnObmH90fladvFZerRhUexCdfDphb21vdJhCiBJKkrtCFnn5CunWUdhSPBdTiBIuIRI2/Q8O/AJl3KHnhxD4oKF7wBZXSimCfIII8gkiMjmSpeFLCQ4P5uVtL+Nq50qfGn0YWHsg9TzqGR2qEKKEkeSukB2PScLaPgYonmVQRAl1NQl+/8w8t06boO0zcM8LUKas0ZGVCFWcq/BEwBM82uhRdp7fyZKwJfx2/Dd+Pvozfh5+DKw9kN41euNq52p0qEKIEqDA5twppWYppS4opQ5na/NQSq1XSoVZPrtb2pVSappSKlwpdVAp1TTbOaMtx4cppUZna2+mlDpkOWeasqxMuNk9ioqwC8lY2Ufj5VS52Fa2r1SpEpUqVTI6DJEfMjPMiySmNYHtH4NfH3hqF3R9VxK7AmBtZU2bym34qMNHbB6ymddavIZJm3hv53v0WNiDOSFzSM9MNzpMIUQxV5ALKmYDPW5oew3YqLWuDWy0PAboCdS2fDwCTAdzogZMBFoCLYCJ2ZK16cC4bOf1uM09ioSwmGTsHGOo61F8h2R79OhBjx43vrWiWNEajq2B6W1g5QvgWRvGbYJ7vwf3akZHVyq42bsxwm8EC/stZH6f+TSq0IiPd3/MgKUD2HR2E1pro0MUQhRTBZbcaa23AfE3NPcH5li+ngMMyNb+ozb7CyirlPICugPrtdbxWutLwHqgh+U5V631X9r8E/DHG66V0z2KhOMX4tE2sdQuK0OywiBR+2FOX/hlKOhMcxHisaugSjOjIyu16nvW55su3/B10NfYWNnw7OZneXjdwxyLP2Z0aEKIYqiw59xV1FpfrwdwHrhewbcKcC7bcRGWtlu1R+TQfqt7/IdS6hHMPYX4+Pjk9XvJM5NJc+LySaxdTNQpxj13ixcvBmDQoEEGRyLyJDEKNk4yL5Zw9IBeH0OzMbJYoghp592OVpVbsfD4Qr7a/xX3Lb+PQbUH8VSTpyhXppzR4QkhignDFlRorbVSqkDHHW53D631d8B3AIGBgQU+BhKVcIVr1pGUAeqULb7JXWJiotEhiLy4lgJ/TIM/p4Epw7xYot2L4OBmdGQiB7ZWttxf7356+fbi24Pf8kvoL6w5vYaHGz7MA/4PSAkVIcRtFXYR4xjLkCqWzxcs7ZFA9s0YvS1tt2r3zqH9VvcwXNiFZKztY7BRdvi4FnxPoSjlTCbY/zN80Qy2ToE63f9ZLCGJXZHnZu/GK81fYUn/JTSv1JzP935O/+D+rD29VubjCSFuqbCTu2XA9RWvo4Gl2dpHWVbNtgISLEOra4FuSil3y0KKbsBay3OJSqlWllWyo264Vk73MFxYTBJW9tH4uvliYyVVaEQBOv07zOgIwY+Dixc8uBbumw3u1Q0OTORVdbfqfNH5C2Z0m4GjrSMvbX2JMWvGEHIxxOjQhBBFVEGWQvkF2AHUVUpFKKUeAqYAXZVSYUAXy2OAVcBJIByYATwBoLWOByYBuywf71rasBzzveWcE8BqS/vN7mG4sJhkbMrE4OdZ1+hQREkVdwLmj4DZvSElDgZ9Dw9vBJ9WRkcm7lIrr1b81uc3JraeyOnE0wxbOYw3fn+DmJQYo0MTQhQxBdZ9pLW+/yZPBeVwrAaevMl1ZgGzcmjfDTTIoT0up3sUBUcvnAfnxGK/M4W3t/ftDxKF68pl2PYR7PwWrO2g85vQ6kmwczQ6MpGPrK2sGVxnMN2rd2fGoRn8dOQn1p9Zz4MNHmR0/dGUsSljdIhCiCJAxgYLidaaU4nhKGeKfRmULl26GB2CuC4zA/bOhk2T4colaDLSnNi5SJHpkszFzoUXmr3AfXXuY+qeqXy1/ysWHl/Ic82eo5dvL6xUYc+4EUIUJfIToJBEJ6Rx1cq85qM4l0ERRciJzfBtO1j5IlTwg0e3Qv8vJbErRaq6VOXTjp/yQ/cf8HDwYPz28Tyw6gEOxB4wOjQhhIEkuSskYReSsXKIxtnWDU8HT6PDuSsLFixgwYIFRodResWdgF/uh7kD4FoyDPkRxqwEr8ZGRyYMElgpkPl95jOp7SSiU6IZuWokr2x7hejk6NufLIQocWRYtpCExSRhbR9DnbJ1sGyDW2ylpqYaHULplJYAWz80z6uzsYegidDqCbB1MDoyUQRYKSsG1BpAt2rdmHl4JnNC5rDp7CZG1x/NQw0ewtFW5l8KUVpIz10h6d2oEmWcYvEvJytlRR6ZMmH3LJjWFHZ8BY2HwtN7oN0LktiJ/3C0deTpJk+zfMByOvt05ruD39FnSR+Cw4MxaZPR4QkhCoEkd4UkXV3kmimN2u7FezGFKGSntsG37WHF81CuNjyyGfp/JfPqxG15OXvxYfsPmdtzLl5OXrz1x1vcv/J+9sTsMTo0IUQBk+SukIRdCgMo9mVQRCGJOwG/DIc5fSEtEQb/AGNXQ+UmRkcmipmACgHM7TWX99u9T9yVOMasGcMLW14gIini9icLIYolmXNXSKJSorBW1tQsW9PoUO6ar6+v0SGUXNnr1dnYQ9AEy7w6qV8m7pyVsqJPjT4E+QQxJ2QOsw7PYsu5LTzg/wDjGo7D2c7Z6BCFEPlIyR6FZoGBgXr37t0Feo8rGVekyKjIWWYG7PkBNr+XrV7dW+BS0ejIRAkUkxLDtH3TWHZiGe727rT0aomfpx/+nv74efjhZi97DwtR1Cml9mitA3N8TpI7s8JI7oTIUfgGWPsGxB6FavdAj/ekrIkoFCEXQ5h1eBaHLx4mKiUqq72KcxX8Pf2zkj0/Tz88HDwMjFQIcSNJ7nJBkrvcmzdvHgAjRowwOJJiLvY4rHsDwtaBuy90mwT1+kAxL5UjiqfLaZc5En+E0LhQQuNDORJ3hHNJ57Ker+RUiU5VOzGw1kD8PP0MjFQIAbdO7mTOnciz9PR0o0Mo3lIuwtYPYNdMsHOCrpOg5aPmOXZCGKSsQ1naVG5Dm8ptstoSryVyNO4oofGhHIg9wKLji/jl6C/Uda/LwNoD6eXbC3cHdwOjFkLkRJI7IQpL+hXY+Q1s/xSupUCz0dDxdXAub3RkQuTI1c6VFl4taOHVAoCEqwmsPrWa4PBgpvw9hY93f0ynqp0YUGsAbSq3wcZKfqUIURTIv0QhCprJBIcXwsZ3IeEc1OkJXd+B8lLQWhQvbvZuDKs3jGH1hnH80nGCw4NZcWIF68+sp3yZ8vSr2Y8BtQZQ3a260aEKUapJcidEQTq1Hda9CdH7zYskBnwNvu2NjkqIu1bHvQ6vNH+F55s+z7aIbSwJX8LskNnMPDyTgPIBDKw9kO7Vu+Nk62R0qEKUOrKgwkIWVOTen3/+CUCbNm1uc2QpFnscNkyEY6vA1dtcr67hfWAldcNFyRWbGsvyk8sJDg/mVMIpytiUoWu1rgyoNYDAioHFfl9tIYoSWS2bC5LciXyRHAtbp8DuH8DW0bz/a6vHpQixKFW01hy8eJAlYUtYc3oNKekpeDt7M6DWAPrX6k8lJ9k+T4i7JcldLkhyJ+5Kehr89bV5sUR6KgQ+CB1fA6dyRkcmhKGuZFxhw5kNBIcH8/f5v1EoWnm1YmDtgXT26Yy9tawSF+JOSHKXC5Lc5d7s2bMBGDNmjKFxFAkmExxeBBvfMS+WqNsLurwD5WUPYSFuFJEUwbITywgODyY6JRoXOxd6+fZiYK2B+Hv6y7CtEHkgde6EKAhn/4K1r0PkHqjUSBZLCHEb3i7ePBHwBI81foy/z/9NcHgwweHB/HrsV2qVrcXAWgPpU7OP7IYhxF2S5E6IvIo/CesnQugycKkMA6ZDo2GyWEKIXLJSVrTyakUrr1Yktkxkzak1BIcH89Huj5i6ZyrtvdszsPZA7qlyj9TOE+IOyL8aIXLryiXY+hH8/R1Y20GnN6D1U2DnaHRkQhRbrnauDKk7hCF1hxB+KZzg8GCWn1zOpnOb8HTwpG/NvgysNZAaZWsYHaoQxYYkd0LcTsY12D0TtkyBtARoMhI6vwkusuJPiPxUy70WLzV/iWebPcv2iO0Ehwcz98hcZofMpnH5xgysNZAevj2kdp4QtyELKixkQUXu7dq1C4DmzZsbHEkB0xqOrTYXIY4/ATU6QrfJUKmB0ZEJUWpcvHKRFSdWsDh8cVbtvG7VujGo9iCaVGgiizBEqSWrZXNBkjvxL9EHzYslTm+HcnXMSV3triC/SIQwhNaaA7EHCA4PZvWp1aRmpFLdtXpW7bxyZaTskChdJLnLBUnuci89PR0AW1tbgyMpAEnnYdMk2DcPyrhDp9eh2RiwLoHfqxDFVGp6KuvOrGNJ2BL2XtiLtbKmnXc7gnyCsLe2R6FAgRVWKKW4/j/z/xUudi40q9gMKyWLoETxJcldLkhyl3slss7dtVTY8SX8/hlkXoNWj0G7l6BMWaMjE0LcwqmEUwSHB7PsxDIuXrmY6/MalmvIK81fIaBCQMEFJ0QBkjp3QtyMyQSHfjMXIU6MBL9+0PUd8JCVeUIUB75uvjzf7HmeavIUEUkRaK3RaEzahEZzvQPj+tcazbH4Y3y570seWP0APav35Llmz1HZubLB34kQ+UeSO1F6ndoO6ydA1F6o3ATu/R6qtTE6KiHEHbC1ssXXzTdXx/p7+tO9end+CPmBHw7/wKZzmxjlP4qHGz6Mo62UNhLFn0w4EKVPzBGYNwTm9IHkCzDwW3h4kyR2QpQijraOPBnwJCsGrqBLtS7MODSD3kt6syRsCSZtMjo8Ie6KJHei9EiIhKVPwjdtzVuHdXkHnt4NjWV3CSFKq0pOlZjSbgrzes2jsnNlJvw5gWErhrHr/C6jQxPijsmCCgtZUJF7+/fvByAgIMDQOHItLcG8UOKvr0GboMUj0O5FcJT9K4UQ/9Bas/rUaqbuncr5lPN0rNqRGm41zGttr6+6zeGztbImsGKg1N0ThUpWy+aCJHcl0PWdJbZ+CFfioeEQ884S7tWMjkwIUYRdybjCjyE/Mjd0LqnpqWg05v/rfy3MuJHU3ROFSZK7XJDkLvdSU1MBcHQsohOPtYaQxbDxXbh0Gnw7QNd3oXKA0ZEJIUqQ60nelYwrrD+z/j919wbWGkg773bYWkmdTJH/JLnLBUnucq9I17k797d5Z4mIXVCxgbmsSc0g2VlCCFEobqy75+ngSb+a/RhQewA13KTEksg/UudOlHyXzsCGt809ds6VoN+XEDAcrKyNjkwIUYpkr7v3e8TvLAlfwo9HfuSHkB8IKB/AmPpj6OzTWebmiQIlyZ0o3tIS4fdPYcfXoKygw6vQ5hmwdzY6MiFEKWZrZUsnn0508unExSsXWX5iOYvCFvHclucIrBjIK81fwc/Tz+gwRQllSP0HpdRppdQhpdR+pdRuS5uHUmq9UirM8tnd0q6UUtOUUuFKqYNKqabZrjPacnyYUmp0tvZmluuHW86VP5FKmswM2P0DfNEUfp8K9Qeay5p0el0SOyFEkVKuTDnGNhhLcP9g3mz5Jicun2DoiqFM+GMCsamxRocnSiAji3t10loHZBsvfg3YqLWuDWy0PAboCdS2fDwCTAdzMghMBFoCLYCJ1xNCyzHjsp3Xo+C/HVFoTmyCb9vBiufAsxaM2wyDvgU3b6MjE0KIm7KxsmFovaGsGLSCUf6jWH5yOX2W9GHGwRmkZaQZHZ4oQYpS5db+wBzL13OAAdnaf9RmfwFllVJeQHdgvdY6Xmt9CVgP9LA856q1/kubV4v8mO1aIh8EBgYSGJjjHM6CdeEozLsP5g6E9FQY8iOMXQ1Vmt7+XCGEKCJc7Vx5qflLLO2/lFZerZi2bxr9g/uz5tQaZJGjyA9GJXcaWKeU2qOUesTSVlFrHW35+jxQ0fJ1FeBctnMjLG23ao/IoV3kkwYNGtCgQYPCu2FSDCx/Dqa3hrM7oeskePJv8O8vq2CFEMWWj6sPn3f+nJndZuJi58LL215m1OpRHIo9ZHRoopgzakHFPVrrSKVUBWC9Uupo9ie11lopVeB/vlgSy0cAfHx8Cvp2JUZCQgIAbm5uBXuja6mw4yv44zPISDPvLNH+FXDyLNj7CiFEIWrh1YJf+/zK0hNLmbZ3GsNXDSfIJ4hBtQfRpnIbbKxk7aPIG0P+i9FaR1o+X1BKLcE8Zy5GKeWltY62DK1esBweCVTNdrq3pS0S6HhD+xZLu3cOx+cUx3fAd2Cuc3d331XpsWTJEqAA69yZMuHAfNg0CZKiwa+veR9Yz5oFcz8hhDCYtZU1g2oPonv17sw8NJNFYYvYeHYj5cuUp2/NvgyoNQBfN1+jwxTFRKEPyyqlnJRSLte/BroBh4FlwPUVr6OBpZavlwGjLKtmWwEJluHbtUA3pZS7ZSFFN2Ct5blEpVQryyrZUdmuJYq6E5vh2w6w9AlwrQxj18DQnySxE0KUCk62TjzT9Bk2DN7AZ50+o75nfeaEzKFfcD8eWPUAi8MWk5KeYnSYoogzoueuIrDEUp3EBvhZa71GKbULWKCUegg4AwyxHL8K6AWEA6nAWACtdbxSahKwy3Lcu1rreMvXTwCzgTLAasuHKMpijsD6CRC+Hsr6wOBZUH+QzKkTQpRKtta2BPkEEeQTlFUnLzg8mIl/TmTK31PoWq0rA2oNILBioBREFv8h249ZyPZjuZev248lRsOW92DfT2DvAu1fNs+ts7G/+2sLIUQJorXm0MVDLAlfwppTa0hOT6ZcmXL4efjh5+mHn4cf9TzqUcW5iiR8pYBsPyaKnqtJ8Mc02PElZKZDi0ehwyvg6GF0ZEIIUSQppWhUvhGNyjfileavsOHMBnZE7SA0PpQ/o/4kU2cC4GLnQj2PelnJnp+HH9XdqsvCjFJEeu4spOcu944dOwZA3bp1835yZgbsnQNbpkDKBfPOEkETwEM21BZCiDuVlpFG2KUwQuNDORp/lKPxRzl+6ThXM68C4GLrQq8avRhYeyD+Hv7Ss1cC3KrnTpI7C0nuCpjWcGwVrJ8IcWHg0xq6/Q+8DSiGLIQQpUCGKYNTCac4Gn+UP6L+YMOZDVzNvEod9zoMqj2I3r69KetQ1ugwxR2S5C4XJLnLvYsXLwJQrly53J0QsQfWvwVn/gDP2tD1HajbSxZLCCFEIUq8lsiaU2tYHLaYkLgQbK1s6ezTmUG1BtHSqyXWVtZGhyjyQJK7XJDkLvdyvaAi/hRsfBdCFoNTeej4GjQdDda2BR6jEEKImzsWf4zg8GCWn1xOwtUEvJy86F+rPwNqDaCKs2zqVBxIcpcLktzl3m2Tu9R42PYR/D0DrGygzdPQ9hnzalghhBBFxrXMa2w6t4ngsGD+jPoTpRSDag/iqYCn8CwjuwEVZbJaVhSO9DT4+1vY9glcS4KAEdDpDXD1MjoyIYQQObCztqNH9R70qN6D6ORofjzyI/OPzmfNqTWMazSOkX4jsbO2MzpMkUeFvkOFKIFMJji4AL5sbi5EXLUFPPYH9P9SEjshhCgmvJy9eLXFqyzuv5hmFZsxdc9U+gf3Z/2Z9cgoX/EiyZ24Oye3woyOsHgclCkLo5bCyIVQ0d/oyIQQQtwBXzdfvgz6km+7fouDjQMvbHmBsWvHciTuiNGhiVySOXcWMucu906ePAmXz1Ij9CsIWwduVaHzW9DwPrCSvxeEEKKkyDBlsDhsMV/u+5LLVy/Tv1Z/nmnyDOUdyxsdWqknCypyQZK7XEqKgc3/M28XZucC7V6Alo+BrYPRkQkhhCggSdeSmHFwBnND52JrZcvDDR9mlP8oHGzkZ79RJLnLBUnubuNaKuz4Cn6fyvkMV6g/kEq9XpbtwoQQohQ5l3iOT/d8yoazG/By8uL5Zs/To3oP2fHCALdK7mQMTdyayQT7f4Evmpl77Gp1Zk3lZ1mTXFcSOyGEKGWqulZlaqepzOo+Czd7N17Z9goPrH6Ag7EHjQ5NZCPJnbi5U9vNiyWCHwOXSjB2NQz9CWzLGB2ZEEIIAzWv1Jz5vefzbpt3iUyOZMSqEYzfPp7zKeeNDk0gde5ETi6Gm0uaHFsJrt4waAY0GCyLJYQQQmSxtrJmYO2BdKvejZmHZjInZA4bzmxgbIOxjKk/BkdbR6NDLLXkt7X4R2o8rHoFvm4Jp7ZB0AR4ejc0GiKJnRBCiBw52TrxTNNnWDZwGR2rdmT6gen0De7L8hPLMWmT0eGVSvIbW5h3lvj9M/g8AHbNgKaj4Jl90O5FGYIVQgiRK1Wcq/BRh4/4seePVChTgdd/f53hK4ez78I+o0MrdWS1rEWpXC1rMsGhBbDpf5BwDur0gC7vQIV6tzzt3LlzAFStWrUwohRCCFHMmLSJlSdX8tnez7iQeoHu1bvzfLPnqeJcxejQSgwphZILpS65O7kF1r0F5w+CVwB0mwS+7Y2OSgghRAmSmp7KnJA5zDo8C5M2Mar+KB5u+DBOtk5Gh1bsSXKXC6UmuYs5Yl4sEb4e3HzM8+oa3JunOXXScyeEECIvzqecZ9reaSw/uRxPB0+eafoM/Wv2x9rK2ujQii2pcycgMQqWPgnftIWIv6HrJHhqFzTK+5ZhGzduZOPGjQUUqBBCiJKmklMl3mv3Hj/3+pmqLlWZ+OdEhq0cxq7zu4wOrUSSUigl3dUk+ONz+PNL0JnQ6gnzQgkpQCyEEKKQNSzfkB97/sja02uZumcqD659kCCfIF5s9iJVXWU0KL9IcldSmTJh31zYNBlSLkD9QdBlIrhXNzoyIYQQpZhSih6+PehYtSNzj8zl+0Pf0y+iHyP9RvJIo0dwsXMxOsRiT4ZlS6LwDfDNPbD8WfDwhYc3wn0/SGInhBCiyHCwcWBco3GsGLiCvjX6MidkDn2W9OG347+Raco0OrxiTZK7kuRCKPx0r/kjPRXumwMPrgXvHOdbCiGEEIYr71ied9u+y/w+86nuWp13d7zL0BVDZT7eXZDVshbFerVs8gXYPBn2/gj2LtD+FWgxDmzsC+R258+b9w6sVKlSgVxfCCFE6aS1Zt2ZdXy6+1OiUqLM8/ECX6Sqi8zHu5GUQsmFYpncpV+BHV+ad5fISIPmD0OHV2WxhBBCiGItLSONH4/8yPeHvifDlMED/g8wruE4nO2cjQ6tyJDkLheKVXKXmQEH58Pm9yExAur1Me8sUa5Wodz+5MmTANSoUaNQ7ieEEKJ0upB6gc/3fs6yE8ukPt4NpM5dSaE1hC6H6W3MNeucK8CYlTBsXqEldgDbtm1j27ZthXY/IYQQpVMFxwpMvmcyv/T+Jas+3v0r75f5eLchyV1xcWobfB8Ev44ENAyZC+M2QfV7jI5MCCGEKFANyjXgx54/8kG7D7h09RIPrn2Q5zc/z7nEc0aHViRJnbuiLmo/bHwHTmwC1yrQ70tofD9Yy1snhBCi9FBK0atGLzr7dGZOyBxmHp7J1oitjPQbybhG46Q+XjbSc1dUxZ2A38bCdx0gah90mwxP74WmD0hiJ4QQotRysHHg0caPsmLgCnrX6M3skNn0WdKHBccWkGHKMDq8IkGSu6Im7gQsfw6+bA7H10D7l+HZA9DmKbB1MDo6IYQQokio4FiBSW0nMb/PfHzdfJn01yTuW34ff0b9aXRohpPVshaGrpY1ZcLxtbDrezixEaxsIXCsObFzrmBMTLdw8eJFAMqVK2dwJEIIIYS5Pt6Gsxv4ZPcnRCZH0sG7Ay8Gvoivm6/RoRUYKYWSC4YkdykXzYWHd/8ACWfBxQuajYVmo8FFCgQLIYQQeXE18yrzQufx3cHvuJpxlWH1hvFY48dws3czOrR8J8ldLhRacqc1RO6Bv2dAyGLIvAbV25l3lKjbC6xtCz6Gu3Ts2DEA6tata3AkQgghxH/FXYnjq/1fsShsES52Ljze+HGG1B2CrVXR/x2bW5Lc5UKBJ3fpV+DQQtg1A6IPgJ0LBNwPgQ9BhXoFd98CMHv2bADGjBljaBxCCCHErRyLP8ZHuz9iZ/ROfN18eSnwJdpVaYdSyujQ7poUMS4K/pgGy56CjGvQ+xN4MRR6fVTsEjshhBCiuKjrUZcZXWfwRecvMGkTT258ksc3PE74pXCjQytQJbamhlKqB/A5YA18r7WeYmhAzcZA9bZQrS2UgL8YhBBCiOJAKUXHqh1pW7kt84/NZ/qB6QxePpjBdQbzRMATeDiUvP3YS2TPnVLKGvgK6An4A/crpfwNDcqlonk3CUnshBBCiEJna23LA/4PsGrgKobUHcLC4wvps7gPsw7PIuFqgtHh5asSmdwBLYBwrfVJrfU1YD7Q3+CYhBBCCGGwsg5leb3l6yzqt4jGFRozdc9UOi3oxMtbX+bPqD8xaZPRId61ErmgQik1GOihtX7Y8vgBoKXW+qkbjnsEeATAx8en2ZkzZwo91uIoIcH8F46bW8lbWi6EEKJ0ORZ/jCXhS1hxcgUJVxPwcvJiQK0B9K/VnyrOVYwO76ZK3WrZ3CZ32RlaxFgIIYQQhrqaeZXN5zazJGwJO6J2ANDSqyUDaw0kqFoQ9tb2Bkf4b7dK7krqgopIoGq2x96WNpEPDh8+DECDBg0MjkQIIYTIH/bW9vSo3oMe1XsQlRzF0hNLCQ4L5tXtr+K605U+NfrwUMOHqOBY9HaOulFJnXO3C6itlPJVStkBw4BlBsdUYuzevRvp5RRCCFFSVXauzOONH2f1vauZ0W0Gbau0ZcHxBfRZ0odvDnzDlYwrRod4SyUyudNaZwBPAWuBUGCB1jrE2KiEEEIIUZxYKStaebXiw/YfsmzAMu6pcg9f7f+KfsH9WHlyJUV1aluJTO4AtNartNZ1tNY1tdaTjY5HCCGEEMVXVZeqfNrxU2Z1n4W7vTuvbX+NkatHciD2gNGh/UeJTe6EEEIIIfJb80rN+aX3L7zb5l2ikqMYuWokr257lejkaKNDyyLJnRBCCCFEHlhbWTOw9kBWDlzJuIbj2Hh2I32D+/Llvi9JTU81OrySWQrlTkgplNxLTTX/h+vo6GhwJEIIIYTxopKj+GzPZ6w+vZryZcrzv3v+R5vKbQr0nrcqhSI9dyLPHB0dJbETQgghLCo7V+bDDh8yt+dcvF28qVDG2HIpJbXOnShA+/fvByAgIMDQOIQQQoiiJKBCAD/2/NHoMKTnTuTd/v37sxI8IYQQQhQtktwJIYQQQpQgktwJIYQQQpQgktwJIYQQQpQgktwJIYQQQpQgslpW5NmIESOMDkEIIYQQNyHJncgzW1tbo0MQQgghxE3IsKzIs127drFr1y6jwxBCCCFEDiS5E3kWEhJCSEiI0WEIIYQQIgeS3AkhhBBClCCS3AkhhBBClCCS3AkhhBBClCCS3AkhhBBClCBKa210DEWCUioWOFPAtykHXCzge4i8k/el6JH3pGiS96XokfekaCqM96Wa1rp8Tk9IcleIlFK7tdaBRsch/k3el6JH3pOiSd6Xokfek6LJ6PdFhmWFEEIIIUoQSe6EEEIIIUoQSe4K13dGByByJO9L0SPvSdEk70vRI+9J0WTo+yJz7oQQQgghShDpuRNCCCGEKEEkuSskSqkeSqljSqlwpdRrRsdTWimlZimlLiilDmdr81BKrVdKhVk+uxsZY2mjlKqqlNqslDqilApRSj1raZf3xSBKKQel1N9KqQOW9+QdS7uvUmqn5efYr0opO6NjLW2UUtZKqX1KqRWWx/KeGEwpdVopdUgptV8ptdvSZujPL0nuCoFSyhr4CugJ+AP3K6X8jY2q1JoN9Lih7TVgo9a6NrDR8lgUngzgRa21P9AKeNLy70PeF+NcBTprrRsDAUAPpVQr4ANgqta6FnAJeMi4EEutZ4HQbI/lPSkaOmmtA7KVPzH055ckd4WjBRCutT6ptb4GzAf6GxxTqaS13gbE39DcH5hj+XoOMKAwYyrttNbRWuu9lq+TMP/iqoK8L4bRZsmWh7aWDw10BhZa2uU9KWRKKW+gN/C95bFC3pOiytCfX5LcFY4qwLlsjyMsbaJoqKi1jrZ8fR6oaGQwpZlSqjrQBNiJvC+Gsgz/7QcuAOuBE8BlrXWG5RD5OVb4PgNeAUyWx57Ie1IUaGCdUmqPUuoRS5uhP79sCvNmQhR1WmutlJIl5AZQSjkDi4DntNaJ5k4JM3lfCp/WOhMIUEqVBZYA9YyNqHRTSvUBLmit9yilOhocjvi3e7TWkUqpCsB6pdTR7E8a8fNLeu4KRyRQNdtjb0ubKBpilFJeAJbPFwyOp9RRStliTuzmaa0XW5rlfSkCtNaXgc1Aa6CsUup6p4D8HCtcbYF+SqnTmKf2dAY+R94Tw2mtIy2fL2D+Q6gFBv/8kuSucOwCaltWNdkBw4BlBsck/rEMGG35ejSw1MBYSh3LvKGZQKjW+tNsT8n7YhClVHlLjx1KqTJAV8xzITcDgy2HyXtSiLTW47XW3lrr6ph/h2zSWo9A3hNDKaWclFIu178GugGHMfjnlxQxLiRKqV6Y50tYA7O01pONjah0Ukr9AnQEygExwEQgGFgA+ABngCFa6xsXXYgCopS6B9gOHOKfuUSvY553J++LAZRSjTBPArfG3AmwQGv9rlKqBuZeIw9gHzBSa33VuEhLJ8uw7Eta6z7ynhjL8vovsTy0AX7WWk9WSnli4M8vSe6EEEIIIUoQGZYVQgghhChBJLkTQgghhChBJLkTQgghhChBJLkTQgghhChBJLkTQgghhChBJLkTQhhKKeWtlFqqlApTSp1QSn1uqQd5/fl7lFJ/K6WOWj4esbS/oZTab/nIzPb1Mzdcf4xSKtby3BGl1Lh8jr+6UupwLo4Znu1xoFJqWj7c214ptUYpdVgp9US29u+UUk1vck721yNEKbVQKeVoee4xpdSou41LCGEsSe6EEIb5f3v3FmJVFcdx/PvLLJpuqAQ+pYiGNOUlxS5oiRE9FAM91EAXrF60glIqkqAywlDBoqgQBLMERQQzrCCiUIyU8G5FWZlEJIkQdtNK59/D+p9pO5yjZyxm7PT7wHD2rL32Xvvsh8Of/1p7//MFxmuAtRExCrgEOA+Yl/uHAiuAmRExGpgMzJB0U0TMi4hxETEOOFzbjoh6QdOq7DcVeFZSX9epHQ50B3cRsSUiHmzcvWk3Ah8CY4C7ACSNBQZExLYTHLcq71U78AfQmde1OCJe/xeuy8z6kYM7M+tP04AjEfEqdNcznQ3cm9mkB4BltUAlIg5SCqfPOZXBsjzQ18AwSddL2i5pt6Slks4GkLRP0sJs/1jSyGxfJqlWCQBJv/Q8f2boNkraln/X5K75wJTMls2WNFXSW3nMYElrJe2StDlfIIykuXld6yXt7ZmRTH8CbcBAoFaM9xngiWbuR5atOhf4sTLmI7m9XtKCvAd7JE3J9vZs25HXPKqZscys7zi4M7P+1A5srTZExE/At8DIevuBLdnea/k2+RHAd8AyoDMiLqe8Wf6+StdD2f4SpbJMsw4AN0TEFZRsWC2LOAfYmNmy53sc8zSwPSLGUCpzVDNnoynZuUnAU1mDt+o9SlZwM/CipA5gW0R8f5Lr7JS0g1KHdDCwrkG/MyNiEjCLUs0FYCbwQmZCJ1LupZmdRhzcmdn/QS2YWQnMAC4CvomIPbn/NeDaSv+Vlc+rezHOQGCJpN3AauDSJo6ZDCwHiIgPgCGSLsh9b0fE75mxPAAcN50cEUcj4vaIGJ/jzQIWSXou19J1NBizNk09lFL27dEG/dbk51ZKEAmwCXhc0mPAsIg43MR3NLM+5ODOzPrTZ8CEakMGNhcDX9Xbn/9/2stxamvMroyIN07enaizfZT8zZR0BnBWz4MoU8o/AGMpWa16fXqjWiP0GCXD2Mj9lKzfVcAhSubw4ROdPEr9yXUcH9jWG7977IhYAXQAh4F3JE078Vcws77m4M7M+tP7QFvtCU1JA4BFlHV2vwEvA3dLGpf7hwALgIX/cNwvgOG19XSUhxE2VPZ3Vj435fY+/g40OyhZup4uBPZHRFeec0C2/wyc3+BaNgJ3QHdB+IM5Nd00SYOAmynBXRvQRQlKz2ni8MmUdYjNjjUC2JsPrrxJeZjDzE4jDu7MrN9k5ugW4FZJXwJ7gCOUtWdExH7gTspU5+fAR8DSiGi0RqzZcY8A9wCrcwq1C1hc6TJI0i7gIUo2DmAJcJ2knZSp2l/rnPoVYHr2GV3psws4JmmnpNk9jpkLTMjx5gPTT+ErPQnMy6DyXWAKZbp1eYP+nbUHIoDxlIcwmnUb8ElOc1/G8WsEzew0oPLbamZmUJ6WBSbmOjczs/8cZ+7MzMzMWogzd2ZmZmYtxJk7MzMzsxbi4M7MzMyshTi4MzMzM2shDu7MzMzMWoiDOzMzM7MW4uDOzMzMrIX8BSH4sJjP5UoNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "plt.title('Fraud Savings Calculations')\n",
    "plt.ylabel('$ Amount')\n",
    "plt.xlabel('OOT Population % Bins')\n",
    "plt.plot('Bin','CumulativeSavings',data=vizdf3,label='Fraud Savings')\n",
    "plt.plot('Bin','CumulativeLosses',data=vizdf3,label='Lost Sales')\n",
    "plt.plot('Bin','CumulativeOverall',data=vizdf3,label='Overall Savings')\n",
    "plt.axvline(x=5,linestyle='--',color='grey')\n",
    "plt.legend()\n",
    "#plt.savefig('savingscals2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "final_model = MLPClassifier(hidden_layer_sizes = (40,), max_iter = 50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y, test_size = .3)\n",
    "final_model.fit(X_train, y_train)\n",
    "ootpredictions = final_model.predict(X_oot3)\n",
    "ootprobs = final_model.predict_proba(X_oot3)\n",
    "trainpredictions = final_model.predict(X_train)\n",
    "trainprobs = final_model.predict_proba(X_train)\n",
    "testpredictions = final_model.predict(X_test)\n",
    "testprobs = final_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpredictions = list(trainpredictions) + list(testpredictions) + list(ootpredictions)\n",
    "allprobs = list(trainprobs) + list(testprobs) + list(ootprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96397"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93059"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93059"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.Date>'2010-01-14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastviz = data[data.Date>'2010-01-14'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastviz = lastviz[['Recnum','Cardnum','Date','Merchnum','Amount','Fraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "newprobs = [i[1] for i in allprobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastviz['Prob'] = newprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Cardnum</th>\n",
       "      <th>Date</th>\n",
       "      <th>Merchnum</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>3345</td>\n",
       "      <td>5142289869</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>602608969534</td>\n",
       "      <td>333.47</td>\n",
       "      <td>0</td>\n",
       "      <td>7.020783e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>3346</td>\n",
       "      <td>5142148452</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>4.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1.328267e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>3347</td>\n",
       "      <td>5142184598</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>680655463</td>\n",
       "      <td>271.93</td>\n",
       "      <td>0</td>\n",
       "      <td>7.083186e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>3348</td>\n",
       "      <td>5142148452</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1.752956e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>3349</td>\n",
       "      <td>5142195887</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>4503082616100</td>\n",
       "      <td>16.28</td>\n",
       "      <td>0</td>\n",
       "      <td>1.006046e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96392</th>\n",
       "      <td>96749</td>\n",
       "      <td>5142276053</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>3500000006160</td>\n",
       "      <td>84.79</td>\n",
       "      <td>0</td>\n",
       "      <td>4.112103e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96393</th>\n",
       "      <td>96750</td>\n",
       "      <td>5142225701</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>8090710030950</td>\n",
       "      <td>118.75</td>\n",
       "      <td>0</td>\n",
       "      <td>3.085791e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96394</th>\n",
       "      <td>96751</td>\n",
       "      <td>5142226486</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>4503057341100</td>\n",
       "      <td>363.56</td>\n",
       "      <td>0</td>\n",
       "      <td>6.366279e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96395</th>\n",
       "      <td>96752</td>\n",
       "      <td>5142244619</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>8834000695412</td>\n",
       "      <td>2202.03</td>\n",
       "      <td>0</td>\n",
       "      <td>2.528124e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96396</th>\n",
       "      <td>96753</td>\n",
       "      <td>5142243247</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>9108347680006</td>\n",
       "      <td>554.64</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517313e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93059 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Recnum     Cardnum        Date       Merchnum   Amount  Fraud  \\\n",
       "3338     3345  5142289869  2010-01-15   602608969534   333.47      0   \n",
       "3339     3346  5142148452  2010-01-15  5509006296254     4.37      0   \n",
       "3340     3347  5142184598  2010-01-15      680655463   271.93      0   \n",
       "3341     3348  5142148452  2010-01-15  5509006296254     3.62      0   \n",
       "3342     3349  5142195887  2010-01-15  4503082616100    16.28      0   \n",
       "...       ...         ...         ...            ...      ...    ...   \n",
       "96392   96749  5142276053  2010-12-31  3500000006160    84.79      0   \n",
       "96393   96750  5142225701  2010-12-31  8090710030950   118.75      0   \n",
       "96394   96751  5142226486  2010-12-31  4503057341100   363.56      0   \n",
       "96395   96752  5142244619  2010-12-31  8834000695412  2202.03      0   \n",
       "96396   96753  5142243247  2010-12-31  9108347680006   554.64      0   \n",
       "\n",
       "               Prob  \n",
       "3338   7.020783e-03  \n",
       "3339   1.328267e-03  \n",
       "3340   7.083186e-04  \n",
       "3341   1.752956e-22  \n",
       "3342   1.006046e-03  \n",
       "...             ...  \n",
       "96392  4.112103e-04  \n",
       "96393  3.085791e-03  \n",
       "96394  6.366279e-02  \n",
       "96395  2.528124e-02  \n",
       "96396  2.517313e-03  \n",
       "\n",
       "[93059 rows x 7 columns]"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cardnum\n",
       "5142205500     9\n",
       "5142225942    10\n",
       "5142232349    10\n",
       "5142245297    12\n",
       "5142206786    20\n",
       "5142249750    24\n",
       "5142183973    25\n",
       "5142111125    26\n",
       "5142189113    27\n",
       "5142299705    27\n",
       "5142116864    28\n",
       "5142176939    28\n",
       "5142197563    30\n",
       "5142182128    31\n",
       "5142197711    32\n",
       "5142235211    32\n",
       "5142179617    32\n",
       "5142152857    32\n",
       "5142271065    34\n",
       "5142138135    36\n",
       "5142847398    37\n",
       "5142214614    37\n",
       "5142202847    37\n",
       "5142220919    38\n",
       "5142212038    39\n",
       "5142181728    39\n",
       "5142160778    40\n",
       "5142189341    41\n",
       "5142199009    45\n",
       "5142140316    46\n",
       "Name: Fraud, dtype: int64"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastviz.groupby('Cardnum')['Fraud'].sum().sort_values().tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardviz = lastviz[lastviz.Cardnum==5142235211]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cardviz['TransactionCount'] = range(1,len(cardviz)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Cardnum</th>\n",
       "      <th>Date</th>\n",
       "      <th>Merchnum</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Prob</th>\n",
       "      <th>TransactionCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16216</th>\n",
       "      <td>16237</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-03-07</td>\n",
       "      <td>2094206450000</td>\n",
       "      <td>417.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16323</th>\n",
       "      <td>16344</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-03-07</td>\n",
       "      <td>809942446330</td>\n",
       "      <td>499.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16568</th>\n",
       "      <td>16590</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-03-07</td>\n",
       "      <td>3404806002325</td>\n",
       "      <td>491.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16575</th>\n",
       "      <td>16597</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-03-07</td>\n",
       "      <td>2094206450000</td>\n",
       "      <td>134.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16928</th>\n",
       "      <td>16952</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-03-08</td>\n",
       "      <td>6000009008310</td>\n",
       "      <td>139.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17031</th>\n",
       "      <td>17055</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-03-09</td>\n",
       "      <td>61563</td>\n",
       "      <td>507.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032417</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20623</th>\n",
       "      <td>20658</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-03-21</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>334.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22846</th>\n",
       "      <td>22895</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-03-29</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>17.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25337</th>\n",
       "      <td>25395</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>809942446330</td>\n",
       "      <td>35.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25833</th>\n",
       "      <td>25893</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-04-08</td>\n",
       "      <td>602608969534</td>\n",
       "      <td>488.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25842</th>\n",
       "      <td>25902</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-04-08</td>\n",
       "      <td>602608969739</td>\n",
       "      <td>46.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26638</th>\n",
       "      <td>26704</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-04-12</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>66.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29356</th>\n",
       "      <td>29436</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-04-22</td>\n",
       "      <td>602608969534</td>\n",
       "      <td>69.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34153</th>\n",
       "      <td>34256</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-05-09</td>\n",
       "      <td>806909482339</td>\n",
       "      <td>129.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34854</th>\n",
       "      <td>34959</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-05-11</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>242.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35765</th>\n",
       "      <td>35871</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>9977060505000</td>\n",
       "      <td>31.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37144</th>\n",
       "      <td>37255</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-05-18</td>\n",
       "      <td>4078000906634</td>\n",
       "      <td>87.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37246</th>\n",
       "      <td>37358</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-05-19</td>\n",
       "      <td>809942446330</td>\n",
       "      <td>88.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37546</th>\n",
       "      <td>37661</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-05-19</td>\n",
       "      <td>809942446330</td>\n",
       "      <td>177.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37655</th>\n",
       "      <td>37770</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-05-20</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>164.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40783</th>\n",
       "      <td>40913</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>42906395331</td>\n",
       "      <td>76.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43078</th>\n",
       "      <td>43216</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-08</td>\n",
       "      <td>08-0616936339</td>\n",
       "      <td>89.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44313</th>\n",
       "      <td>44456</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-13</td>\n",
       "      <td>08-3508309915</td>\n",
       "      <td>132.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45048</th>\n",
       "      <td>45192</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-15</td>\n",
       "      <td>6050276620006</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032994</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46175</th>\n",
       "      <td>46324</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-20</td>\n",
       "      <td>602608969534</td>\n",
       "      <td>20.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46655</th>\n",
       "      <td>46808</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-21</td>\n",
       "      <td>08-0616936339</td>\n",
       "      <td>149.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47837</th>\n",
       "      <td>48000</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-26</td>\n",
       "      <td>6050276620006</td>\n",
       "      <td>22.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48719</th>\n",
       "      <td>48890</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-28</td>\n",
       "      <td>6050276620006</td>\n",
       "      <td>130.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48947</th>\n",
       "      <td>49118</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>6050276620006</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49006</th>\n",
       "      <td>49177</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>6050276620006</td>\n",
       "      <td>120.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49268</th>\n",
       "      <td>49439</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>131090799339</td>\n",
       "      <td>295.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50017</th>\n",
       "      <td>50191</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-07-03</td>\n",
       "      <td>6822400303287</td>\n",
       "      <td>15.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51228</th>\n",
       "      <td>51405</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-07-08</td>\n",
       "      <td>08-0004098330</td>\n",
       "      <td>21.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51537</th>\n",
       "      <td>51716</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-07-10</td>\n",
       "      <td>6050276620006</td>\n",
       "      <td>19.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52210</th>\n",
       "      <td>52390</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>6050276620006</td>\n",
       "      <td>152.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54782</th>\n",
       "      <td>54972</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-07-20</td>\n",
       "      <td>5000580022574</td>\n",
       "      <td>220.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57037</th>\n",
       "      <td>57233</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-07-27</td>\n",
       "      <td>09-3666145263</td>\n",
       "      <td>145.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57714</th>\n",
       "      <td>57912</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-07-31</td>\n",
       "      <td>42906395331</td>\n",
       "      <td>899.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59958</th>\n",
       "      <td>60164</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-05</td>\n",
       "      <td>4500640489700</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60522</th>\n",
       "      <td>60732</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-08</td>\n",
       "      <td>42906395331</td>\n",
       "      <td>899.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60816</th>\n",
       "      <td>61027</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-08</td>\n",
       "      <td>42906395331</td>\n",
       "      <td>165.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62507</th>\n",
       "      <td>62727</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-12</td>\n",
       "      <td>935610288226</td>\n",
       "      <td>32.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62745</th>\n",
       "      <td>62965</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-14</td>\n",
       "      <td>08-9006010336</td>\n",
       "      <td>28.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62759</th>\n",
       "      <td>62979</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-14</td>\n",
       "      <td>6000009008310</td>\n",
       "      <td>157.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63116</th>\n",
       "      <td>63337</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-15</td>\n",
       "      <td>9384000642389</td>\n",
       "      <td>109.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964732</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63316</th>\n",
       "      <td>63539</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-15</td>\n",
       "      <td>935610288226</td>\n",
       "      <td>30.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63442</th>\n",
       "      <td>63665</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-15</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>589.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63450</th>\n",
       "      <td>63673</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-15</td>\n",
       "      <td>9384000642389</td>\n",
       "      <td>194.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63871</th>\n",
       "      <td>64094</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-16</td>\n",
       "      <td>42909087333</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64271</th>\n",
       "      <td>64495</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-17</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>66.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021955</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64307</th>\n",
       "      <td>64531</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-18</td>\n",
       "      <td>6050719130006</td>\n",
       "      <td>17.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64589</th>\n",
       "      <td>64814</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-18</td>\n",
       "      <td>08-9006010336</td>\n",
       "      <td>8.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64675</th>\n",
       "      <td>64900</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-19</td>\n",
       "      <td>4500640489700</td>\n",
       "      <td>28.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65540</th>\n",
       "      <td>65766</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-22</td>\n",
       "      <td>911887996222</td>\n",
       "      <td>58.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65975</th>\n",
       "      <td>66202</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-23</td>\n",
       "      <td>6050276620006</td>\n",
       "      <td>33.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66091</th>\n",
       "      <td>66318</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-23</td>\n",
       "      <td>991809128336</td>\n",
       "      <td>505.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66208</th>\n",
       "      <td>66435</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-23</td>\n",
       "      <td>273506864213</td>\n",
       "      <td>136.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66361</th>\n",
       "      <td>66588</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-24</td>\n",
       "      <td>809942446330</td>\n",
       "      <td>106.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66587</th>\n",
       "      <td>66815</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-24</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>139.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67069</th>\n",
       "      <td>67298</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-25</td>\n",
       "      <td>602608969534</td>\n",
       "      <td>179.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67227</th>\n",
       "      <td>67457</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-27</td>\n",
       "      <td>970615886224</td>\n",
       "      <td>1134.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67569</th>\n",
       "      <td>67806</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-28</td>\n",
       "      <td>6822409024168</td>\n",
       "      <td>85.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67678</th>\n",
       "      <td>67915</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-29</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67808</th>\n",
       "      <td>68046</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-08-29</td>\n",
       "      <td>9384000642389</td>\n",
       "      <td>109.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71463</th>\n",
       "      <td>71737</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-09-09</td>\n",
       "      <td>6822400303287</td>\n",
       "      <td>126.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71481</th>\n",
       "      <td>71755</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-09-09</td>\n",
       "      <td>08-0616936339</td>\n",
       "      <td>212.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74521</th>\n",
       "      <td>74809</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-09-19</td>\n",
       "      <td>456960821331</td>\n",
       "      <td>118.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033795</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77627</th>\n",
       "      <td>77941</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-09-27</td>\n",
       "      <td>602608969284</td>\n",
       "      <td>244.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87228</th>\n",
       "      <td>87572</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>8488900610006</td>\n",
       "      <td>327.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89021</th>\n",
       "      <td>89365</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>472.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89022</th>\n",
       "      <td>89366</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1397.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89023</th>\n",
       "      <td>89367</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>497.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250813</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89025</th>\n",
       "      <td>89369</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>890.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353426</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89031</th>\n",
       "      <td>89375</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1288.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631107</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89034</th>\n",
       "      <td>89378</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>3619.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.836287</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89037</th>\n",
       "      <td>89381</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1310.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974297</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89040</th>\n",
       "      <td>89384</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>204.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973087</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89048</th>\n",
       "      <td>89392</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1016.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986294</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89049</th>\n",
       "      <td>89393</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1215.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993849</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89055</th>\n",
       "      <td>89399</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1172.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996505</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89057</th>\n",
       "      <td>89401</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1496.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998018</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89060</th>\n",
       "      <td>89404</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>935.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998976</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89068</th>\n",
       "      <td>89412</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>3154.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999398</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89074</th>\n",
       "      <td>89418</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>2967.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89075</th>\n",
       "      <td>89419</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>483.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89077</th>\n",
       "      <td>89421</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>528.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89082</th>\n",
       "      <td>89426</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>196.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991423</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89083</th>\n",
       "      <td>89427</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>382.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995259</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89091</th>\n",
       "      <td>89435</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1407.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997363</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89112</th>\n",
       "      <td>89457</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>467.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89114</th>\n",
       "      <td>89459</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>2099.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999607</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89117</th>\n",
       "      <td>89462</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>413.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89120</th>\n",
       "      <td>89465</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>354.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89121</th>\n",
       "      <td>89466</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1640.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89128</th>\n",
       "      <td>89473</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>468.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89129</th>\n",
       "      <td>89474</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>376.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89130</th>\n",
       "      <td>89475</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>8296.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89134</th>\n",
       "      <td>89479</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>298.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89174</th>\n",
       "      <td>89520</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>547.17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89183</th>\n",
       "      <td>89529</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1694.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89186</th>\n",
       "      <td>89532</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>194.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89858</th>\n",
       "      <td>90204</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>19906412332</td>\n",
       "      <td>49.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Recnum     Cardnum        Date       Merchnum   Amount  Fraud  \\\n",
       "16216   16237  5142235211  2010-03-07  2094206450000   417.90      0   \n",
       "16323   16344  5142235211  2010-03-07   809942446330   499.66      0   \n",
       "16568   16590  5142235211  2010-03-07  3404806002325   491.35      0   \n",
       "16575   16597  5142235211  2010-03-07  2094206450000   134.35      0   \n",
       "16928   16952  5142235211  2010-03-08  6000009008310   139.16      0   \n",
       "17031   17055  5142235211  2010-03-09          61563   507.80      0   \n",
       "20623   20658  5142235211  2010-03-21   602608969284   334.29      0   \n",
       "22846   22895  5142235211  2010-03-29   602608969284    17.37      0   \n",
       "25337   25395  5142235211  2010-04-06   809942446330    35.97      0   \n",
       "25833   25893  5142235211  2010-04-08   602608969534   488.00      0   \n",
       "25842   25902  5142235211  2010-04-08   602608969739    46.99      0   \n",
       "26638   26704  5142235211  2010-04-12   602608969284    66.99      0   \n",
       "29356   29436  5142235211  2010-04-22   602608969534    69.23      0   \n",
       "34153   34256  5142235211  2010-05-09   806909482339   129.99      0   \n",
       "34854   34959  5142235211  2010-05-11   602608969284   242.82      0   \n",
       "35765   35871  5142235211  2010-05-15  9977060505000    31.52      0   \n",
       "37144   37255  5142235211  2010-05-18  4078000906634    87.00      0   \n",
       "37246   37358  5142235211  2010-05-19   809942446330    88.13      0   \n",
       "37546   37661  5142235211  2010-05-19   809942446330   177.11      0   \n",
       "37655   37770  5142235211  2010-05-20   602608969284   164.64      0   \n",
       "40783   40913  5142235211  2010-06-01    42906395331    76.78      0   \n",
       "43078   43216  5142235211  2010-06-08  08-0616936339    89.94      0   \n",
       "44313   44456  5142235211  2010-06-13  08-3508309915   132.25      0   \n",
       "45048   45192  5142235211  2010-06-15  6050276620006     7.92      0   \n",
       "46175   46324  5142235211  2010-06-20   602608969534    20.87      0   \n",
       "46655   46808  5142235211  2010-06-21  08-0616936339   149.30      0   \n",
       "47837   48000  5142235211  2010-06-26  6050276620006    22.83      0   \n",
       "48719   48890  5142235211  2010-06-28  6050276620006   130.96      0   \n",
       "48947   49118  5142235211  2010-06-29  6050276620006     2.02      0   \n",
       "49006   49177  5142235211  2010-06-29  6050276620006   120.76      0   \n",
       "49268   49439  5142235211  2010-06-29   131090799339   295.47      0   \n",
       "50017   50191  5142235211  2010-07-03  6822400303287    15.31      0   \n",
       "51228   51405  5142235211  2010-07-08  08-0004098330    21.15      0   \n",
       "51537   51716  5142235211  2010-07-10  6050276620006    19.80      0   \n",
       "52210   52390  5142235211  2010-07-12  6050276620006   152.31      0   \n",
       "54782   54972  5142235211  2010-07-20  5000580022574   220.80      0   \n",
       "57037   57233  5142235211  2010-07-27  09-3666145263   145.16      0   \n",
       "57714   57912  5142235211  2010-07-31    42906395331   899.96      0   \n",
       "59958   60164  5142235211  2010-08-05  4500640489700    15.00      0   \n",
       "60522   60732  5142235211  2010-08-08    42906395331   899.96      0   \n",
       "60816   61027  5142235211  2010-08-08    42906395331   165.60      0   \n",
       "62507   62727  5142235211  2010-08-12   935610288226    32.16      0   \n",
       "62745   62965  5142235211  2010-08-14  08-9006010336    28.47      0   \n",
       "62759   62979  5142235211  2010-08-14  6000009008310   157.02      0   \n",
       "63116   63337  5142235211  2010-08-15  9384000642389   109.75      0   \n",
       "63316   63539  5142235211  2010-08-15   935610288226    30.51      0   \n",
       "63442   63665  5142235211  2010-08-15   602608969284   589.68      0   \n",
       "63450   63673  5142235211  2010-08-15  9384000642389   194.63      0   \n",
       "63871   64094  5142235211  2010-08-16    42909087333    83.14      0   \n",
       "64271   64495  5142235211  2010-08-17   602608969284    66.99      0   \n",
       "64307   64531  5142235211  2010-08-18  6050719130006    17.23      0   \n",
       "64589   64814  5142235211  2010-08-18  08-9006010336     8.57      0   \n",
       "64675   64900  5142235211  2010-08-19  4500640489700    28.36      0   \n",
       "65540   65766  5142235211  2010-08-22   911887996222    58.50      0   \n",
       "65975   66202  5142235211  2010-08-23  6050276620006    33.18      0   \n",
       "66091   66318  5142235211  2010-08-23   991809128336   505.00      0   \n",
       "66208   66435  5142235211  2010-08-23   273506864213   136.25      0   \n",
       "66361   66588  5142235211  2010-08-24   809942446330   106.86      0   \n",
       "66587   66815  5142235211  2010-08-24   602608969284   139.42      0   \n",
       "67069   67298  5142235211  2010-08-25   602608969534   179.56      0   \n",
       "67227   67457  5142235211  2010-08-27   970615886224  1134.00      0   \n",
       "67569   67806  5142235211  2010-08-28  6822409024168    85.49      0   \n",
       "67678   67915  5142235211  2010-08-29   602608969284    34.00      0   \n",
       "67808   68046  5142235211  2010-08-29  9384000642389   109.75      0   \n",
       "71463   71737  5142235211  2010-09-09  6822400303287   126.54      0   \n",
       "71481   71755  5142235211  2010-09-09  08-0616936339   212.90      0   \n",
       "74521   74809  5142235211  2010-09-19   456960821331   118.02      0   \n",
       "77627   77941  5142235211  2010-09-27   602608969284   244.00      0   \n",
       "87228   87572  5142235211  2010-11-17  8488900610006   327.47      0   \n",
       "89021   89365  5142235211  2010-11-25  4353000719908   472.53      1   \n",
       "89022   89366  5142235211  2010-11-25  4353000719908  1397.77      1   \n",
       "89023   89367  5142235211  2010-11-25  4353000719908   497.03      1   \n",
       "89025   89369  5142235211  2010-11-25  4353000719908   890.53      1   \n",
       "89031   89375  5142235211  2010-11-25  4353000719908  1288.90      1   \n",
       "89034   89378  5142235211  2010-11-25  4353000719908  3619.88      1   \n",
       "89037   89381  5142235211  2010-11-25  4353000719908  1310.28      1   \n",
       "89040   89384  5142235211  2010-11-25  4353000719908   204.21      1   \n",
       "89048   89392  5142235211  2010-11-25  4353000719908  1016.16      1   \n",
       "89049   89393  5142235211  2010-11-25  4353000719908  1215.24      1   \n",
       "89055   89399  5142235211  2010-11-25  4353000719908  1172.09      1   \n",
       "89057   89401  5142235211  2010-11-25  4353000719908  1496.60      1   \n",
       "89060   89404  5142235211  2010-11-25  4353000719908   935.85      1   \n",
       "89068   89412  5142235211  2010-11-25  4353000719908  3154.26      1   \n",
       "89074   89418  5142235211  2010-11-25  4353000719908  2967.79      1   \n",
       "89075   89419  5142235211  2010-11-25  4353000719908   483.95      1   \n",
       "89077   89421  5142235211  2010-11-25  4353000719908   528.02      1   \n",
       "89082   89426  5142235211  2010-11-26  4353000719908   196.68      1   \n",
       "89083   89427  5142235211  2010-11-26  4353000719908   382.09      1   \n",
       "89091   89435  5142235211  2010-11-26  4353000719908  1407.17      1   \n",
       "89112   89457  5142235211  2010-11-26  4353000719908   467.46      1   \n",
       "89114   89459  5142235211  2010-11-26  4353000719908  2099.34      1   \n",
       "89117   89462  5142235211  2010-11-26  4353000719908   413.53      1   \n",
       "89120   89465  5142235211  2010-11-26  4353000719908   354.68      1   \n",
       "89121   89466  5142235211  2010-11-26  4353000719908  1640.51      1   \n",
       "89128   89473  5142235211  2010-11-26  4353000719908   468.85      1   \n",
       "89129   89474  5142235211  2010-11-26  4353000719908   376.09      1   \n",
       "89130   89475  5142235211  2010-11-26  4353000719908  8296.63      1   \n",
       "89134   89479  5142235211  2010-11-26  4353000719908   298.14      1   \n",
       "89174   89520  5142235211  2010-11-26  4353000719908   547.17      1   \n",
       "89183   89529  5142235211  2010-11-26  4353000719908  1694.85      1   \n",
       "89186   89532  5142235211  2010-11-26  4353000719908   194.30      1   \n",
       "89858   90204  5142235211  2010-12-01    19906412332    49.63      0   \n",
       "\n",
       "           Prob  TransactionCount  \n",
       "16216  0.004622                 1  \n",
       "16323  0.000576                 2  \n",
       "16568  0.001520                 3  \n",
       "16575  0.001542                 4  \n",
       "16928  0.004311                 5  \n",
       "17031  0.032417                 6  \n",
       "20623  0.004221                 7  \n",
       "22846  0.007903                 8  \n",
       "25337  0.000109                 9  \n",
       "25833  0.000076                10  \n",
       "25842  0.000949                11  \n",
       "26638  0.001303                12  \n",
       "29356  0.001477                13  \n",
       "34153  0.000696                14  \n",
       "34854  0.001701                15  \n",
       "35765  0.001514                16  \n",
       "37144  0.000627                17  \n",
       "37246  0.002043                18  \n",
       "37546  0.001023                19  \n",
       "37655  0.001101                20  \n",
       "40783  0.001467                21  \n",
       "43078  0.002489                22  \n",
       "44313  0.001338                23  \n",
       "45048  0.032994                24  \n",
       "46175  0.012370                25  \n",
       "46655  0.002731                26  \n",
       "47837  0.014835                27  \n",
       "48719  0.000397                28  \n",
       "48947  0.001493                29  \n",
       "49006  0.000955                30  \n",
       "49268  0.000373                31  \n",
       "50017  0.001145                32  \n",
       "51228  0.000003                33  \n",
       "51537  0.001734                34  \n",
       "52210  0.000295                35  \n",
       "54782  0.002945                36  \n",
       "57037  0.001503                37  \n",
       "57714  0.002015                38  \n",
       "59958  0.000306                39  \n",
       "60522  0.000497                40  \n",
       "60816  0.001400                41  \n",
       "62507  0.000870                42  \n",
       "62745  0.000521                43  \n",
       "62759  0.000555                44  \n",
       "63116  0.964732                45  \n",
       "63316  0.000606                46  \n",
       "63442  0.001061                47  \n",
       "63450  0.000377                48  \n",
       "63871  0.003397                49  \n",
       "64271  0.021955                50  \n",
       "64307  0.004580                51  \n",
       "64589  0.000916                52  \n",
       "64675  0.002471                53  \n",
       "65540  0.001610                54  \n",
       "65975  0.001490                55  \n",
       "66091  0.000679                56  \n",
       "66208  0.006359                57  \n",
       "66361  0.001216                58  \n",
       "66587  0.001049                59  \n",
       "67069  0.000129                60  \n",
       "67227  0.000688                61  \n",
       "67569  0.009558                62  \n",
       "67678  0.000632                63  \n",
       "67808  0.001897                64  \n",
       "71463  0.000459                65  \n",
       "71481  0.000089                66  \n",
       "74521  0.033795                67  \n",
       "77627  0.000618                68  \n",
       "87228  0.000411                69  \n",
       "89021  0.000545                70  \n",
       "89022  0.007608                71  \n",
       "89023  0.250813                72  \n",
       "89025  0.353426                73  \n",
       "89031  0.631107                74  \n",
       "89034  0.836287                75  \n",
       "89037  0.974297                76  \n",
       "89040  0.973087                77  \n",
       "89048  0.986294                78  \n",
       "89049  0.993849                79  \n",
       "89055  0.996505                80  \n",
       "89057  0.998018                81  \n",
       "89060  0.998976                82  \n",
       "89068  0.999398                83  \n",
       "89074  0.999756                84  \n",
       "89075  0.999894                85  \n",
       "89077  0.999917                86  \n",
       "89082  0.991423                87  \n",
       "89083  0.995259                88  \n",
       "89091  0.997363                89  \n",
       "89112  0.999502                90  \n",
       "89114  0.999607                91  \n",
       "89117  0.999868                92  \n",
       "89120  0.999905                93  \n",
       "89121  0.999927                94  \n",
       "89128  0.999949                95  \n",
       "89129  0.999958                96  \n",
       "89130  0.999965                97  \n",
       "89134  1.000000                98  \n",
       "89174  1.000000                99  \n",
       "89183  1.000000               100  \n",
       "89186  1.000000               101  \n",
       "89858  0.001789               102  "
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "cardviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cardviz[cardviz.Date=='2010-11-26'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardviz2 = cardviz[cardviz.Date>'2010-08-14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Card Number 5142235211')\n",
    "plt.ylabel('Fraud Score')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=45)\n",
    "plt.plot('Date','Prob',data=cardviz2)\n",
    "#plt.savefig('score_dates.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Card Number 5142235211')\n",
    "plt.ylabel('Fraud Score')\n",
    "plt.xlabel('Transaction Count')\n",
    "plt.plot('TransactionCount','Prob',data=cardviz)\n",
    "plt.axvline(x=70,linestyle='--',color='grey')\n",
    "#plt.savefig('score_trans.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "69 transactions from (03-07 to 11-17)\n",
    "17 transactions on 11-25\n",
    "15 transactions on 11-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Merchnum\n",
       "4063000739258      4\n",
       "5725000466504      4\n",
       "2094206450000      4\n",
       "9977060941600      4\n",
       "4591200814444      7\n",
       "6929               8\n",
       "679613867334       8\n",
       "5000006000095      9\n",
       "5863604000604     10\n",
       "9108234610006     10\n",
       "6170075665        18\n",
       "6899988049601     18\n",
       "8292309000040     20\n",
       "6005030600003     24\n",
       "92891948003       24\n",
       "9900020006406     25\n",
       "6006333528866     27\n",
       "6070095870009     27\n",
       "997674930332      29\n",
       "4503082476300     31\n",
       "938909877224      32\n",
       "9108234610000     33\n",
       "253052983001      33\n",
       "900009045549      36\n",
       "618901687330      36\n",
       "4503738417400     37\n",
       "4620009957157     39\n",
       "8834000695423     46\n",
       "930090121224      53\n",
       "4353000719908    107\n",
       "Name: Fraud, dtype: int64"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastviz.groupby('Merchnum')['Fraud'].sum().sort_values().tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Cardnum</th>\n",
       "      <th>Date</th>\n",
       "      <th>Merchnum</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Prob</th>\n",
       "      <th>TransactionCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>3399</td>\n",
       "      <td>5142241068</td>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>65.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>3489</td>\n",
       "      <td>5142216104</td>\n",
       "      <td>2010-01-16</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>49.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>3732</td>\n",
       "      <td>5142231744</td>\n",
       "      <td>2010-01-18</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>113.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>3827</td>\n",
       "      <td>5142216104</td>\n",
       "      <td>2010-01-18</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>49.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011273</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>3873</td>\n",
       "      <td>5142192111</td>\n",
       "      <td>2010-01-18</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>393.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96174</th>\n",
       "      <td>96530</td>\n",
       "      <td>5142146217</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>240.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96209</th>\n",
       "      <td>96565</td>\n",
       "      <td>5142190418</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>46.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96268</th>\n",
       "      <td>96624</td>\n",
       "      <td>5142178848</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>18.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96316</th>\n",
       "      <td>96672</td>\n",
       "      <td>5142217905</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>68.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96335</th>\n",
       "      <td>96691</td>\n",
       "      <td>5142236933</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>262.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1037 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Recnum     Cardnum        Date       Merchnum  Amount  Fraud      Prob  \\\n",
       "3392     3399  5142241068  2010-01-15  4353000719908   65.99      0  0.000330   \n",
       "3482     3489  5142216104  2010-01-16  4353000719908   49.49      0  0.010863   \n",
       "3725     3732  5142231744  2010-01-18  4353000719908  113.99      0  0.001032   \n",
       "3819     3827  5142216104  2010-01-18  4353000719908   49.49      0  0.011273   \n",
       "3865     3873  5142192111  2010-01-18  4353000719908  393.91      0  0.004064   \n",
       "...       ...         ...         ...            ...     ...    ...       ...   \n",
       "96174   96530  5142146217  2010-12-30  4353000719908  240.95      0  0.000482   \n",
       "96209   96565  5142190418  2010-12-30  4353000719908   46.94      0  0.000432   \n",
       "96268   96624  5142178848  2010-12-30  4353000719908   18.46      0  0.000855   \n",
       "96316   96672  5142217905  2010-12-30  4353000719908   68.90      0  0.000795   \n",
       "96335   96691  5142236933  2010-12-30  4353000719908  262.92      0  0.000657   \n",
       "\n",
       "       TransactionCount  \n",
       "3392                  1  \n",
       "3482                  2  \n",
       "3725                  3  \n",
       "3819                  4  \n",
       "3865                  5  \n",
       "...                 ...  \n",
       "96174              1033  \n",
       "96209              1034  \n",
       "96268              1035  \n",
       "96316              1036  \n",
       "96335              1037  \n",
       "\n",
       "[1037 rows x 8 columns]"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#253052983001\n",
    "merchviz = lastviz[lastviz.Merchnum=='4353000719908']\n",
    "merchviz['TransactionCount'] = range(1,len(merchviz)+1)\n",
    "merchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchviz2 = merchviz[(merchviz.Date>='2010-11-01') & (merchviz.Date<'2010-12-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Cardnum</th>\n",
       "      <th>Date</th>\n",
       "      <th>Merchnum</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Prob</th>\n",
       "      <th>TransactionCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84104</th>\n",
       "      <td>84434</td>\n",
       "      <td>5142170410</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>35.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84124</th>\n",
       "      <td>84454</td>\n",
       "      <td>5142141358</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>34.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84194</th>\n",
       "      <td>84524</td>\n",
       "      <td>5142124208</td>\n",
       "      <td>2010-11-02</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>421.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84283</th>\n",
       "      <td>84613</td>\n",
       "      <td>5142224426</td>\n",
       "      <td>2010-11-02</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>56.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84341</th>\n",
       "      <td>84671</td>\n",
       "      <td>5142132687</td>\n",
       "      <td>2010-11-02</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>21.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84363</th>\n",
       "      <td>84693</td>\n",
       "      <td>5142158538</td>\n",
       "      <td>2010-11-02</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>78.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84396</th>\n",
       "      <td>84726</td>\n",
       "      <td>5142152982</td>\n",
       "      <td>2010-11-02</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>19.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84416</th>\n",
       "      <td>84747</td>\n",
       "      <td>5142150217</td>\n",
       "      <td>2010-11-03</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>248.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84783</th>\n",
       "      <td>85119</td>\n",
       "      <td>5142189945</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>10.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84802</th>\n",
       "      <td>85139</td>\n",
       "      <td>5142170410</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>720.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84806</th>\n",
       "      <td>85143</td>\n",
       "      <td>5142224426</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>433.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84873</th>\n",
       "      <td>85210</td>\n",
       "      <td>5142278177</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>116.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84985</th>\n",
       "      <td>85322</td>\n",
       "      <td>5142184598</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>113.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85318</th>\n",
       "      <td>85655</td>\n",
       "      <td>5142227402</td>\n",
       "      <td>2010-11-06</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>82.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85350</th>\n",
       "      <td>85687</td>\n",
       "      <td>5142134357</td>\n",
       "      <td>2010-11-06</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>247.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85382</th>\n",
       "      <td>85719</td>\n",
       "      <td>5142116345</td>\n",
       "      <td>2010-11-08</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>95.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85446</th>\n",
       "      <td>85785</td>\n",
       "      <td>5142178899</td>\n",
       "      <td>2010-11-08</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>179.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85515</th>\n",
       "      <td>85855</td>\n",
       "      <td>5142116345</td>\n",
       "      <td>2010-11-08</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>33.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85739</th>\n",
       "      <td>86083</td>\n",
       "      <td>5142137416</td>\n",
       "      <td>2010-11-09</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>44.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85757</th>\n",
       "      <td>86101</td>\n",
       "      <td>5142139483</td>\n",
       "      <td>2010-11-09</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>178.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86044</th>\n",
       "      <td>86388</td>\n",
       "      <td>5142180432</td>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>237.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86063</th>\n",
       "      <td>86407</td>\n",
       "      <td>5142139483</td>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>178.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86142</th>\n",
       "      <td>86486</td>\n",
       "      <td>5142178848</td>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>15.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86459</th>\n",
       "      <td>86803</td>\n",
       "      <td>5142146217</td>\n",
       "      <td>2010-11-12</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>63.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86564</th>\n",
       "      <td>86908</td>\n",
       "      <td>5142223659</td>\n",
       "      <td>2010-11-12</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>73.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86641</th>\n",
       "      <td>86985</td>\n",
       "      <td>5142137416</td>\n",
       "      <td>2010-11-13</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>35.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86657</th>\n",
       "      <td>87001</td>\n",
       "      <td>5142236799</td>\n",
       "      <td>2010-11-14</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>98.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86939</th>\n",
       "      <td>87283</td>\n",
       "      <td>5142221962</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>32.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86974</th>\n",
       "      <td>87318</td>\n",
       "      <td>5142226979</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>35.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87072</th>\n",
       "      <td>87416</td>\n",
       "      <td>5142221962</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>234.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87097</th>\n",
       "      <td>87441</td>\n",
       "      <td>5142226979</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>55.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87115</th>\n",
       "      <td>87459</td>\n",
       "      <td>5142178848</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87139</th>\n",
       "      <td>87483</td>\n",
       "      <td>5142223659</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>52.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87161</th>\n",
       "      <td>87505</td>\n",
       "      <td>5142223659</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>70.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87166</th>\n",
       "      <td>87510</td>\n",
       "      <td>5142226979</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>179.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87244</th>\n",
       "      <td>87588</td>\n",
       "      <td>5142206786</td>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>327.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87294</th>\n",
       "      <td>87638</td>\n",
       "      <td>5142256802</td>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>35.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87343</th>\n",
       "      <td>87687</td>\n",
       "      <td>5142206786</td>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>108.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028360</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87478</th>\n",
       "      <td>87822</td>\n",
       "      <td>5142231744</td>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>158.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87509</th>\n",
       "      <td>87853</td>\n",
       "      <td>5142211054</td>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>97.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87688</th>\n",
       "      <td>88032</td>\n",
       "      <td>5142126504</td>\n",
       "      <td>2010-11-18</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87722</th>\n",
       "      <td>88066</td>\n",
       "      <td>5142260253</td>\n",
       "      <td>2010-11-18</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>53.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87758</th>\n",
       "      <td>88102</td>\n",
       "      <td>5142216837</td>\n",
       "      <td>2010-11-18</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>69.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023786</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87810</th>\n",
       "      <td>88154</td>\n",
       "      <td>5142264676</td>\n",
       "      <td>2010-11-18</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>182.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87922</th>\n",
       "      <td>88266</td>\n",
       "      <td>5142212179</td>\n",
       "      <td>2010-11-19</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>118.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87945</th>\n",
       "      <td>88289</td>\n",
       "      <td>5142126504</td>\n",
       "      <td>2010-11-19</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>70.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87957</th>\n",
       "      <td>88301</td>\n",
       "      <td>5142121708</td>\n",
       "      <td>2010-11-19</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>24.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88044</th>\n",
       "      <td>88388</td>\n",
       "      <td>5142237607</td>\n",
       "      <td>2010-11-19</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>81.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88194</th>\n",
       "      <td>88538</td>\n",
       "      <td>5142215286</td>\n",
       "      <td>2010-11-22</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>18.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88244</th>\n",
       "      <td>88588</td>\n",
       "      <td>5142272511</td>\n",
       "      <td>2010-11-22</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>48.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88409</th>\n",
       "      <td>88753</td>\n",
       "      <td>5142215286</td>\n",
       "      <td>2010-11-22</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88473</th>\n",
       "      <td>88817</td>\n",
       "      <td>5142283322</td>\n",
       "      <td>2010-11-23</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>15.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88541</th>\n",
       "      <td>88885</td>\n",
       "      <td>5142177486</td>\n",
       "      <td>2010-11-23</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>67.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88656</th>\n",
       "      <td>89000</td>\n",
       "      <td>5142283322</td>\n",
       "      <td>2010-11-23</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>43.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88971</th>\n",
       "      <td>89315</td>\n",
       "      <td>5142177486</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>35.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89021</th>\n",
       "      <td>89365</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>472.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89022</th>\n",
       "      <td>89366</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1397.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89023</th>\n",
       "      <td>89367</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>497.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250813</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89025</th>\n",
       "      <td>89369</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>890.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353426</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89031</th>\n",
       "      <td>89375</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1288.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631107</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89034</th>\n",
       "      <td>89378</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>3619.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.836287</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89037</th>\n",
       "      <td>89381</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1310.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974297</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89040</th>\n",
       "      <td>89384</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>204.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973087</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89048</th>\n",
       "      <td>89392</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1016.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986294</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89049</th>\n",
       "      <td>89393</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1215.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993849</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89055</th>\n",
       "      <td>89399</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1172.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996505</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89057</th>\n",
       "      <td>89401</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1496.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998018</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89060</th>\n",
       "      <td>89404</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>935.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998976</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89068</th>\n",
       "      <td>89412</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>3154.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999398</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89074</th>\n",
       "      <td>89418</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>2967.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89075</th>\n",
       "      <td>89419</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>483.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89077</th>\n",
       "      <td>89421</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>528.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89082</th>\n",
       "      <td>89426</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>196.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991423</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89083</th>\n",
       "      <td>89427</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>382.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995259</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89091</th>\n",
       "      <td>89435</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1407.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997363</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89112</th>\n",
       "      <td>89457</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>467.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89114</th>\n",
       "      <td>89459</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>2099.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999607</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89117</th>\n",
       "      <td>89462</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>413.53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89120</th>\n",
       "      <td>89465</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>354.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89121</th>\n",
       "      <td>89466</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1640.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89128</th>\n",
       "      <td>89473</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>468.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89129</th>\n",
       "      <td>89474</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>376.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89130</th>\n",
       "      <td>89475</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>8296.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89134</th>\n",
       "      <td>89479</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>298.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89174</th>\n",
       "      <td>89520</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>547.17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89183</th>\n",
       "      <td>89529</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>1694.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89186</th>\n",
       "      <td>89532</td>\n",
       "      <td>5142235211</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>194.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89233</th>\n",
       "      <td>89579</td>\n",
       "      <td>5142253597</td>\n",
       "      <td>2010-11-28</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>316.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89304</th>\n",
       "      <td>89650</td>\n",
       "      <td>5142198358</td>\n",
       "      <td>2010-11-29</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>34.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89430</th>\n",
       "      <td>89776</td>\n",
       "      <td>5142231744</td>\n",
       "      <td>2010-11-29</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>607.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031698</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89471</th>\n",
       "      <td>89817</td>\n",
       "      <td>5142220919</td>\n",
       "      <td>2010-11-30</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>140.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89564</th>\n",
       "      <td>89910</td>\n",
       "      <td>5142228903</td>\n",
       "      <td>2010-11-30</td>\n",
       "      <td>4353000719908</td>\n",
       "      <td>53.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023086</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Recnum     Cardnum        Date       Merchnum   Amount  Fraud  \\\n",
       "84104   84434  5142170410  2010-11-01  4353000719908    35.94      0   \n",
       "84124   84454  5142141358  2010-11-01  4353000719908    34.02      0   \n",
       "84194   84524  5142124208  2010-11-02  4353000719908   421.80      0   \n",
       "84283   84613  5142224426  2010-11-02  4353000719908    56.95      0   \n",
       "84341   84671  5142132687  2010-11-02  4353000719908    21.42      0   \n",
       "84363   84693  5142158538  2010-11-02  4353000719908    78.90      0   \n",
       "84396   84726  5142152982  2010-11-02  4353000719908    19.91      0   \n",
       "84416   84747  5142150217  2010-11-03  4353000719908   248.55      0   \n",
       "84783   85119  5142189945  2010-11-04  4353000719908    10.39      0   \n",
       "84802   85139  5142170410  2010-11-04  4353000719908   720.05      0   \n",
       "84806   85143  5142224426  2010-11-04  4353000719908   433.96      0   \n",
       "84873   85210  5142278177  2010-11-04  4353000719908   116.62      0   \n",
       "84985   85322  5142184598  2010-11-04  4353000719908   113.95      0   \n",
       "85318   85655  5142227402  2010-11-06  4353000719908    82.81      0   \n",
       "85350   85687  5142134357  2010-11-06  4353000719908   247.52      0   \n",
       "85382   85719  5142116345  2010-11-08  4353000719908    95.95      0   \n",
       "85446   85785  5142178899  2010-11-08  4353000719908   179.90      0   \n",
       "85515   85855  5142116345  2010-11-08  4353000719908    33.70      0   \n",
       "85739   86083  5142137416  2010-11-09  4353000719908    44.05      0   \n",
       "85757   86101  5142139483  2010-11-09  4353000719908   178.36      0   \n",
       "86044   86388  5142180432  2010-11-10  4353000719908   237.60      0   \n",
       "86063   86407  5142139483  2010-11-10  4353000719908   178.36      0   \n",
       "86142   86486  5142178848  2010-11-10  4353000719908    15.11      0   \n",
       "86459   86803  5142146217  2010-11-12  4353000719908    63.45      0   \n",
       "86564   86908  5142223659  2010-11-12  4353000719908    73.90      0   \n",
       "86641   86985  5142137416  2010-11-13  4353000719908    35.90      0   \n",
       "86657   87001  5142236799  2010-11-14  4353000719908    98.60      0   \n",
       "86939   87283  5142221962  2010-11-16  4353000719908    32.28      0   \n",
       "86974   87318  5142226979  2010-11-16  4353000719908    35.06      0   \n",
       "87072   87416  5142221962  2010-11-16  4353000719908   234.54      0   \n",
       "87097   87441  5142226979  2010-11-16  4353000719908    55.62      0   \n",
       "87115   87459  5142178848  2010-11-16  4353000719908    11.93      0   \n",
       "87139   87483  5142223659  2010-11-16  4353000719908    52.84      0   \n",
       "87161   87505  5142223659  2010-11-16  4353000719908    70.90      0   \n",
       "87166   87510  5142226979  2010-11-16  4353000719908   179.32      0   \n",
       "87244   87588  5142206786  2010-11-17  4353000719908   327.23      1   \n",
       "87294   87638  5142256802  2010-11-17  4353000719908    35.65      0   \n",
       "87343   87687  5142206786  2010-11-17  4353000719908   108.93      1   \n",
       "87478   87822  5142231744  2010-11-17  4353000719908   158.39      0   \n",
       "87509   87853  5142211054  2010-11-17  4353000719908    97.95      0   \n",
       "87688   88032  5142126504  2010-11-18  4353000719908    14.00      0   \n",
       "87722   88066  5142260253  2010-11-18  4353000719908    53.70      0   \n",
       "87758   88102  5142216837  2010-11-18  4353000719908    69.86      0   \n",
       "87810   88154  5142264676  2010-11-18  4353000719908   182.10      0   \n",
       "87922   88266  5142212179  2010-11-19  4353000719908   118.95      0   \n",
       "87945   88289  5142126504  2010-11-19  4353000719908    70.76      0   \n",
       "87957   88301  5142121708  2010-11-19  4353000719908    24.92      0   \n",
       "88044   88388  5142237607  2010-11-19  4353000719908    81.88      0   \n",
       "88194   88538  5142215286  2010-11-22  4353000719908    18.95      0   \n",
       "88244   88588  5142272511  2010-11-22  4353000719908    48.90      0   \n",
       "88409   88753  5142215286  2010-11-22  4353000719908    17.02      0   \n",
       "88473   88817  5142283322  2010-11-23  4353000719908    15.15      0   \n",
       "88541   88885  5142177486  2010-11-23  4353000719908    67.62      0   \n",
       "88656   89000  5142283322  2010-11-23  4353000719908    43.40      0   \n",
       "88971   89315  5142177486  2010-11-24  4353000719908    35.78      0   \n",
       "89021   89365  5142235211  2010-11-25  4353000719908   472.53      1   \n",
       "89022   89366  5142235211  2010-11-25  4353000719908  1397.77      1   \n",
       "89023   89367  5142235211  2010-11-25  4353000719908   497.03      1   \n",
       "89025   89369  5142235211  2010-11-25  4353000719908   890.53      1   \n",
       "89031   89375  5142235211  2010-11-25  4353000719908  1288.90      1   \n",
       "89034   89378  5142235211  2010-11-25  4353000719908  3619.88      1   \n",
       "89037   89381  5142235211  2010-11-25  4353000719908  1310.28      1   \n",
       "89040   89384  5142235211  2010-11-25  4353000719908   204.21      1   \n",
       "89048   89392  5142235211  2010-11-25  4353000719908  1016.16      1   \n",
       "89049   89393  5142235211  2010-11-25  4353000719908  1215.24      1   \n",
       "89055   89399  5142235211  2010-11-25  4353000719908  1172.09      1   \n",
       "89057   89401  5142235211  2010-11-25  4353000719908  1496.60      1   \n",
       "89060   89404  5142235211  2010-11-25  4353000719908   935.85      1   \n",
       "89068   89412  5142235211  2010-11-25  4353000719908  3154.26      1   \n",
       "89074   89418  5142235211  2010-11-25  4353000719908  2967.79      1   \n",
       "89075   89419  5142235211  2010-11-25  4353000719908   483.95      1   \n",
       "89077   89421  5142235211  2010-11-25  4353000719908   528.02      1   \n",
       "89082   89426  5142235211  2010-11-26  4353000719908   196.68      1   \n",
       "89083   89427  5142235211  2010-11-26  4353000719908   382.09      1   \n",
       "89091   89435  5142235211  2010-11-26  4353000719908  1407.17      1   \n",
       "89112   89457  5142235211  2010-11-26  4353000719908   467.46      1   \n",
       "89114   89459  5142235211  2010-11-26  4353000719908  2099.34      1   \n",
       "89117   89462  5142235211  2010-11-26  4353000719908   413.53      1   \n",
       "89120   89465  5142235211  2010-11-26  4353000719908   354.68      1   \n",
       "89121   89466  5142235211  2010-11-26  4353000719908  1640.51      1   \n",
       "89128   89473  5142235211  2010-11-26  4353000719908   468.85      1   \n",
       "89129   89474  5142235211  2010-11-26  4353000719908   376.09      1   \n",
       "89130   89475  5142235211  2010-11-26  4353000719908  8296.63      1   \n",
       "89134   89479  5142235211  2010-11-26  4353000719908   298.14      1   \n",
       "89174   89520  5142235211  2010-11-26  4353000719908   547.17      1   \n",
       "89183   89529  5142235211  2010-11-26  4353000719908  1694.85      1   \n",
       "89186   89532  5142235211  2010-11-26  4353000719908   194.30      1   \n",
       "89233   89579  5142253597  2010-11-28  4353000719908   316.99      0   \n",
       "89304   89650  5142198358  2010-11-29  4353000719908    34.55      0   \n",
       "89430   89776  5142231744  2010-11-29  4353000719908   607.00      0   \n",
       "89471   89817  5142220919  2010-11-30  4353000719908   140.87      0   \n",
       "89564   89910  5142228903  2010-11-30  4353000719908    53.94      0   \n",
       "\n",
       "           Prob  TransactionCount  \n",
       "84104  0.000718               843  \n",
       "84124  0.000812               844  \n",
       "84194  0.000516               845  \n",
       "84283  0.006660               846  \n",
       "84341  0.000824               847  \n",
       "84363  0.003790               848  \n",
       "84396  0.013578               849  \n",
       "84416  0.000534               850  \n",
       "84783  0.003779               851  \n",
       "84802  0.004221               852  \n",
       "84806  0.010299               853  \n",
       "84873  0.002505               854  \n",
       "84985  0.003166               855  \n",
       "85318  0.001425               856  \n",
       "85350  0.001757               857  \n",
       "85382  0.000561               858  \n",
       "85446  0.000300               859  \n",
       "85515  0.001343               860  \n",
       "85739  0.000730               861  \n",
       "85757  0.000983               862  \n",
       "86044  0.002184               863  \n",
       "86063  0.002222               864  \n",
       "86142  0.000812               865  \n",
       "86459  0.000743               866  \n",
       "86564  0.005481               867  \n",
       "86641  0.000843               868  \n",
       "86657  0.000295               869  \n",
       "86939  0.000877               870  \n",
       "86974  0.000314               871  \n",
       "87072  0.000968               872  \n",
       "87097  0.000567               873  \n",
       "87115  0.000337               874  \n",
       "87139  0.001032               875  \n",
       "87161  0.001671               876  \n",
       "87166  0.000683               877  \n",
       "87244  0.003451               878  \n",
       "87294  0.002931               879  \n",
       "87343  0.028360               880  \n",
       "87478  0.000995               881  \n",
       "87509  0.001253               882  \n",
       "87688  0.000955               883  \n",
       "87722  0.001112               884  \n",
       "87758  0.023786               885  \n",
       "87810  0.001386               886  \n",
       "87922  0.003031               887  \n",
       "87945  0.001718               888  \n",
       "87957  0.001921               889  \n",
       "88044  0.001669               890  \n",
       "88194  0.000498               891  \n",
       "88244  0.000585               892  \n",
       "88409  0.000589               893  \n",
       "88473  0.000455               894  \n",
       "88541  0.000448               895  \n",
       "88656  0.000251               896  \n",
       "88971  0.012136               897  \n",
       "89021  0.000545               898  \n",
       "89022  0.007608               899  \n",
       "89023  0.250813               900  \n",
       "89025  0.353426               901  \n",
       "89031  0.631107               902  \n",
       "89034  0.836287               903  \n",
       "89037  0.974297               904  \n",
       "89040  0.973087               905  \n",
       "89048  0.986294               906  \n",
       "89049  0.993849               907  \n",
       "89055  0.996505               908  \n",
       "89057  0.998018               909  \n",
       "89060  0.998976               910  \n",
       "89068  0.999398               911  \n",
       "89074  0.999756               912  \n",
       "89075  0.999894               913  \n",
       "89077  0.999917               914  \n",
       "89082  0.991423               915  \n",
       "89083  0.995259               916  \n",
       "89091  0.997363               917  \n",
       "89112  0.999502               918  \n",
       "89114  0.999607               919  \n",
       "89117  0.999868               920  \n",
       "89120  0.999905               921  \n",
       "89121  0.999927               922  \n",
       "89128  0.999949               923  \n",
       "89129  0.999958               924  \n",
       "89130  0.999965               925  \n",
       "89134  1.000000               926  \n",
       "89174  1.000000               927  \n",
       "89183  1.000000               928  \n",
       "89186  1.000000               929  \n",
       "89233  0.000005               930  \n",
       "89304  0.038337               931  \n",
       "89430  0.031698               932  \n",
       "89471  0.002858               933  \n",
       "89564  0.023086               934  "
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchviz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "merchviz2['TransactionCount'] = range(1,len(merchviz2)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Merchant 4353000719908 November Transactions')\n",
    "plt.ylabel('Fraud Score')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=45)\n",
    "plt.plot('Date','Prob',data=merchviz2)\n",
    "#plt.savefig('merch_dates.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Merchant 4353000719908 November Transactions')\n",
    "plt.ylabel('Fraud Score')\n",
    "plt.xlabel('Transaction Count')\n",
    "plt.plot('TransactionCount','Prob',data=merchviz2)\n",
    "plt.axvline(x=56,linestyle='--',color='grey')\n",
    "plt.savefig('merch_trans.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92 transactions at this merchant in the month of November\n",
    "From 11/1 to 11/24 they average 2.24 transactions a day\n",
    "17 transactions on 11/25\n",
    "15 transactions on 11/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cardnum_max_30',\n",
       " 'card_merchant_max_30',\n",
       " 'Merchnum_total_3',\n",
       " 'Cardnum_total_130',\n",
       " 'Merchnum_mean_7',\n",
       " 'card_merchant_median_1',\n",
       " 'Merchnum_mean_3',\n",
       " 'Cardnum_mean_30',\n",
       " 'card_merchant_mean_1',\n",
       " 'card_state_mean_30',\n",
       " 'card_state_median_30',\n",
       " 'card_zip_median_1',\n",
       " 'card_state_mean_14',\n",
       " 'Cardnum_max_14',\n",
       " 'card_state_max_0',\n",
       " 'Cardnum_total_30',\n",
       " 'card_zip_mean_1',\n",
       " 'card_state_median_14',\n",
       " 'card_zip_max_14',\n",
       " 'card_state_total_30']"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainpred\n",
    "# trainprob\n",
    "# testpred\n",
    "# testprob\n",
    "# ootpred\n",
    "# ootprob\n",
    "# y_train\n",
    "# y_test\n",
    "# y_oot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for final model (only based off final iteration (not average), reason why numbers are different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.DataFrame(columns = ['Pred','Prob','Y'])\n",
    "traindf['Pred'] = trainpred\n",
    "traindf['Prob'] = [i[1] for i in trainprob]\n",
    "traindf['Y'] = list(y_train)\n",
    "\n",
    "traindf = traindf.sort_values(by='Prob',ascending=False)\n",
    "\n",
    "qc = pd.qcut(range(len(traindf)), q=100, precision=1)\n",
    "# bin definition\n",
    "bins  = qc.categories\n",
    "# bin corresponding to each point in data\n",
    "codes = qc.codes\n",
    "\n",
    "traindf['Bin'] = codes\n",
    "trainresults = pd.DataFrame(columns = ['Bin','#Records', '#Goods', '#Bads','%Goods','%Bads',\n",
    "                                      'Total # Records','CumGoods','CumBads','Cum%Goods','Cum%Bads',\n",
    "                                      'FDR','FPR'])\n",
    "\n",
    "trainresults['Bin'] = list(np.unique(codes))\n",
    "\n",
    "\n",
    "\n",
    "for i in trainresults.index:\n",
    "    filt = traindf[traindf.Bin==trainresults.loc[i,'Bin']]\n",
    "    trainresults.loc[i,'#Records'] = len(filt)\n",
    "    trainresults.loc[i,'#Goods'] = len(filt[filt.Y==0])\n",
    "    trainresults.loc[i,'#Bads'] = len(filt[filt.Y==1])\n",
    "    trainresults.loc[i,'%Goods'] = 100* len(filt[filt.Y==0]) / len(filt)\n",
    "    trainresults.loc[i,'%Bads'] = 100* len(filt[filt.Y==1]) / len(filt)\n",
    "    trainresults.loc[i,'FDR'] = 100*len(filt[(filt.Pred==1)&(filt.Y==1)]) / len(traindf[traindf.Y==1])\n",
    "    trainresults.loc[i,'FPR'] = 100* len(filt[(filt.Pred==1)&(filt.Y==0)]) / (len(filt[(filt.Pred==1)&(filt.Y==0)]) + len(filt[(filt.Pred==0)&(filt.Y==0)]))\n",
    "\n",
    "trainresults.loc[0,'Total # Records'] = trainresults.loc[0,'#Records']\n",
    "trainresults.loc[0,'CumGoods'] = trainresults.loc[0,'#Goods']\n",
    "trainresults.loc[0,'CumBads'] = trainresults.loc[0,'#Bads']\n",
    "trainresults.loc[0,'Cum%Goods'] = trainresults.loc[0,'%Goods']\n",
    "trainresults.loc[0,'Cum%Bads'] = trainresults.loc[0,'%Bads']    \n",
    "\n",
    "\n",
    "for i in range(1,len(trainresults)):\n",
    "    trainresults.loc[i,'Total # Records'] = trainresults.loc[i,'#Records'] + trainresults.loc[i-1,'Total # Records']\n",
    "    trainresults.loc[i,'CumGoods'] = trainresults.loc[i,'#Goods'] + trainresults.loc[i-1,'CumGoods']\n",
    "    trainresults.loc[i,'CumBads'] = trainresults.loc[i,'#Bads'] + trainresults.loc[i-1,'CumBads']\n",
    "    trainresults.loc[i,'Cum%Goods'] = 100* trainresults.loc[i,'CumGoods'] / trainresults.loc[i,'Total # Records']\n",
    "    trainresults.loc[i,'Cum%Bads'] = 100* trainresults.loc[i,'CumBads'] / trainresults.loc[i,'Total # Records']\n",
    "    trainresults.loc[i,'FDR'] = trainresults.loc[i,'FDR'] + trainresults.loc[i-1,'FDR']\n",
    "    trainresults.loc[i,'FPR'] = trainresults.loc[i,'FPR'] + trainresults.loc[i-1,'FPR']\n",
    "    \n",
    "trainresults['Bin'] = trainresults['Bin'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Subset\n",
      "# Records:56442, #Goods:55830, #Bads:612, Fraud Rate:0.010843\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bin</th>\n",
       "      <th>#Records</th>\n",
       "      <th>#Goods</th>\n",
       "      <th>#Bads</th>\n",
       "      <th>%Goods</th>\n",
       "      <th>%Bads</th>\n",
       "      <th>Total # Records</th>\n",
       "      <th>CumGoods</th>\n",
       "      <th>CumBads</th>\n",
       "      <th>Cum%Goods</th>\n",
       "      <th>Cum%Bads</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>565</td>\n",
       "      <td>167</td>\n",
       "      <td>398</td>\n",
       "      <td>29.5575</td>\n",
       "      <td>70.4425</td>\n",
       "      <td>565</td>\n",
       "      <td>167</td>\n",
       "      <td>398</td>\n",
       "      <td>29.5575</td>\n",
       "      <td>70.4425</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>564</td>\n",
       "      <td>504</td>\n",
       "      <td>60</td>\n",
       "      <td>89.3617</td>\n",
       "      <td>10.6383</td>\n",
       "      <td>1129</td>\n",
       "      <td>671</td>\n",
       "      <td>458</td>\n",
       "      <td>59.4331</td>\n",
       "      <td>40.5669</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>565</td>\n",
       "      <td>533</td>\n",
       "      <td>32</td>\n",
       "      <td>94.3363</td>\n",
       "      <td>5.66372</td>\n",
       "      <td>1694</td>\n",
       "      <td>1204</td>\n",
       "      <td>490</td>\n",
       "      <td>71.0744</td>\n",
       "      <td>28.9256</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>564</td>\n",
       "      <td>540</td>\n",
       "      <td>24</td>\n",
       "      <td>95.7447</td>\n",
       "      <td>4.25532</td>\n",
       "      <td>2258</td>\n",
       "      <td>1744</td>\n",
       "      <td>514</td>\n",
       "      <td>77.2365</td>\n",
       "      <td>22.7635</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>565</td>\n",
       "      <td>560</td>\n",
       "      <td>5</td>\n",
       "      <td>99.115</td>\n",
       "      <td>0.884956</td>\n",
       "      <td>2823</td>\n",
       "      <td>2304</td>\n",
       "      <td>519</td>\n",
       "      <td>81.6153</td>\n",
       "      <td>18.3847</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>564</td>\n",
       "      <td>558</td>\n",
       "      <td>6</td>\n",
       "      <td>98.9362</td>\n",
       "      <td>1.06383</td>\n",
       "      <td>3387</td>\n",
       "      <td>2862</td>\n",
       "      <td>525</td>\n",
       "      <td>84.4996</td>\n",
       "      <td>15.5004</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>564</td>\n",
       "      <td>559</td>\n",
       "      <td>5</td>\n",
       "      <td>99.1135</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>3951</td>\n",
       "      <td>3421</td>\n",
       "      <td>530</td>\n",
       "      <td>86.5857</td>\n",
       "      <td>13.4143</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>565</td>\n",
       "      <td>559</td>\n",
       "      <td>6</td>\n",
       "      <td>98.9381</td>\n",
       "      <td>1.06195</td>\n",
       "      <td>4516</td>\n",
       "      <td>3980</td>\n",
       "      <td>536</td>\n",
       "      <td>88.1311</td>\n",
       "      <td>11.8689</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>564</td>\n",
       "      <td>557</td>\n",
       "      <td>7</td>\n",
       "      <td>98.7589</td>\n",
       "      <td>1.24113</td>\n",
       "      <td>5080</td>\n",
       "      <td>4537</td>\n",
       "      <td>543</td>\n",
       "      <td>89.311</td>\n",
       "      <td>10.689</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>565</td>\n",
       "      <td>562</td>\n",
       "      <td>3</td>\n",
       "      <td>99.469</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>5645</td>\n",
       "      <td>5099</td>\n",
       "      <td>546</td>\n",
       "      <td>90.3277</td>\n",
       "      <td>9.67228</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>564</td>\n",
       "      <td>559</td>\n",
       "      <td>5</td>\n",
       "      <td>99.1135</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>6209</td>\n",
       "      <td>5658</td>\n",
       "      <td>551</td>\n",
       "      <td>91.1258</td>\n",
       "      <td>8.87421</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>564</td>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>99.8227</td>\n",
       "      <td>0.177305</td>\n",
       "      <td>6773</td>\n",
       "      <td>6221</td>\n",
       "      <td>552</td>\n",
       "      <td>91.85</td>\n",
       "      <td>8.15001</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>565</td>\n",
       "      <td>558</td>\n",
       "      <td>7</td>\n",
       "      <td>98.7611</td>\n",
       "      <td>1.23894</td>\n",
       "      <td>7338</td>\n",
       "      <td>6779</td>\n",
       "      <td>559</td>\n",
       "      <td>92.3821</td>\n",
       "      <td>7.61788</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>564</td>\n",
       "      <td>560</td>\n",
       "      <td>4</td>\n",
       "      <td>99.2908</td>\n",
       "      <td>0.70922</td>\n",
       "      <td>7902</td>\n",
       "      <td>7339</td>\n",
       "      <td>563</td>\n",
       "      <td>92.8752</td>\n",
       "      <td>7.12478</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>565</td>\n",
       "      <td>561</td>\n",
       "      <td>4</td>\n",
       "      <td>99.292</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>8467</td>\n",
       "      <td>7900</td>\n",
       "      <td>567</td>\n",
       "      <td>93.3034</td>\n",
       "      <td>6.69659</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>564</td>\n",
       "      <td>561</td>\n",
       "      <td>3</td>\n",
       "      <td>99.4681</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>9031</td>\n",
       "      <td>8461</td>\n",
       "      <td>570</td>\n",
       "      <td>93.6884</td>\n",
       "      <td>6.31159</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>564</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>99.6454</td>\n",
       "      <td>0.35461</td>\n",
       "      <td>9595</td>\n",
       "      <td>9023</td>\n",
       "      <td>572</td>\n",
       "      <td>94.0386</td>\n",
       "      <td>5.96144</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>565</td>\n",
       "      <td>561</td>\n",
       "      <td>4</td>\n",
       "      <td>99.292</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>10160</td>\n",
       "      <td>9584</td>\n",
       "      <td>576</td>\n",
       "      <td>94.3307</td>\n",
       "      <td>5.66929</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>564</td>\n",
       "      <td>561</td>\n",
       "      <td>3</td>\n",
       "      <td>99.4681</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>10724</td>\n",
       "      <td>10145</td>\n",
       "      <td>579</td>\n",
       "      <td>94.6009</td>\n",
       "      <td>5.3991</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>565</td>\n",
       "      <td>563</td>\n",
       "      <td>2</td>\n",
       "      <td>99.646</td>\n",
       "      <td>0.353982</td>\n",
       "      <td>11289</td>\n",
       "      <td>10708</td>\n",
       "      <td>581</td>\n",
       "      <td>94.8534</td>\n",
       "      <td>5.1466</td>\n",
       "      <td>54.2484</td>\n",
       "      <td>8.38323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bin #Records #Goods #Bads   %Goods     %Bads Total # Records CumGoods  \\\n",
       "0     1      565    167   398  29.5575   70.4425             565      167   \n",
       "1     2      564    504    60  89.3617   10.6383            1129      671   \n",
       "2     3      565    533    32  94.3363   5.66372            1694     1204   \n",
       "3     4      564    540    24  95.7447   4.25532            2258     1744   \n",
       "4     5      565    560     5   99.115  0.884956            2823     2304   \n",
       "5     6      564    558     6  98.9362   1.06383            3387     2862   \n",
       "6     7      564    559     5  99.1135  0.886525            3951     3421   \n",
       "7     8      565    559     6  98.9381   1.06195            4516     3980   \n",
       "8     9      564    557     7  98.7589   1.24113            5080     4537   \n",
       "9    10      565    562     3   99.469  0.530973            5645     5099   \n",
       "10   11      564    559     5  99.1135  0.886525            6209     5658   \n",
       "11   12      564    563     1  99.8227  0.177305            6773     6221   \n",
       "12   13      565    558     7  98.7611   1.23894            7338     6779   \n",
       "13   14      564    560     4  99.2908   0.70922            7902     7339   \n",
       "14   15      565    561     4   99.292  0.707965            8467     7900   \n",
       "15   16      564    561     3  99.4681  0.531915            9031     8461   \n",
       "16   17      564    562     2  99.6454   0.35461            9595     9023   \n",
       "17   18      565    561     4   99.292  0.707965           10160     9584   \n",
       "18   19      564    561     3  99.4681  0.531915           10724    10145   \n",
       "19   20      565    563     2   99.646  0.353982           11289    10708   \n",
       "\n",
       "   CumBads Cum%Goods Cum%Bads      FDR      FPR  \n",
       "0      398   29.5575  70.4425  54.2484  8.38323  \n",
       "1      458   59.4331  40.5669  54.2484  8.38323  \n",
       "2      490   71.0744  28.9256  54.2484  8.38323  \n",
       "3      514   77.2365  22.7635  54.2484  8.38323  \n",
       "4      519   81.6153  18.3847  54.2484  8.38323  \n",
       "5      525   84.4996  15.5004  54.2484  8.38323  \n",
       "6      530   86.5857  13.4143  54.2484  8.38323  \n",
       "7      536   88.1311  11.8689  54.2484  8.38323  \n",
       "8      543    89.311   10.689  54.2484  8.38323  \n",
       "9      546   90.3277  9.67228  54.2484  8.38323  \n",
       "10     551   91.1258  8.87421  54.2484  8.38323  \n",
       "11     552     91.85  8.15001  54.2484  8.38323  \n",
       "12     559   92.3821  7.61788  54.2484  8.38323  \n",
       "13     563   92.8752  7.12478  54.2484  8.38323  \n",
       "14     567   93.3034  6.69659  54.2484  8.38323  \n",
       "15     570   93.6884  6.31159  54.2484  8.38323  \n",
       "16     572   94.0386  5.96144  54.2484  8.38323  \n",
       "17     576   94.3307  5.66929  54.2484  8.38323  \n",
       "18     579   94.6009   5.3991  54.2484  8.38323  \n",
       "19     581   94.8534   5.1466  54.2484  8.38323  "
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training Subset')\n",
    "print(f'# Records:{len(traindf)}, #Goods:{len(traindf[traindf.Y==0])}, #Bads:{len(traindf[traindf.Y==1])}, Fraud Rate:{round(len(traindf[traindf.Y==1])/len(traindf),6)}')\n",
    "trainresults.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.DataFrame(columns = ['Pred','Prob','Y'])\n",
    "testdf['Pred'] = testpred\n",
    "testdf['Prob'] = [i[1] for i in testprob]\n",
    "testdf['Y'] = list(y_test)\n",
    "\n",
    "testdf = testdf.sort_values(by='Prob',ascending=False)\n",
    "\n",
    "qc = pd.qcut(range(len(testdf)), q=100, precision=1)\n",
    "# bin definition\n",
    "bins  = qc.categories\n",
    "# bin corresponding to each point in data\n",
    "codes = qc.codes\n",
    "\n",
    "testdf['Bin'] = codes\n",
    "testresults = pd.DataFrame(columns = ['Bin','#Records', '#Goods', '#Bads','%Goods','%Bads',\n",
    "                                      'Total # Records','CumGoods','CumBads','Cum%Goods','Cum%Bads',\n",
    "                                      'FDR','FPR'])\n",
    "\n",
    "testresults['Bin'] = list(np.unique(codes))\n",
    "\n",
    "\n",
    "\n",
    "for i in testresults.index:\n",
    "    filt = testdf[testdf.Bin==testresults.loc[i,'Bin']]\n",
    "    testresults.loc[i,'#Records'] = len(filt)\n",
    "    testresults.loc[i,'#Goods'] = len(filt[filt.Y==0])\n",
    "    testresults.loc[i,'#Bads'] = len(filt[filt.Y==1])\n",
    "    testresults.loc[i,'%Goods'] = 100* len(filt[filt.Y==0]) / len(filt)\n",
    "    testresults.loc[i,'%Bads'] = 100* len(filt[filt.Y==1]) / len(filt)\n",
    "    testresults.loc[i,'FDR'] = 100*len(filt[(filt.Pred==1)&(filt.Y==1)]) / len(testdf[testdf.Y==1])\n",
    "    testresults.loc[i,'FPR'] = 100* len(filt[(filt.Pred==1)&(filt.Y==0)]) / (len(filt[(filt.Pred==1)&(filt.Y==0)]) + len(filt[(filt.Pred==0)&(filt.Y==0)]))\n",
    "\n",
    "testresults.loc[0,'Total # Records'] = testresults.loc[0,'#Records']\n",
    "testresults.loc[0,'CumGoods'] = testresults.loc[0,'#Goods']\n",
    "testresults.loc[0,'CumBads'] = testresults.loc[0,'#Bads']\n",
    "testresults.loc[0,'Cum%Goods'] = testresults.loc[0,'%Goods']\n",
    "testresults.loc[0,'Cum%Bads'] = testresults.loc[0,'%Bads']    \n",
    "\n",
    "\n",
    "for i in range(1,len(testresults)):\n",
    "    testresults.loc[i,'Total # Records'] = testresults.loc[i,'#Records'] + testresults.loc[i-1,'Total # Records']\n",
    "    testresults.loc[i,'CumGoods'] = testresults.loc[i,'#Goods'] + testresults.loc[i-1,'CumGoods']\n",
    "    testresults.loc[i,'CumBads'] = testresults.loc[i,'#Bads'] + testresults.loc[i-1,'CumBads']\n",
    "    testresults.loc[i,'Cum%Goods'] = 100* testresults.loc[i,'CumGoods'] / testresults.loc[i,'Total # Records']\n",
    "    testresults.loc[i,'Cum%Bads'] = 100* testresults.loc[i,'CumBads'] / testresults.loc[i,'Total # Records']\n",
    "    testresults.loc[i,'FDR'] = testresults.loc[i,'FDR'] + testresults.loc[i-1,'FDR']\n",
    "    testresults.loc[i,'FPR'] = testresults.loc[i,'FPR'] + testresults.loc[i-1,'FPR']\n",
    "    \n",
    "testresults['Bin'] = testresults['Bin'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Subset\n",
      "# Records:24190, #Goods:23934, #Bads:256, Fraud Rate:0.010583\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bin</th>\n",
       "      <th>#Records</th>\n",
       "      <th>#Goods</th>\n",
       "      <th>#Bads</th>\n",
       "      <th>%Goods</th>\n",
       "      <th>%Bads</th>\n",
       "      <th>Total # Records</th>\n",
       "      <th>CumGoods</th>\n",
       "      <th>CumBads</th>\n",
       "      <th>Cum%Goods</th>\n",
       "      <th>Cum%Bads</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>103</td>\n",
       "      <td>139</td>\n",
       "      <td>42.562</td>\n",
       "      <td>57.438</td>\n",
       "      <td>242</td>\n",
       "      <td>103</td>\n",
       "      <td>139</td>\n",
       "      <td>42.562</td>\n",
       "      <td>57.438</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>221</td>\n",
       "      <td>21</td>\n",
       "      <td>91.3223</td>\n",
       "      <td>8.67769</td>\n",
       "      <td>484</td>\n",
       "      <td>324</td>\n",
       "      <td>160</td>\n",
       "      <td>66.9421</td>\n",
       "      <td>33.0579</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>242</td>\n",
       "      <td>225</td>\n",
       "      <td>17</td>\n",
       "      <td>92.9752</td>\n",
       "      <td>7.02479</td>\n",
       "      <td>726</td>\n",
       "      <td>549</td>\n",
       "      <td>177</td>\n",
       "      <td>75.6198</td>\n",
       "      <td>24.3802</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>242</td>\n",
       "      <td>236</td>\n",
       "      <td>6</td>\n",
       "      <td>97.5207</td>\n",
       "      <td>2.47934</td>\n",
       "      <td>968</td>\n",
       "      <td>785</td>\n",
       "      <td>183</td>\n",
       "      <td>81.095</td>\n",
       "      <td>18.905</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>242</td>\n",
       "      <td>236</td>\n",
       "      <td>6</td>\n",
       "      <td>97.5207</td>\n",
       "      <td>2.47934</td>\n",
       "      <td>1210</td>\n",
       "      <td>1021</td>\n",
       "      <td>189</td>\n",
       "      <td>84.3802</td>\n",
       "      <td>15.6198</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>242</td>\n",
       "      <td>236</td>\n",
       "      <td>6</td>\n",
       "      <td>97.5207</td>\n",
       "      <td>2.47934</td>\n",
       "      <td>1452</td>\n",
       "      <td>1257</td>\n",
       "      <td>195</td>\n",
       "      <td>86.5702</td>\n",
       "      <td>13.4298</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>242</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>99.5868</td>\n",
       "      <td>0.413223</td>\n",
       "      <td>1694</td>\n",
       "      <td>1498</td>\n",
       "      <td>196</td>\n",
       "      <td>88.4298</td>\n",
       "      <td>11.5702</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>242</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>99.1736</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>1936</td>\n",
       "      <td>1738</td>\n",
       "      <td>198</td>\n",
       "      <td>89.7727</td>\n",
       "      <td>10.2273</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>242</td>\n",
       "      <td>237</td>\n",
       "      <td>5</td>\n",
       "      <td>97.9339</td>\n",
       "      <td>2.06612</td>\n",
       "      <td>2178</td>\n",
       "      <td>1975</td>\n",
       "      <td>203</td>\n",
       "      <td>90.6795</td>\n",
       "      <td>9.32048</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>241</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>99.1701</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>2419</td>\n",
       "      <td>2214</td>\n",
       "      <td>205</td>\n",
       "      <td>91.5254</td>\n",
       "      <td>8.47458</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>242</td>\n",
       "      <td>237</td>\n",
       "      <td>5</td>\n",
       "      <td>97.9339</td>\n",
       "      <td>2.06612</td>\n",
       "      <td>2661</td>\n",
       "      <td>2451</td>\n",
       "      <td>210</td>\n",
       "      <td>92.1082</td>\n",
       "      <td>7.89177</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>242</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>99.1736</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>2903</td>\n",
       "      <td>2691</td>\n",
       "      <td>212</td>\n",
       "      <td>92.6972</td>\n",
       "      <td>7.30279</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>242</td>\n",
       "      <td>237</td>\n",
       "      <td>5</td>\n",
       "      <td>97.9339</td>\n",
       "      <td>2.06612</td>\n",
       "      <td>3145</td>\n",
       "      <td>2928</td>\n",
       "      <td>217</td>\n",
       "      <td>93.1002</td>\n",
       "      <td>6.89984</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>242</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>99.5868</td>\n",
       "      <td>0.413223</td>\n",
       "      <td>3387</td>\n",
       "      <td>3169</td>\n",
       "      <td>218</td>\n",
       "      <td>93.5636</td>\n",
       "      <td>6.43637</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>242</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>99.1736</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>3629</td>\n",
       "      <td>3409</td>\n",
       "      <td>220</td>\n",
       "      <td>93.9377</td>\n",
       "      <td>6.06228</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>242</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>99.1736</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>3871</td>\n",
       "      <td>3649</td>\n",
       "      <td>222</td>\n",
       "      <td>94.265</td>\n",
       "      <td>5.73495</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>242</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>99.1736</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>4113</td>\n",
       "      <td>3889</td>\n",
       "      <td>224</td>\n",
       "      <td>94.5539</td>\n",
       "      <td>5.44615</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>99.1736</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>4355</td>\n",
       "      <td>4129</td>\n",
       "      <td>226</td>\n",
       "      <td>94.8106</td>\n",
       "      <td>5.18944</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>241</td>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>99.1701</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>4596</td>\n",
       "      <td>4368</td>\n",
       "      <td>228</td>\n",
       "      <td>95.0392</td>\n",
       "      <td>4.96084</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>4838</td>\n",
       "      <td>4610</td>\n",
       "      <td>228</td>\n",
       "      <td>95.2873</td>\n",
       "      <td>4.71269</td>\n",
       "      <td>41.4062</td>\n",
       "      <td>11.6505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bin #Records #Goods #Bads   %Goods     %Bads Total # Records CumGoods  \\\n",
       "0     1      242    103   139   42.562    57.438             242      103   \n",
       "1     2      242    221    21  91.3223   8.67769             484      324   \n",
       "2     3      242    225    17  92.9752   7.02479             726      549   \n",
       "3     4      242    236     6  97.5207   2.47934             968      785   \n",
       "4     5      242    236     6  97.5207   2.47934            1210     1021   \n",
       "5     6      242    236     6  97.5207   2.47934            1452     1257   \n",
       "6     7      242    241     1  99.5868  0.413223            1694     1498   \n",
       "7     8      242    240     2  99.1736  0.826446            1936     1738   \n",
       "8     9      242    237     5  97.9339   2.06612            2178     1975   \n",
       "9    10      241    239     2  99.1701  0.829876            2419     2214   \n",
       "10   11      242    237     5  97.9339   2.06612            2661     2451   \n",
       "11   12      242    240     2  99.1736  0.826446            2903     2691   \n",
       "12   13      242    237     5  97.9339   2.06612            3145     2928   \n",
       "13   14      242    241     1  99.5868  0.413223            3387     3169   \n",
       "14   15      242    240     2  99.1736  0.826446            3629     3409   \n",
       "15   16      242    240     2  99.1736  0.826446            3871     3649   \n",
       "16   17      242    240     2  99.1736  0.826446            4113     3889   \n",
       "17   18      242    240     2  99.1736  0.826446            4355     4129   \n",
       "18   19      241    239     2  99.1701  0.829876            4596     4368   \n",
       "19   20      242    242     0      100         0            4838     4610   \n",
       "\n",
       "   CumBads Cum%Goods Cum%Bads      FDR      FPR  \n",
       "0      139    42.562   57.438  41.4062  11.6505  \n",
       "1      160   66.9421  33.0579  41.4062  11.6505  \n",
       "2      177   75.6198  24.3802  41.4062  11.6505  \n",
       "3      183    81.095   18.905  41.4062  11.6505  \n",
       "4      189   84.3802  15.6198  41.4062  11.6505  \n",
       "5      195   86.5702  13.4298  41.4062  11.6505  \n",
       "6      196   88.4298  11.5702  41.4062  11.6505  \n",
       "7      198   89.7727  10.2273  41.4062  11.6505  \n",
       "8      203   90.6795  9.32048  41.4062  11.6505  \n",
       "9      205   91.5254  8.47458  41.4062  11.6505  \n",
       "10     210   92.1082  7.89177  41.4062  11.6505  \n",
       "11     212   92.6972  7.30279  41.4062  11.6505  \n",
       "12     217   93.1002  6.89984  41.4062  11.6505  \n",
       "13     218   93.5636  6.43637  41.4062  11.6505  \n",
       "14     220   93.9377  6.06228  41.4062  11.6505  \n",
       "15     222    94.265  5.73495  41.4062  11.6505  \n",
       "16     224   94.5539  5.44615  41.4062  11.6505  \n",
       "17     226   94.8106  5.18944  41.4062  11.6505  \n",
       "18     228   95.0392  4.96084  41.4062  11.6505  \n",
       "19     228   95.2873  4.71269  41.4062  11.6505  "
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Testing Subset')\n",
    "print(f'# Records:{len(testdf)}, #Goods:{len(testdf[testdf.Y==0])}, #Bads:{len(testdf[testdf.Y==1])}, Fraud Rate:{round(len(testdf[testdf.Y==1])/len(testdf),6)}')\n",
    "testresults.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "ootdf = pd.DataFrame(columns = ['Pred','Prob','Y'])\n",
    "ootdf['Pred'] = ootpred\n",
    "ootdf['Prob'] = [i[1] for i in ootprob]\n",
    "ootdf['Y'] = list(y_oot)\n",
    "\n",
    "ootdf = ootdf.sort_values(by='Prob',ascending=False)\n",
    "\n",
    "qc = pd.qcut(range(len(ootdf)), q=100, precision=1)\n",
    "# bin definition\n",
    "bins  = qc.categories\n",
    "# bin corresponding to each point in data\n",
    "codes = qc.codes\n",
    "\n",
    "ootdf['Bin'] = codes\n",
    "ootresults = pd.DataFrame(columns = ['Bin','#Records', '#Goods', '#Bads','%Goods','%Bads',\n",
    "                                      'Total # Records','CumGoods','CumBads','Cum%Goods','Cum%Bads',\n",
    "                                      'FDR','FPR'])\n",
    "\n",
    "ootresults['Bin'] = list(np.unique(codes))\n",
    "\n",
    "\n",
    "\n",
    "for i in ootresults.index:\n",
    "    filt = ootdf[ootdf.Bin==ootresults.loc[i,'Bin']]\n",
    "    ootresults.loc[i,'#Records'] = len(filt)\n",
    "    ootresults.loc[i,'#Goods'] = len(filt[filt.Y==0])\n",
    "    ootresults.loc[i,'#Bads'] = len(filt[filt.Y==1])\n",
    "    ootresults.loc[i,'%Goods'] = 100* len(filt[filt.Y==0]) / len(filt)\n",
    "    ootresults.loc[i,'%Bads'] = 100* len(filt[filt.Y==1]) / len(filt)\n",
    "    ootresults.loc[i,'FDR'] = 100*len(filt[(filt.Pred==1)&(filt.Y==1)]) / len(ootdf[ootdf.Y==1])\n",
    "    ootresults.loc[i,'FPR'] = 100* len(filt[(filt.Pred==1)&(filt.Y==0)]) / (len(filt[(filt.Pred==1)&(filt.Y==0)]) + len(filt[(filt.Pred==0)&(filt.Y==0)]))\n",
    "\n",
    "ootresults.loc[0,'Total # Records'] = ootresults.loc[0,'#Records']\n",
    "ootresults.loc[0,'CumGoods'] = ootresults.loc[0,'#Goods']\n",
    "ootresults.loc[0,'CumBads'] = ootresults.loc[0,'#Bads']\n",
    "ootresults.loc[0,'Cum%Goods'] = ootresults.loc[0,'%Goods']\n",
    "ootresults.loc[0,'Cum%Bads'] = ootresults.loc[0,'%Bads']    \n",
    "\n",
    "\n",
    "for i in range(1,len(ootresults)):\n",
    "    ootresults.loc[i,'Total # Records'] = ootresults.loc[i,'#Records'] + ootresults.loc[i-1,'Total # Records']\n",
    "    ootresults.loc[i,'CumGoods'] = ootresults.loc[i,'#Goods'] + ootresults.loc[i-1,'CumGoods']\n",
    "    ootresults.loc[i,'CumBads'] = ootresults.loc[i,'#Bads'] + ootresults.loc[i-1,'CumBads']\n",
    "    ootresults.loc[i,'Cum%Goods'] = 100* ootresults.loc[i,'CumGoods'] / ootresults.loc[i,'Total # Records']\n",
    "    ootresults.loc[i,'Cum%Bads'] = 100* ootresults.loc[i,'CumBads'] / ootresults.loc[i,'Total # Records']\n",
    "    ootresults.loc[i,'FDR'] = ootresults.loc[i,'FDR'] + ootresults.loc[i-1,'FDR']\n",
    "    ootresults.loc[i,'FPR'] = ootresults.loc[i,'FPR'] + ootresults.loc[i-1,'FPR']\n",
    "    \n",
    "ootresults['Bin'] = ootresults['Bin'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOT Subset\n",
      "# Records:12427, #Goods:12248, #Bads:179, Fraud Rate:0.014404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bin</th>\n",
       "      <th>#Records</th>\n",
       "      <th>#Goods</th>\n",
       "      <th>#Bads</th>\n",
       "      <th>%Goods</th>\n",
       "      <th>%Bads</th>\n",
       "      <th>Total # Records</th>\n",
       "      <th>CumGoods</th>\n",
       "      <th>CumBads</th>\n",
       "      <th>Cum%Goods</th>\n",
       "      <th>Cum%Bads</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>87</td>\n",
       "      <td>38</td>\n",
       "      <td>69.6</td>\n",
       "      <td>30.4</td>\n",
       "      <td>125</td>\n",
       "      <td>87</td>\n",
       "      <td>38</td>\n",
       "      <td>69.6</td>\n",
       "      <td>30.4</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>91</td>\n",
       "      <td>33</td>\n",
       "      <td>73.3871</td>\n",
       "      <td>26.6129</td>\n",
       "      <td>249</td>\n",
       "      <td>178</td>\n",
       "      <td>71</td>\n",
       "      <td>71.4859</td>\n",
       "      <td>28.5141</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "      <td>101</td>\n",
       "      <td>23</td>\n",
       "      <td>81.4516</td>\n",
       "      <td>18.5484</td>\n",
       "      <td>373</td>\n",
       "      <td>279</td>\n",
       "      <td>94</td>\n",
       "      <td>74.7989</td>\n",
       "      <td>25.2011</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>95.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>498</td>\n",
       "      <td>398</td>\n",
       "      <td>100</td>\n",
       "      <td>79.9197</td>\n",
       "      <td>20.0803</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>95.9677</td>\n",
       "      <td>4.03226</td>\n",
       "      <td>622</td>\n",
       "      <td>517</td>\n",
       "      <td>105</td>\n",
       "      <td>83.119</td>\n",
       "      <td>16.881</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>6</td>\n",
       "      <td>95.1613</td>\n",
       "      <td>4.83871</td>\n",
       "      <td>746</td>\n",
       "      <td>635</td>\n",
       "      <td>111</td>\n",
       "      <td>85.1206</td>\n",
       "      <td>14.8794</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>1.6129</td>\n",
       "      <td>870</td>\n",
       "      <td>757</td>\n",
       "      <td>113</td>\n",
       "      <td>87.0115</td>\n",
       "      <td>12.9885</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>95.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>995</td>\n",
       "      <td>876</td>\n",
       "      <td>119</td>\n",
       "      <td>88.0402</td>\n",
       "      <td>11.9598</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>99.1935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1119</td>\n",
       "      <td>999</td>\n",
       "      <td>120</td>\n",
       "      <td>89.2761</td>\n",
       "      <td>10.7239</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>1.6129</td>\n",
       "      <td>1243</td>\n",
       "      <td>1121</td>\n",
       "      <td>122</td>\n",
       "      <td>90.185</td>\n",
       "      <td>9.81496</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>1.6129</td>\n",
       "      <td>1367</td>\n",
       "      <td>1243</td>\n",
       "      <td>124</td>\n",
       "      <td>90.929</td>\n",
       "      <td>9.07096</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>98.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1492</td>\n",
       "      <td>1366</td>\n",
       "      <td>126</td>\n",
       "      <td>91.555</td>\n",
       "      <td>8.44504</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>97.5806</td>\n",
       "      <td>2.41935</td>\n",
       "      <td>1616</td>\n",
       "      <td>1487</td>\n",
       "      <td>129</td>\n",
       "      <td>92.0173</td>\n",
       "      <td>7.98267</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>1.6129</td>\n",
       "      <td>1740</td>\n",
       "      <td>1609</td>\n",
       "      <td>131</td>\n",
       "      <td>92.4713</td>\n",
       "      <td>7.52874</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>97.5806</td>\n",
       "      <td>2.41935</td>\n",
       "      <td>1864</td>\n",
       "      <td>1730</td>\n",
       "      <td>134</td>\n",
       "      <td>92.8112</td>\n",
       "      <td>7.18884</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1989</td>\n",
       "      <td>1854</td>\n",
       "      <td>135</td>\n",
       "      <td>93.2127</td>\n",
       "      <td>6.78733</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>99.1935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>2113</td>\n",
       "      <td>1977</td>\n",
       "      <td>136</td>\n",
       "      <td>93.5637</td>\n",
       "      <td>6.43635</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>99.1935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>2237</td>\n",
       "      <td>2100</td>\n",
       "      <td>137</td>\n",
       "      <td>93.8757</td>\n",
       "      <td>6.12427</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2361</td>\n",
       "      <td>2224</td>\n",
       "      <td>137</td>\n",
       "      <td>94.1974</td>\n",
       "      <td>5.80263</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>98.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2486</td>\n",
       "      <td>2347</td>\n",
       "      <td>139</td>\n",
       "      <td>94.4087</td>\n",
       "      <td>5.59131</td>\n",
       "      <td>20.1117</td>\n",
       "      <td>71.2644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bin #Records #Goods #Bads   %Goods     %Bads Total # Records CumGoods  \\\n",
       "0     1      125     87    38     69.6      30.4             125       87   \n",
       "1     2      124     91    33  73.3871   26.6129             249      178   \n",
       "2     3      124    101    23  81.4516   18.5484             373      279   \n",
       "3     4      125    119     6     95.2       4.8             498      398   \n",
       "4     5      124    119     5  95.9677   4.03226             622      517   \n",
       "5     6      124    118     6  95.1613   4.83871             746      635   \n",
       "6     7      124    122     2  98.3871    1.6129             870      757   \n",
       "7     8      125    119     6     95.2       4.8             995      876   \n",
       "8     9      124    123     1  99.1935  0.806452            1119      999   \n",
       "9    10      124    122     2  98.3871    1.6129            1243     1121   \n",
       "10   11      124    122     2  98.3871    1.6129            1367     1243   \n",
       "11   12      125    123     2     98.4       1.6            1492     1366   \n",
       "12   13      124    121     3  97.5806   2.41935            1616     1487   \n",
       "13   14      124    122     2  98.3871    1.6129            1740     1609   \n",
       "14   15      124    121     3  97.5806   2.41935            1864     1730   \n",
       "15   16      125    124     1     99.2       0.8            1989     1854   \n",
       "16   17      124    123     1  99.1935  0.806452            2113     1977   \n",
       "17   18      124    123     1  99.1935  0.806452            2237     2100   \n",
       "18   19      124    124     0      100         0            2361     2224   \n",
       "19   20      125    123     2     98.4       1.6            2486     2347   \n",
       "\n",
       "   CumBads Cum%Goods Cum%Bads      FDR      FPR  \n",
       "0       38      69.6     30.4  20.1117  71.2644  \n",
       "1       71   71.4859  28.5141  20.1117  71.2644  \n",
       "2       94   74.7989  25.2011  20.1117  71.2644  \n",
       "3      100   79.9197  20.0803  20.1117  71.2644  \n",
       "4      105    83.119   16.881  20.1117  71.2644  \n",
       "5      111   85.1206  14.8794  20.1117  71.2644  \n",
       "6      113   87.0115  12.9885  20.1117  71.2644  \n",
       "7      119   88.0402  11.9598  20.1117  71.2644  \n",
       "8      120   89.2761  10.7239  20.1117  71.2644  \n",
       "9      122    90.185  9.81496  20.1117  71.2644  \n",
       "10     124    90.929  9.07096  20.1117  71.2644  \n",
       "11     126    91.555  8.44504  20.1117  71.2644  \n",
       "12     129   92.0173  7.98267  20.1117  71.2644  \n",
       "13     131   92.4713  7.52874  20.1117  71.2644  \n",
       "14     134   92.8112  7.18884  20.1117  71.2644  \n",
       "15     135   93.2127  6.78733  20.1117  71.2644  \n",
       "16     136   93.5637  6.43635  20.1117  71.2644  \n",
       "17     137   93.8757  6.12427  20.1117  71.2644  \n",
       "18     137   94.1974  5.80263  20.1117  71.2644  \n",
       "19     139   94.4087  5.59131  20.1117  71.2644  "
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('OOT Subset')\n",
    "print(f'# Records:{len(ootdf)}, #Goods:{len(ootdf[ootdf.Y==0])}, #Bads:{len(ootdf[ootdf.Y==1])}, Fraud Rate:{round(len(ootdf[ootdf.Y==1])/len(ootdf),6)}')\n",
    "ootresults.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for final model (retrained on all modeling data, tested on oot data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekcarlson/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# trainpred\n",
    "# trainprob\n",
    "# testpred\n",
    "# testprob\n",
    "# y\n",
    "# y_oot\n",
    "\n",
    "final_model2 = MLPClassifier(hidden_layer_sizes = (40,), max_iter = 50)\n",
    "final_model2.fit(X3, y)\n",
    "train2pred = final_model2.predict(X3)\n",
    "train2prob = final_model2.predict_proba(X3)\n",
    "test2pred = final_model2.predict(X_oot3)\n",
    "test2prob = final_model2.predict_proba(X_oot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2df = pd.DataFrame(columns = ['Pred','Prob','Y'])\n",
    "train2df['Pred'] = train2pred\n",
    "train2df['Prob'] = [i[1] for i in train2prob]\n",
    "train2df['Y'] = list(y)\n",
    "\n",
    "train2df = train2df.sort_values(by='Prob',ascending=False)\n",
    "\n",
    "qc = pd.qcut(range(len(train2df)), q=100, precision=1)\n",
    "# bin definition\n",
    "bins  = qc.categories\n",
    "# bin corresponding to each point in data\n",
    "codes = qc.codes\n",
    "\n",
    "train2df['Bin'] = codes\n",
    "train2results = pd.DataFrame(columns = ['Bin','#Records', '#Goods', '#Bads','%Goods','%Bads',\n",
    "                                      'Total # Records','CumGoods','CumBads','Cum%Goods','Cum%Bads',\n",
    "                                      'FDR','FPR'])\n",
    "\n",
    "train2results['Bin'] = list(np.unique(codes))\n",
    "\n",
    "\n",
    "\n",
    "for i in train2results.index:\n",
    "    filt = train2df[train2df.Bin==train2results.loc[i,'Bin']]\n",
    "    train2results.loc[i,'#Records'] = len(filt)\n",
    "    train2results.loc[i,'#Goods'] = len(filt[filt.Y==0])\n",
    "    train2results.loc[i,'#Bads'] = len(filt[filt.Y==1])\n",
    "    train2results.loc[i,'%Goods'] = 100* len(filt[filt.Y==0]) / len(filt)\n",
    "    train2results.loc[i,'%Bads'] = 100* len(filt[filt.Y==1]) / len(filt)\n",
    "    #train2results.loc[i,'FDR'] = 100*len(filt[(filt.Pred==1)&(filt.Y==1)]) / len(train2df[train2df.Y==1])\n",
    "    #train2results.loc[i,'FPR'] = 100* len(filt[(filt.Pred==1)&(filt.Y==0)]) / (len(filt[(filt.Pred==1)&(filt.Y==0)]) + len(filt[(filt.Pred==0)&(filt.Y==0)]))\n",
    "\n",
    "train2results.loc[0,'Total # Records'] = train2results.loc[0,'#Records']\n",
    "train2results.loc[0,'CumGoods'] = train2results.loc[0,'#Goods']\n",
    "train2results.loc[0,'CumBads'] = train2results.loc[0,'#Bads']\n",
    "train2results.loc[0,'Cum%Goods'] = train2results.loc[0,'%Goods']\n",
    "train2results.loc[0,'Cum%Bads'] = train2results.loc[0,'%Bads']    \n",
    "\n",
    "\n",
    "for i in range(1,len(train2results)):\n",
    "    train2results.loc[i,'Total # Records'] = train2results.loc[i,'#Records'] + train2results.loc[i-1,'Total # Records']\n",
    "    train2results.loc[i,'CumGoods'] = train2results.loc[i,'#Goods'] + train2results.loc[i-1,'CumGoods']\n",
    "    train2results.loc[i,'CumBads'] = train2results.loc[i,'#Bads'] + train2results.loc[i-1,'CumBads']\n",
    "    train2results.loc[i,'Cum%Goods'] = 100* train2results.loc[i,'CumGoods'] / train2results.loc[i,'Total # Records']\n",
    "    train2results.loc[i,'Cum%Bads'] = 100* train2results.loc[i,'CumBads'] / train2results.loc[i,'Total # Records']\n",
    "    #train2results.loc[i,'FDR'] = 100*len(filt[(filt.Pred==1)&(filt.Y==1)]) / len(train2df[train2df.Y==1]) + train2results.loc[i-1,'FDR']\n",
    "    #train2results.loc[i,'FPR'] = 100* len(filt[(filt.Pred==1)&(filt.Y==0)]) / (len(filt[(filt.Pred==1)&(filt.Y==0)]) + len(filt[(filt.Pred==0)&(filt.Y==0)])) + train2results.loc[i-1,'FPR']\n",
    "    \n",
    "train2results['Bin'] = train2results['Bin'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Subset\n",
      "# Records:80632, #Goods:79764, #Bads:868, Fraud Rate:0.010765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bin</th>\n",
       "      <th>#Records</th>\n",
       "      <th>#Goods</th>\n",
       "      <th>#Bads</th>\n",
       "      <th>%Goods</th>\n",
       "      <th>%Bads</th>\n",
       "      <th>Total # Records</th>\n",
       "      <th>CumGoods</th>\n",
       "      <th>CumBads</th>\n",
       "      <th>Cum%Goods</th>\n",
       "      <th>Cum%Bads</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>807</td>\n",
       "      <td>261</td>\n",
       "      <td>546</td>\n",
       "      <td>32.342</td>\n",
       "      <td>67.658</td>\n",
       "      <td>807</td>\n",
       "      <td>261</td>\n",
       "      <td>546</td>\n",
       "      <td>32.342</td>\n",
       "      <td>67.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>806</td>\n",
       "      <td>721</td>\n",
       "      <td>85</td>\n",
       "      <td>89.4541</td>\n",
       "      <td>10.5459</td>\n",
       "      <td>1613</td>\n",
       "      <td>982</td>\n",
       "      <td>631</td>\n",
       "      <td>60.8803</td>\n",
       "      <td>39.1197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>806</td>\n",
       "      <td>759</td>\n",
       "      <td>47</td>\n",
       "      <td>94.1687</td>\n",
       "      <td>5.83127</td>\n",
       "      <td>2419</td>\n",
       "      <td>1741</td>\n",
       "      <td>678</td>\n",
       "      <td>71.9719</td>\n",
       "      <td>28.0281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>807</td>\n",
       "      <td>786</td>\n",
       "      <td>21</td>\n",
       "      <td>97.3978</td>\n",
       "      <td>2.60223</td>\n",
       "      <td>3226</td>\n",
       "      <td>2527</td>\n",
       "      <td>699</td>\n",
       "      <td>78.3323</td>\n",
       "      <td>21.6677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>806</td>\n",
       "      <td>789</td>\n",
       "      <td>17</td>\n",
       "      <td>97.8908</td>\n",
       "      <td>2.10918</td>\n",
       "      <td>4032</td>\n",
       "      <td>3316</td>\n",
       "      <td>716</td>\n",
       "      <td>82.2421</td>\n",
       "      <td>17.7579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>806</td>\n",
       "      <td>788</td>\n",
       "      <td>18</td>\n",
       "      <td>97.7667</td>\n",
       "      <td>2.23325</td>\n",
       "      <td>4838</td>\n",
       "      <td>4104</td>\n",
       "      <td>734</td>\n",
       "      <td>84.8284</td>\n",
       "      <td>15.1716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>807</td>\n",
       "      <td>794</td>\n",
       "      <td>13</td>\n",
       "      <td>98.3891</td>\n",
       "      <td>1.6109</td>\n",
       "      <td>5645</td>\n",
       "      <td>4898</td>\n",
       "      <td>747</td>\n",
       "      <td>86.7671</td>\n",
       "      <td>13.2329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>806</td>\n",
       "      <td>799</td>\n",
       "      <td>7</td>\n",
       "      <td>99.1315</td>\n",
       "      <td>0.868486</td>\n",
       "      <td>6451</td>\n",
       "      <td>5697</td>\n",
       "      <td>754</td>\n",
       "      <td>88.3119</td>\n",
       "      <td>11.6881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>806</td>\n",
       "      <td>796</td>\n",
       "      <td>10</td>\n",
       "      <td>98.7593</td>\n",
       "      <td>1.24069</td>\n",
       "      <td>7257</td>\n",
       "      <td>6493</td>\n",
       "      <td>764</td>\n",
       "      <td>89.4722</td>\n",
       "      <td>10.5278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>807</td>\n",
       "      <td>805</td>\n",
       "      <td>2</td>\n",
       "      <td>99.7522</td>\n",
       "      <td>0.247831</td>\n",
       "      <td>8064</td>\n",
       "      <td>7298</td>\n",
       "      <td>766</td>\n",
       "      <td>90.501</td>\n",
       "      <td>9.49901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>799</td>\n",
       "      <td>7</td>\n",
       "      <td>99.1315</td>\n",
       "      <td>0.868486</td>\n",
       "      <td>8870</td>\n",
       "      <td>8097</td>\n",
       "      <td>773</td>\n",
       "      <td>91.2852</td>\n",
       "      <td>8.71477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>806</td>\n",
       "      <td>804</td>\n",
       "      <td>2</td>\n",
       "      <td>99.7519</td>\n",
       "      <td>0.248139</td>\n",
       "      <td>9676</td>\n",
       "      <td>8901</td>\n",
       "      <td>775</td>\n",
       "      <td>91.9905</td>\n",
       "      <td>8.00951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>807</td>\n",
       "      <td>801</td>\n",
       "      <td>6</td>\n",
       "      <td>99.2565</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>10483</td>\n",
       "      <td>9702</td>\n",
       "      <td>781</td>\n",
       "      <td>92.5498</td>\n",
       "      <td>7.45016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>806</td>\n",
       "      <td>800</td>\n",
       "      <td>6</td>\n",
       "      <td>99.2556</td>\n",
       "      <td>0.744417</td>\n",
       "      <td>11289</td>\n",
       "      <td>10502</td>\n",
       "      <td>787</td>\n",
       "      <td>93.0286</td>\n",
       "      <td>6.97139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>806</td>\n",
       "      <td>803</td>\n",
       "      <td>3</td>\n",
       "      <td>99.6278</td>\n",
       "      <td>0.372208</td>\n",
       "      <td>12095</td>\n",
       "      <td>11305</td>\n",
       "      <td>790</td>\n",
       "      <td>93.4684</td>\n",
       "      <td>6.53162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>806</td>\n",
       "      <td>803</td>\n",
       "      <td>3</td>\n",
       "      <td>99.6278</td>\n",
       "      <td>0.372208</td>\n",
       "      <td>12901</td>\n",
       "      <td>12108</td>\n",
       "      <td>793</td>\n",
       "      <td>93.8532</td>\n",
       "      <td>6.14681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>807</td>\n",
       "      <td>804</td>\n",
       "      <td>3</td>\n",
       "      <td>99.6283</td>\n",
       "      <td>0.371747</td>\n",
       "      <td>13708</td>\n",
       "      <td>12912</td>\n",
       "      <td>796</td>\n",
       "      <td>94.1932</td>\n",
       "      <td>5.80683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>806</td>\n",
       "      <td>802</td>\n",
       "      <td>4</td>\n",
       "      <td>99.5037</td>\n",
       "      <td>0.496278</td>\n",
       "      <td>14514</td>\n",
       "      <td>13714</td>\n",
       "      <td>800</td>\n",
       "      <td>94.4881</td>\n",
       "      <td>5.51192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>806</td>\n",
       "      <td>802</td>\n",
       "      <td>4</td>\n",
       "      <td>99.5037</td>\n",
       "      <td>0.496278</td>\n",
       "      <td>15320</td>\n",
       "      <td>14516</td>\n",
       "      <td>804</td>\n",
       "      <td>94.752</td>\n",
       "      <td>5.24804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>807</td>\n",
       "      <td>804</td>\n",
       "      <td>3</td>\n",
       "      <td>99.6283</td>\n",
       "      <td>0.371747</td>\n",
       "      <td>16127</td>\n",
       "      <td>15320</td>\n",
       "      <td>807</td>\n",
       "      <td>94.996</td>\n",
       "      <td>5.00403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bin #Records #Goods #Bads   %Goods     %Bads Total # Records CumGoods  \\\n",
       "0     1      807    261   546   32.342    67.658             807      261   \n",
       "1     2      806    721    85  89.4541   10.5459            1613      982   \n",
       "2     3      806    759    47  94.1687   5.83127            2419     1741   \n",
       "3     4      807    786    21  97.3978   2.60223            3226     2527   \n",
       "4     5      806    789    17  97.8908   2.10918            4032     3316   \n",
       "5     6      806    788    18  97.7667   2.23325            4838     4104   \n",
       "6     7      807    794    13  98.3891    1.6109            5645     4898   \n",
       "7     8      806    799     7  99.1315  0.868486            6451     5697   \n",
       "8     9      806    796    10  98.7593   1.24069            7257     6493   \n",
       "9    10      807    805     2  99.7522  0.247831            8064     7298   \n",
       "10   11      806    799     7  99.1315  0.868486            8870     8097   \n",
       "11   12      806    804     2  99.7519  0.248139            9676     8901   \n",
       "12   13      807    801     6  99.2565  0.743494           10483     9702   \n",
       "13   14      806    800     6  99.2556  0.744417           11289    10502   \n",
       "14   15      806    803     3  99.6278  0.372208           12095    11305   \n",
       "15   16      806    803     3  99.6278  0.372208           12901    12108   \n",
       "16   17      807    804     3  99.6283  0.371747           13708    12912   \n",
       "17   18      806    802     4  99.5037  0.496278           14514    13714   \n",
       "18   19      806    802     4  99.5037  0.496278           15320    14516   \n",
       "19   20      807    804     3  99.6283  0.371747           16127    15320   \n",
       "\n",
       "   CumBads Cum%Goods Cum%Bads  FDR  FPR  \n",
       "0      546    32.342   67.658  NaN  NaN  \n",
       "1      631   60.8803  39.1197  NaN  NaN  \n",
       "2      678   71.9719  28.0281  NaN  NaN  \n",
       "3      699   78.3323  21.6677  NaN  NaN  \n",
       "4      716   82.2421  17.7579  NaN  NaN  \n",
       "5      734   84.8284  15.1716  NaN  NaN  \n",
       "6      747   86.7671  13.2329  NaN  NaN  \n",
       "7      754   88.3119  11.6881  NaN  NaN  \n",
       "8      764   89.4722  10.5278  NaN  NaN  \n",
       "9      766    90.501  9.49901  NaN  NaN  \n",
       "10     773   91.2852  8.71477  NaN  NaN  \n",
       "11     775   91.9905  8.00951  NaN  NaN  \n",
       "12     781   92.5498  7.45016  NaN  NaN  \n",
       "13     787   93.0286  6.97139  NaN  NaN  \n",
       "14     790   93.4684  6.53162  NaN  NaN  \n",
       "15     793   93.8532  6.14681  NaN  NaN  \n",
       "16     796   94.1932  5.80683  NaN  NaN  \n",
       "17     800   94.4881  5.51192  NaN  NaN  \n",
       "18     804    94.752  5.24804  NaN  NaN  \n",
       "19     807    94.996  5.00403  NaN  NaN  "
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training Subset')\n",
    "print(f'# Records:{len(train2df)}, #Goods:{len(train2df[train2df.Y==0])}, #Bads:{len(train2df[train2df.Y==1])}, Fraud Rate:{round(len(train2df[train2df.Y==1])/len(train2df),6)}')\n",
    "train2results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Subset\n",
      "# Records:12427, #Goods:12248, #Bads:179, Fraud Rate:0.014404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bin</th>\n",
       "      <th>#Records</th>\n",
       "      <th>#Goods</th>\n",
       "      <th>#Bads</th>\n",
       "      <th>%Goods</th>\n",
       "      <th>%Bads</th>\n",
       "      <th>Total # Records</th>\n",
       "      <th>CumGoods</th>\n",
       "      <th>CumBads</th>\n",
       "      <th>Cum%Goods</th>\n",
       "      <th>Cum%Bads</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>57.6</td>\n",
       "      <td>42.4</td>\n",
       "      <td>125</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>57.6</td>\n",
       "      <td>42.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>115</td>\n",
       "      <td>9</td>\n",
       "      <td>92.7419</td>\n",
       "      <td>7.25806</td>\n",
       "      <td>249</td>\n",
       "      <td>187</td>\n",
       "      <td>62</td>\n",
       "      <td>75.1004</td>\n",
       "      <td>24.8996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "      <td>101</td>\n",
       "      <td>23</td>\n",
       "      <td>81.4516</td>\n",
       "      <td>18.5484</td>\n",
       "      <td>373</td>\n",
       "      <td>288</td>\n",
       "      <td>85</td>\n",
       "      <td>77.2118</td>\n",
       "      <td>22.7882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>109</td>\n",
       "      <td>16</td>\n",
       "      <td>87.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>498</td>\n",
       "      <td>397</td>\n",
       "      <td>101</td>\n",
       "      <td>79.7189</td>\n",
       "      <td>20.2811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>97.5806</td>\n",
       "      <td>2.41935</td>\n",
       "      <td>622</td>\n",
       "      <td>518</td>\n",
       "      <td>104</td>\n",
       "      <td>83.2797</td>\n",
       "      <td>16.7203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>96.7742</td>\n",
       "      <td>3.22581</td>\n",
       "      <td>746</td>\n",
       "      <td>638</td>\n",
       "      <td>108</td>\n",
       "      <td>85.5228</td>\n",
       "      <td>14.4772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>1.6129</td>\n",
       "      <td>870</td>\n",
       "      <td>760</td>\n",
       "      <td>110</td>\n",
       "      <td>87.3563</td>\n",
       "      <td>12.6437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>97.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>995</td>\n",
       "      <td>882</td>\n",
       "      <td>113</td>\n",
       "      <td>88.6432</td>\n",
       "      <td>11.3568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>124</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>96.7742</td>\n",
       "      <td>3.22581</td>\n",
       "      <td>1119</td>\n",
       "      <td>1002</td>\n",
       "      <td>117</td>\n",
       "      <td>89.5442</td>\n",
       "      <td>10.4558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>1.6129</td>\n",
       "      <td>1243</td>\n",
       "      <td>1124</td>\n",
       "      <td>119</td>\n",
       "      <td>90.4264</td>\n",
       "      <td>9.57361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>1.6129</td>\n",
       "      <td>1367</td>\n",
       "      <td>1246</td>\n",
       "      <td>121</td>\n",
       "      <td>91.1485</td>\n",
       "      <td>8.8515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>96.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1492</td>\n",
       "      <td>1367</td>\n",
       "      <td>125</td>\n",
       "      <td>91.622</td>\n",
       "      <td>8.37802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>1.6129</td>\n",
       "      <td>1616</td>\n",
       "      <td>1489</td>\n",
       "      <td>127</td>\n",
       "      <td>92.1411</td>\n",
       "      <td>7.85891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>124</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>96.7742</td>\n",
       "      <td>3.22581</td>\n",
       "      <td>1740</td>\n",
       "      <td>1609</td>\n",
       "      <td>131</td>\n",
       "      <td>92.4713</td>\n",
       "      <td>7.52874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>97.5806</td>\n",
       "      <td>2.41935</td>\n",
       "      <td>1864</td>\n",
       "      <td>1730</td>\n",
       "      <td>134</td>\n",
       "      <td>92.8112</td>\n",
       "      <td>7.18884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>98.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1989</td>\n",
       "      <td>1853</td>\n",
       "      <td>136</td>\n",
       "      <td>93.1624</td>\n",
       "      <td>6.83761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>99.1935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>2113</td>\n",
       "      <td>1976</td>\n",
       "      <td>137</td>\n",
       "      <td>93.5163</td>\n",
       "      <td>6.48367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>99.1935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>2237</td>\n",
       "      <td>2099</td>\n",
       "      <td>138</td>\n",
       "      <td>93.831</td>\n",
       "      <td>6.16898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>1.6129</td>\n",
       "      <td>2361</td>\n",
       "      <td>2221</td>\n",
       "      <td>140</td>\n",
       "      <td>94.0703</td>\n",
       "      <td>5.92969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>98.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2486</td>\n",
       "      <td>2344</td>\n",
       "      <td>142</td>\n",
       "      <td>94.288</td>\n",
       "      <td>5.71199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bin #Records #Goods #Bads   %Goods     %Bads Total # Records CumGoods  \\\n",
       "0     1      125     72    53     57.6      42.4             125       72   \n",
       "1     2      124    115     9  92.7419   7.25806             249      187   \n",
       "2     3      124    101    23  81.4516   18.5484             373      288   \n",
       "3     4      125    109    16     87.2      12.8             498      397   \n",
       "4     5      124    121     3  97.5806   2.41935             622      518   \n",
       "5     6      124    120     4  96.7742   3.22581             746      638   \n",
       "6     7      124    122     2  98.3871    1.6129             870      760   \n",
       "7     8      125    122     3     97.6       2.4             995      882   \n",
       "8     9      124    120     4  96.7742   3.22581            1119     1002   \n",
       "9    10      124    122     2  98.3871    1.6129            1243     1124   \n",
       "10   11      124    122     2  98.3871    1.6129            1367     1246   \n",
       "11   12      125    121     4     96.8       3.2            1492     1367   \n",
       "12   13      124    122     2  98.3871    1.6129            1616     1489   \n",
       "13   14      124    120     4  96.7742   3.22581            1740     1609   \n",
       "14   15      124    121     3  97.5806   2.41935            1864     1730   \n",
       "15   16      125    123     2     98.4       1.6            1989     1853   \n",
       "16   17      124    123     1  99.1935  0.806452            2113     1976   \n",
       "17   18      124    123     1  99.1935  0.806452            2237     2099   \n",
       "18   19      124    122     2  98.3871    1.6129            2361     2221   \n",
       "19   20      125    123     2     98.4       1.6            2486     2344   \n",
       "\n",
       "   CumBads Cum%Goods Cum%Bads  FDR  FPR  \n",
       "0       53      57.6     42.4  NaN  NaN  \n",
       "1       62   75.1004  24.8996  NaN  NaN  \n",
       "2       85   77.2118  22.7882  NaN  NaN  \n",
       "3      101   79.7189  20.2811  NaN  NaN  \n",
       "4      104   83.2797  16.7203  NaN  NaN  \n",
       "5      108   85.5228  14.4772  NaN  NaN  \n",
       "6      110   87.3563  12.6437  NaN  NaN  \n",
       "7      113   88.6432  11.3568  NaN  NaN  \n",
       "8      117   89.5442  10.4558  NaN  NaN  \n",
       "9      119   90.4264  9.57361  NaN  NaN  \n",
       "10     121   91.1485   8.8515  NaN  NaN  \n",
       "11     125    91.622  8.37802  NaN  NaN  \n",
       "12     127   92.1411  7.85891  NaN  NaN  \n",
       "13     131   92.4713  7.52874  NaN  NaN  \n",
       "14     134   92.8112  7.18884  NaN  NaN  \n",
       "15     136   93.1624  6.83761  NaN  NaN  \n",
       "16     137   93.5163  6.48367  NaN  NaN  \n",
       "17     138    93.831  6.16898  NaN  NaN  \n",
       "18     140   94.0703  5.92969  NaN  NaN  \n",
       "19     142    94.288  5.71199  NaN  NaN  "
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2df = pd.DataFrame(columns = ['Pred','Prob','Y'])\n",
    "test2df['Pred'] = test2pred\n",
    "test2df['Prob'] = [i[1] for i in test2prob]\n",
    "test2df['Y'] = list(y_oot)\n",
    "\n",
    "test2df = test2df.sort_values(by='Prob',ascending=False)\n",
    "\n",
    "qc = pd.qcut(range(len(test2df)), q=100, precision=1)\n",
    "# bin definition\n",
    "bins  = qc.categories\n",
    "# bin corresponding to each point in data\n",
    "codes = qc.codes\n",
    "\n",
    "test2df['Bin'] = codes\n",
    "test2results = pd.DataFrame(columns = ['Bin','#Records', '#Goods', '#Bads','%Goods','%Bads',\n",
    "                                      'Total # Records','CumGoods','CumBads','Cum%Goods','Cum%Bads',\n",
    "                                      'FDR','FPR'])\n",
    "\n",
    "test2results['Bin'] = list(np.unique(codes))\n",
    "\n",
    "\n",
    "\n",
    "for i in test2results.index:\n",
    "    filt = test2df[test2df.Bin==test2results.loc[i,'Bin']]\n",
    "    test2results.loc[i,'#Records'] = len(filt)\n",
    "    test2results.loc[i,'#Goods'] = len(filt[filt.Y==0])\n",
    "    test2results.loc[i,'#Bads'] = len(filt[filt.Y==1])\n",
    "    test2results.loc[i,'%Goods'] = 100* len(filt[filt.Y==0]) / len(filt)\n",
    "    test2results.loc[i,'%Bads'] = 100* len(filt[filt.Y==1]) / len(filt)\n",
    "    #test2results.loc[i,'FDR'] = 100*len(filt[(filt.Pred==1)&(filt.Y==1)]) / len(filt[test2df.Y==1])\n",
    "    #test2results.loc[i,'FPR'] = 100* len(filt[(filt.Pred==1)&(filt.Y==0)]) / (len(filt[(filt.Pred==1)&(filt.Y==0)]) + len(filt[(filt.Pred==0)&(filt.Y==0)]))\n",
    "\n",
    "test2results.loc[0,'Total # Records'] = test2results.loc[0,'#Records']\n",
    "test2results.loc[0,'CumGoods'] = test2results.loc[0,'#Goods']\n",
    "test2results.loc[0,'CumBads'] = test2results.loc[0,'#Bads']\n",
    "test2results.loc[0,'Cum%Goods'] = test2results.loc[0,'%Goods']\n",
    "test2results.loc[0,'Cum%Bads'] = test2results.loc[0,'%Bads']    \n",
    "\n",
    "\n",
    "for i in range(1,len(test2results)):\n",
    "    test2results.loc[i,'Total # Records'] = test2results.loc[i,'#Records'] + test2results.loc[i-1,'Total # Records']\n",
    "    test2results.loc[i,'CumGoods'] = test2results.loc[i,'#Goods'] + test2results.loc[i-1,'CumGoods']\n",
    "    test2results.loc[i,'CumBads'] = test2results.loc[i,'#Bads'] + test2results.loc[i-1,'CumBads']\n",
    "    test2results.loc[i,'Cum%Goods'] = 100* test2results.loc[i,'CumGoods'] / test2results.loc[i,'Total # Records']\n",
    "    test2results.loc[i,'Cum%Bads'] = 100* test2results.loc[i,'CumBads'] / test2results.loc[i,'Total # Records']\n",
    "    #test2results.loc[i,'FDR'] = 100*len(filt[(filt.Pred==1)&(filt.Y==1)]) / len(test2df[test2df.Y==1]) + test2results.loc[i-1,'FDR']\n",
    "    #test2results.loc[i,'FPR'] = 100* len(filt[(filt.Pred==1)&(filt.Y==0)]) / (len(filt[(filt.Pred==1)&(filt.Y==0)]) + len(filt[(filt.Pred==0)&(filt.Y==0)])) + test2results.loc[i-1,'FPR']\n",
    "    \n",
    "test2results['Bin'] = test2results['Bin'] + 1\n",
    "\n",
    "\n",
    "print('Testing Subset')\n",
    "print(f'# Records:{len(test2df)}, #Goods:{len(test2df[test2df.Y==0])}, #Bads:{len(test2df[test2df.Y==1])}, Fraud Rate:{round(len(test2df[test2df.Y==1])/len(test2df),6)}')\n",
    "test2results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
